<!DOCTYPE html>
<html lang="zh-CN">

  <head>
  <meta charset="utf-8">
  <meta name="author" content="zchengsite, 1451426471@qq.com" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  
  <title>coder的特殊身份</title>

  
    <link rel="apple-touch-icon" href="/images/favicon.png">
    <link rel="icon" href="/images/favicon.png">
  

  <!-- Raleway-Font -->
  <link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet">

  <!-- hexo site css -->
  
<link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/iconfont/iconfont.css">
<link rel="stylesheet" href="/css/github-markdown.css">
<link rel="stylesheet" href="/css/highlight.css">


  <!-- jquery3.3.1 -->
  <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

  <!-- fancybox -->
  <link href="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.css" rel="stylesheet">
  <script async src="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.js"></script>
  
<script src="/js/fancybox.js"></script>


  

<meta name="generator" content="Hexo 4.2.1"></head>


  <body>
    <div id="app">
      <div class="header">
  <div class="avatar">
    <a href="/"><img src="/images/avatar.png" alt=""></a>
    <div class="nickname"><a href="/"></a></div>
  </div>
  <div class="navbar">
    <ul>
      
        <li class="nav-item" data-path="/">
          <a href="/">主页</a>
        </li>
      
        <li class="nav-item" data-path="/archives/">
          <a href="/archives/">归档</a>
        </li>
      
        <li class="nav-item" data-path="/categories/">
          <a href="/categories/">分类</a>
        </li>
      
        <li class="nav-item" data-path="/tags/">
          <a href="/tags/">标签</a>
        </li>
      
        <li class="nav-item" data-path="/about/">
          <a href="/about/">关于</a>
        </li>
      
    </ul>
  </div>
</div>


<script src="/js/activeNav.js"></script>



      <div class="flex-container">
        <!-- 文章详情页，展示文章具体内容，url形式：https://yoursite/文章标题/ -->
<!-- 同时为「标签tag」，「朋友friend」，「分类categories」，「关于about」页面的承载页面，具体展示取决于page.type -->


  
  
  
  
  
  
  
  
  <!-- 文章内容页 url形式：https://yoursite/文章标题/ -->
  <div class="container post-details" id="post-details">
    <div class="post-content">
      <div class="post-title"></div>
      <div class="post-attach">
        <span class="post-pubtime">2020-07-23</span>
        
      </div>
      <div class="markdown-body">
        <h1 id="基础数据类型"><a href="#基础数据类型" class="headerlink" title="基础数据类型"></a>基础数据类型</h1><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707114234.jpg" alt="image-data-struct"></p>
<h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><ul>
<li>SDS（Simple Dynamic String）</li>
</ul>
<p>命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set KEY VALUE</span><br></pre></td></tr></table></figure>



<h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p>Redis 早期版本存储 list 列表数据结构使用的是压缩列表 <code>ziplist</code> 和普通的双向链表 <code>linkedlist</code>，也就是元素少时用 <code>ziplist</code>，元素多时用 <code>linkedlist</code>；</p>
<ul>
<li><strong>ZipList</strong></li>
<li>list（双向链表）</li>
</ul>
<h4 id="编码转换"><a href="#编码转换" class="headerlink" title="编码转换"></a>编码转换</h4><p>当列表对象可以同时满足以下两个条件时，列表对象使用<code>ziplist</code>编码：</p>
<ul>
<li><p>列表对象保存的所有字符串元素的<code>长度都小于64字节</code>；</p>
</li>
<li><p>列表对象保存的元素<code>数量小于512个</code>；<strong>不能满足这两个条件的列表对象需要使用<code>linkedlist</code>编码</strong>。</p>
</li>
</ul>
<h4 id="链表的缺陷"><a href="#链表的缺陷" class="headerlink" title="链表的缺陷"></a>链表的缺陷</h4><ul>
<li>附加空间相对太高，prev 和 next 指针就要占去 16 个字节；</li>
<li>每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率；</li>
</ul>
<p><code>故用 quicklist 代替了 ziplist 和 linkedlist。</code></p>
<h4 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lpush KEY VALUE1 VALUE2 ... VALUEN</span><br></pre></td></tr></table></figure>



<h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><ul>
<li><p><strong>IntSet</strong></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708152254203.png" alt="image-20200708152254203"></p>
</li>
<li><p><strong>Dict（hashtable）</strong></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708152304695.png" alt="image-20200708152304695"></p>
</li>
</ul>
<h4 id="编码转换-1"><a href="#编码转换-1" class="headerlink" title="编码转换"></a>编码转换</h4><p>当集合对象可以同时满足以下两个条件时，对象使用intset编码：</p>
<ul>
<li>集合对象保存的<code>所有元素都是整数值</code>；</li>
<li>集合对象保存的元素<code>数量不超过512个</code>。<strong>不能满足这两个条件的集合对象需要使用<code>hashtable编码</code></strong>。</li>
</ul>
<h4 id="命令-1"><a href="#命令-1" class="headerlink" title="命令"></a>命令</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SADD KEY VALUE</span><br></pre></td></tr></table></figure>



<h3 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h3><h4 id="命令-2"><a href="#命令-2" class="headerlink" title="命令"></a>命令</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZADD KEY FIELD VALUE</span><br></pre></td></tr></table></figure>

<h4 id="编码转换-2"><a href="#编码转换-2" class="headerlink" title="编码转换"></a>编码转换</h4><p>当有序集合对象可以同时满足以下两个条件时，对象使用<code>ziplist编码</code>：</p>
<ul>
<li>有序集合保存的元素<code>数量小于128个</code>；</li>
<li>有序集合保存的所有元素成员的<code>长度都小于64字节</code>；<strong>不能满足以上两个条件的有序集合对象将使用<code>skiplist编码</code>。</strong></li>
</ul>
<h5 id="ZipList编码（REDIS-ENCODING-ZIPLIST）"><a href="#ZipList编码（REDIS-ENCODING-ZIPLIST）" class="headerlink" title="ZipList编码（REDIS_ENCODING_ZIPLIST）"></a><strong>ZipList</strong>编码（<code>REDIS_ENCODING_ZIPLIST</code>）</h5><p><code>ziplist编码</code>的压缩列表对象使用<strong>压缩列表</strong>作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，<strong>第一个节点保存元素的成员（member），而第二个元素则保存元素的分值（score）</strong>。</p>
<p>压缩列表内的集合元素按<strong>分值从小到大进行排序</strong>，<strong>分值较小的元素被放置在靠近表头的方向，而分值较大的元素则被放置在靠近表尾的方向</strong>。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708153022699.png" alt="image-20200708153022699"></p>
<h5 id="SkipList编码（REDIS-ENCODING-SKIPLIST）"><a href="#SkipList编码（REDIS-ENCODING-SKIPLIST）" class="headerlink" title="SkipList编码（REDIS_ENCODING_SKIPLIST）"></a>SkipList编码（<code>REDIS_ENCODING_SKIPLIST</code>）</h5><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708153127512.png" alt="image-20200708153127512"></p>
<p><code>skiplist编码</code>的有序集合对象使用<code>zset结构</code>作为底层实现，一个<code>zset结构</code>同时包含<code>一个字典</code>和<code>一个跳跃表</code>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zset</span> &#123;</span></span><br><span class="line">	zskiplist *zsl;</span><br><span class="line">	dict *dict;</span><br><span class="line">&#125; zset;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>zset结构</code>中的<code>zsl跳跃表</code>按<strong>分值从小到大</strong>保存了所有集合元素，每个跳跃表节点都保存了一个集合元素：<ul>
<li>跳跃表节点的<code>object属性</code>保存了元素的成员，而跳跃表节点的<code>score属性</code>则保存了元素的分值。</li>
<li>通过这个跳跃表，程序可以对有序集合进行<strong>范围型操作</strong>，比如ZRANK、ZRANGE等命令就是基于跳跃表API来实现的。</li>
</ul>
</li>
<li><code>zset结构</code>中的<code>dict字典</code>为有序集合创建了一个从<strong>成员到分值的映射</strong>，字典中的每个键值对都保存了一个集合元素：<ul>
<li>字典的键保存了元素的成员，而字典的值则保存了元素的分值。</li>
<li>通过这个字典，程序可以用<code>O(1)</code>复杂度查找给定成员的分值，<code>ZSCORE命令</code>就是根据这一特性实现的，而很多其他有序集合命令都在实现的内部用到了这一特性。</li>
</ul>
</li>
</ul>
<h4 id="为什么有序集合需要同时使用跳跃表和字典来实现？"><a href="#为什么有序集合需要同时使用跳跃表和字典来实现？" class="headerlink" title="为什么有序集合需要同时使用跳跃表和字典来实现？"></a>为什么有序集合需要同时使用跳跃表和字典来实现？</h4><ul>
<li><p>如果我们只使用<code>字典</code>来实现有序集合，那么虽然以<code>O（1）</code>复杂度查找成员的分值这一特性会被保留，但是，因为字典以无序的方式来保存集合元素，所以每次在执行<strong>范围型操作</strong>——比如<code>ZRANK</code>、<code>ZRANGE</code>等命令时，程序都<strong>需要对字典保存的所有元素进行排序</strong>，完成这种排序需要至少<code>O（NlogN）</code>时间复杂度，以及额外的<code>O（N）</code>内存空间（因为要创建一个数组来保存排序后的元素）。</p>
</li>
<li><p>如果我们只使用<code>跳跃表</code>来实现有序集合，那么跳跃表执行范围型操作的所有优点都会被保留，但因为没有了字典，所以根据成员<strong>查找分值</strong>这一操作的复杂度将从<code>O（1）</code>上升为<code>O（logN）</code>。</p>
</li>
</ul>
<p>  因为以上原因，为了让有序集合的查找和范围型操作都尽可能快地执行，Redis选择了同时使用字典和跳跃表两种数据结构来实现有序集合。</p>
<h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p>在<code>field</code>比较少，各个<code>value</code>值也比较小的时候，<code>hash</code>采用<code>ziplist</code>来实现；</p>
<p>而随着<code>field</code>增多和<code>value</code>值增大，<code>hash</code>可能会变成<code>dict</code>来实现。</p>
<ul>
<li><strong>ZipList</strong></li>
<li><strong>Dict（hashtable）</strong></li>
</ul>
<pre><code>`ziplist编码`的哈希对象使用`压缩列表zipList`作为底层实现，每当有新的键值对要加入到哈希对象时，程序会先将保存了**键的压缩列表节点**推入到压缩列表表尾，然后再将保存了**值的压缩列表节点**推入到压缩列表表尾，因此：</code></pre><ul>
<li>保存了同一键值对的两个节点总是紧挨在一起，<strong>保存键的节点在前，保存值的节点在后</strong>；</li>
<li>先添加到哈希对象中的键值对会被放在压缩列表的表头方向，而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向。</li>
</ul>
<h4 id="编码转换-3"><a href="#编码转换-3" class="headerlink" title="编码转换"></a>编码转换</h4><p>当哈希对象可以同时满足以下两个条件时，哈希对象使用<code>ziplist编码</code>：</p>
<ul>
<li>哈希对象保存的所有键值对的键和值的字符串<code>长度都小于64字节</code>；</li>
<li>哈希对象保存的键值对<code>数量小于512个</code>；<strong>不能满足这两个条件的哈希对象需要使用<code>hashtable编码</code></strong>。</li>
</ul>
<h3 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h3><p>用数据库来算附近的人。</p>
<h4 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h4><p>ZSet</p>
<h4 id="命令-3"><a href="#命令-3" class="headerlink" title="命令"></a>命令</h4><ul>
<li><p>geoadd</p>
<p>携带集合名称以及多个经纬度名称三元组：</p>
<p><code>geoadd hashName 经度 纬度 域名称</code></p>
</li>
<li><p>geodist </p>
<p>可以用来计算两个元素之间的距离，携带集合名称、2 个名称和距离单位；</p>
<p><code>geodist hashName 域名称A 域名称B 距离单位（m、km、mt、ft）</code></p>
</li>
<li><p>geopos</p>
<p>获取集合中任意元素的经纬度坐标，可以一次获取多个；</p>
<p><code>geopos hashName 域名称A 域名称B...</code></p>
</li>
<li><p>geohash</p>
<p>获取元素的经纬度编码字符串；（经纬度为 base32 编码）</p>
</li>
<li><p>georadiusbymember</p>
<p>用来查询指定元素附近的其它元素；</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 范围 20 公里以内最多 3 个元素按距离倒排</span></span><br><span class="line">georadiusbymember company 域名称 <span class="number">20</span> km count <span class="number">3</span> desc</span><br></pre></td></tr></table></figure>
</li>
<li><p>georadius</p>
<p>以给定的经纬度为中心， 返回位于指定半径内的成员。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEORADIUS key longitude latitude radius unit [WITHCOORD] [WITHDIST] [WITHHASH] [ASC|DESC] [COUNT count]</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h4 id="GEO算法"><a href="#GEO算法" class="headerlink" title="GEO算法"></a>GEO算法</h4><pre><code>GeoHash 算法将 `二维的经纬度` 数据映射到 `一维` 的整数，**这样所有的元素都将在挂载到一条线上，距离靠近的二维坐标映射到一维后的点之间距离也会很接近。**
**当我们想要计算 「附近的人时」，首先将目标位置映射到这条线上，然后在这个一维的线上获取附近的点就行了。**

**核心思想：**

就是把整个地球看成是一个 二维的平面，然后把这个平面不断地等分成一个一个小的方格，每一个 坐标元素都位于其中的 唯一一个方格 中，等分之后的 方格越小，那么坐标也就 越精确。</code></pre><h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707162935.jpg" alt="geo-image-1"></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707162942.jpg" alt="geo-image-2"></p>
<p>   把任意坐标变成一串二进制的编码了，类似于 11010010110001000100 这样，通过这个整数我们就可以还原出元素的坐标，整数越长，还原出来的坐标值的损失程序就越小。</p>
<p>规律：</p>
<ul>
<li><p>横着的所有编码中，第 2 位和第 4 位都是一样的，例如第一排第一个 0101 和第二个 0111，他们的第 2 位和第 4 位都是 1；</p>
</li>
<li><p>竖着的所有编码中，第 1 位和第 3 位是递增的，例如第一排第一个 0101，如果单独把第 1 位和第 3 位拎出来的话，那就是 00，同理看第一排第二个 0111，同样的方法第 1 位和第 3 位拎出来是 01，刚好是 00 递增一个；</p>
<p>通过这样的规律我们就把每一个小方块儿进行了一定顺序的编码，这样做的 好处 是显而易见的：<strong>每一个元素坐标既能够被 唯一标识 在这张被编码的地图上，也不至于 暴露特别的具体的位置。</strong></p>
</li>
</ul>
<pre><code>**最后用Base32将二进制编码变为字符串，放进zset中。zset 的 value 是元素的 key，score 是 GeoHash 的 52 位整数值。zset 的 score 虽然是浮点数，但是对于 52 位的整数值来说，它可以无损存储。**</code></pre><h3 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h3><p>用来统计UV。</p>
<h4 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h4><p>Bitmap</p>
<pre><code>Redis 的 HyperLogLog 实现中用到的是 16384 个桶，也就是 2^14，每个桶的 maxbits 需要 6 个 bits 来存储，最大可以表示 maxbits=63，于是总共占用内存就是`2^14 * 6 / 8 = 12k`字节。</code></pre><h4 id="指令"><a href="#指令" class="headerlink" title="指令"></a>指令</h4><ul>
<li><p><strong>pfadd</strong> </p>
<p>增加计数</p>
</li>
<li><p><strong>pfcount</strong></p>
<p>获取计数</p>
</li>
</ul>
<h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707170136.jpg" alt="hyperloglog-image"></p>
<p>给定一系列的随机整数，我们记录下低位连续零位的最大长度 k，通过这个 k 值可以估算出随机数的数量。</p>
<p>利用集合中数字的比特串第一个1出现位置的最大值来预估整体基数，但是这种预估方法存在较大误差，为了改善误差情况，HLL中引入分桶平均的概念。</p>
<h3 id="BloomFilter"><a href="#BloomFilter" class="headerlink" title="BloomFilter"></a>BloomFilter</h3><pre><code>场景：比如我们在使用新闻客户端看新闻时，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉那些已经看过的内容。问题来了，**新闻客户端推荐系统如何实现推送去重的？**</code></pre><h4 id="指令-1"><a href="#指令-1" class="headerlink" title="指令"></a>指令</h4><h5 id="bf-add-bf-madd"><a href="#bf-add-bf-madd" class="headerlink" title="bf.add/bf.madd"></a>bf.add/bf.madd</h5><p><code>bf.add codehole user1</code></p>
<p><code>bf.madd codehole user4 user5 user6</code></p>
<p>添加元素</p>
<h5 id="bf-exists-bf-mexists"><a href="#bf-exists-bf-mexists" class="headerlink" title="bf.exists/bf.mexists"></a>bf.exists/bf.mexists</h5><p><code>bf.exists codehole user4</code></p>
<p><code>bf.mexists codehole user4 user5 user6 user7</code></p>
<p>查询元素是否存在</p>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707172454.jpg" alt="bloomFilter-image"></p>
<pre><code>**每个布隆过滤器对应到 Redis 的数据结构里面就是一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。**</code></pre><h5 id="add操作"><a href="#add操作" class="headerlink" title="add操作"></a>add操作</h5><pre><code>向布隆过滤器中添加 `key` 时，会使用多个 `hash` 函数对` key` 进行 `hash `算得一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 `hash` 函数都会算得一个不同的位置。

再把位数组的这几个位置都置为 1 就完成了` add `操作。</code></pre><h5 id="exists操作"><a href="#exists操作" class="headerlink" title="exists操作"></a>exists操作</h5><pre><code>跟 `add` 一样，也会把 `hash` 的几个位置都算出来，看看位数组中这几个位置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个 `key` 不存在。

如果都是 1，这并不能说明这个 `key` 就一定存在，只是极有可能存在，因为这些位被置为 1 可能是因为其它的 `key` 存在所致。</code></pre><p><strong>如果这个位数组比较稀疏，判断正确的概率就会很大，如果这个位数组比较拥挤，判断正确的概率就会降低。</strong></p>
<h3 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h3><blockquote>
<p>参考：<a href="https://www.wmyskxz.com/2020/03/15/redis-8-fa-bu-ding-yue-yu-stream/#toc-heading-1" target="_blank" rel="noopener">https://www.wmyskxz.com/2020/03/15/redis-8-fa-bu-ding-yue-yu-stream/#toc-heading-1</a></p>
</blockquote>
<p>主要由消息、生产者、消费者、消费组4部分组成。</p>
<ul>
<li><code>生产者</code>负责向消息队列中生产消息，消费者消费某个消息流。<br><code>消费者</code>可以归属某个消费组，也可以不归属任何消费组。<br>当消费者不归属于任何消费组时，该消费者可以消费消息队列中的任何消息。</li>
<li><strong>支持高可用</strong>。但是因为Redis指令复制是异步的。在<code>failOver</code>发生时，Redis可能会丢失极小部分数据。</li>
<li><strong>分区</strong>。没有原生分区支持，必须在客户端进行策略生产消息到不同的Stream。</li>
</ul>
<h4 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707211302.jpg" alt="stream-struct-image"></p>
<h4 id="消息"><a href="#消息" class="headerlink" title="消息"></a>消息</h4><h5 id="语法格式"><a href="#语法格式" class="headerlink" title="语法格式"></a>语法格式</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XADD key ID field string [field string ...]</span><br></pre></td></tr></table></figure>

<p>例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xadd mystream1 * name hb age 20</span><br></pre></td></tr></table></figure>

<ul>
<li><code>mystream1</code>为<code>Stream</code>的名称；</li>
<li><code>*</code> 代表由Redis自行生成消息ID；</li>
<li><code>name</code>、<code>age</code>为该消息的<code>field</code>；</li>
<li><code>hb</code>、<code>20</code>则为对应的<code>field的值</code>；</li>
</ul>
<h5 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h5><ol>
<li><p>唯一的<code>消息ID</code>，严格递增；（Redis自己生成的消息ID为“<code>时间戳+序号</code>”单调递增ID方案。）</p>
<p><strong>为什么使用时间做ID的一部分？</strong></p>
<ul>
<li><p>满足ID自增；</p>
</li>
<li><p>支持范围查找；</p>
</li>
</ul>
</li>
<li><p>消息内容由多个<code>field-value</code>组成；</p>
</li>
</ol>
<h4 id="消费组"><a href="#消费组" class="headerlink" title="消费组"></a>消费组</h4><ul>
<li>每个消费组会有个游标（<code>last_delivered_id</code>）在<code>Stream</code>数组上往前移动，表示当前消费组已经消费到哪条消息了。任意消费者读取了消息都会让<code>last_delivered_id</code>游标移动。</li>
<li>每个消费组都有一个Stream中唯一名称，消费组不会自动创建，需要<code>xgroup create</code>进行创建，需要指定从<code>Stream</code>的某个消息ID开始消费，这个ID用来初始化<code>last_delivered_id</code>变量。</li>
<li>组内消费者既可以选择使用<code>XREAD</code>进行独立消费，也可以多个消费者同时加入一个消费组进行组内消费；</li>
</ul>
<h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><ul>
<li>每个消费组通过组名称唯一标识，每个消费组都可以消费该消息队列的全部消息，多个消费组之间相互独立。</li>
<li>每个消费组可以有多个消费者，消费者通过名称唯一标识，消费者之间的关系是竞争关系，也就是说一个消息只能由该组的一个成员消费。</li>
<li>消费组中的每个成员也有一个待确认消息队列（<code>PEL（Pending Entries List）</code>），<strong>维护着该消费者已经消费尚未确认的消息</strong>。</li>
</ul>
<h5 id="命令-4"><a href="#命令-4" class="headerlink" title="命令"></a>命令</h5><ul>
<li><p><strong>XGROUP</strong></p>
<p>用于管理消费者组，提供创建组、销毁组，更新组起始消息ID等操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XGROUP CREATE mq mqGroup 0</span><br></pre></td></tr></table></figure>

<p>用于在消息队列<code>mq</code>上创建消费组 <code>mpGroup</code>，最后一个参数0，表示该组从第一条消息开始消费。（意义与<code>XREAD</code>的0一致）。<br>除了支持<code>CREATE</code>外，还支持<code>SETID</code>设置起始ID，<code>DESTROY</code>销毁组，<code>DELCONSUMER</code>删除组内消费者等操作。</p>
</li>
<li><p><strong>XREADGROUP</strong></p>
<p>分组消费消息操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XREADGROUP GROUP mqGroup consumerA BLOCK 0 COUNT 1 STREAMS mq &gt;</span><br></pre></td></tr></table></figure>

<p>用于组<code>mqGroup</code>内消费者<code>consumerA</code>在队列mq中消费，阻塞模式为<strong>永远阻塞</strong>，<code>参数&gt;</code>表示未被组内消费的起始消息，参数<code>count 1</code>表示获取一条。</p>
</li>
</ul>
<h5 id="组内消费原理"><a href="#组内消费原理" class="headerlink" title="组内消费原理"></a>组内消费原理</h5><ul>
<li><code>STREAM</code>类型会为每个组记录一个最后处理（交付）的消息ID（<code>last_delivered_id</code>），这样在组内消费时，就可以从这个值后面开始读取，保证不重复消费。</li>
<li>处理完毕后，客户端会使用<code>XACK</code>通知服务器，本条消息已经处理完毕，该消息就会从<code>PEL</code>中移除。</li>
</ul>
<h4 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h4><ul>
<li><p>消费者内部会有个状态变量<code>pending_ids</code>（<code>Pending Entries List</code>），记录了当前已被客户端读取，但是还没有<code>ack</code>的消息。</p>
</li>
<li><p>如果客户端还没有<code>ack</code>，这个变量里的消息ID就会越来越多，一旦某个消息被<code>ack</code>，它就开始减少。</p>
<p>可以独立消费：</p>
</li>
<li><p><strong>可以在不定义消费组的情况下进行Stream消息的独立消费，当Stream没有新消息时，甚至可以阻塞等待。</strong></p>
</li>
<li><p>但是需要独立消费者自己记住当前消费到哪儿了，也就是返回的消息ID。下次继续调用<code>xread</code>时，将上次返回的最后一个消息ID作为参数传递过去，获取后续消费的消息。    </p>
</li>
</ul>
<h5 id="命令-5"><a href="#命令-5" class="headerlink" title="命令"></a>命令</h5><ul>
<li><p><strong>xread</strong></p>
<p>从Stream中读取数据。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] ID [ID ...]</span><br></pre></td></tr></table></figure>

<ul>
<li><code>[COUNT count]</code>，用于限定获取的消息数量；</li>
<li><code>[BLOCK milliseconds]</code>，用于设置<code>XREAD</code>为阻塞模式，默认为非阻塞模式；（BLOCK 0 表示永远阻塞，直到消息到来）</li>
<li><code>ID</code>，用于设置由哪个消息ID开始读取。使用0表示从第一条消息开始。<br>（本例中就是使用0）此处需要注意，消息队列ID是单调递增的，所以通过设置起点，可以向后读取。<br>在阻塞模式中，可以使用<code>$</code> ，表示最新的消息ID。（在非阻塞模式下<code>$</code>无意义）。</li>
</ul>
</li>
</ul>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XREAD streams memberMessage 0</span><br></pre></td></tr></table></figure>

<p>  从<code>memberMessage</code>中读取所有消息。</p>
<h5 id="顺序消费"><a href="#顺序消费" class="headerlink" title="顺序消费"></a>顺序消费</h5><p>需要返回消息ID，下次继续调用<code>xread</code>时，将上次返回的消息ID作为参数传递进去，就可以进行后续信息的消费。</p>
<h4 id="消费"><a href="#消费" class="headerlink" title="消费"></a>消费</h4><p>读到新消息后，对应的新消息ID就会进入消费者的PEL结构中，客户端处理完成后使用xack指令通知服务器，本条消息ID从<code>PEL(Pending)</code>中擦除。</p>
<h4 id="命令-6"><a href="#命令-6" class="headerlink" title="命令"></a>命令</h4><h5 id="xadd"><a href="#xadd" class="headerlink" title="xadd"></a><strong>xadd</strong></h5><p>向Stream中追加消息。</p>
<h5 id="xdel"><a href="#xdel" class="headerlink" title="xdel"></a><strong>xdel</strong></h5><p>从Stream中删除消息，<strong>仅仅设置标志位，不影响消息总长度</strong>。</p>
<h5 id="xrange"><a href="#xrange" class="headerlink" title="xrange"></a><strong>xrange</strong></h5><p>获取Stream中的消息列表，会自动过滤已经删除的消息。</p>
<h5 id="xlen"><a href="#xlen" class="headerlink" title="xlen"></a><strong>xlen</strong></h5><p>获取Stream消息长度。</p>
<h5 id="del"><a href="#del" class="headerlink" title="del"></a><strong>del</strong></h5><p>删除整个Stream消息列表中所有消息。</p>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><h5 id="1）Stream消息太多怎么办？"><a href="#1）Stream消息太多怎么办？" class="headerlink" title="1）Stream消息太多怎么办？"></a>1）Stream消息太多怎么办？</h5><p>方案一：</p>
<p><code>Redis</code>给<code>Stream</code>提供一种定长<code>Stream</code>功能，在<code>XADD</code>的指令提供一个定长长度<code>MAXLEN</code>，就可以将老的消息干掉。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XADD streamName MAXLEN 10</span><br></pre></td></tr></table></figure>

<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708024900885.png" alt="image-20200708024900885"></p>
<p>方案二：</p>
<p>MAXLEN开销大，Stream为了节省内存空间，采用一种带有<code>~</code>的特殊命令：（至少保存1000条数据）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XADD streamName MAXLEN ~ 1000 * ... entry fields here...</span><br></pre></td></tr></table></figure>

<h5 id="2）PEL（Pending-Entries-List）如何避免消息丢失？"><a href="#2）PEL（Pending-Entries-List）如何避免消息丢失？" class="headerlink" title="2）PEL（Pending Entries List）如何避免消息丢失？"></a>2）PEL（Pending Entries List）如何避免消息丢失？</h5><p>在客户端消费者读取Stream消息时，Redis服务器将消息回复给客户端的过程中，客户端突然断开了连接，消息丢失。但是PEL中已经保存了发送出去的消息ID，客户端重新连接后，即可再次收到PEL中消息ID列表。</p>
<p>不过此时<code>XREADGROUP</code>的起始消息ID不能为参数<code>&gt;</code>，而必须是任意有效消息ID，一般设置为<code>0-0</code>，表示读取所有PEL消息以及自<code>last_delevered_id</code>之后消息。</p>
<h5 id="3）忘记ACK怎么办？"><a href="#3）忘记ACK怎么办？" class="headerlink" title="3）忘记ACK怎么办？"></a>3）忘记ACK怎么办？</h5><p>因为PEL是在收到ACK后才删除消息，没有收到的话，会导致PEL不断增长。</p>
<h5 id="4）Stream高可用？"><a href="#4）Stream高可用？" class="headerlink" title="4）Stream高可用？"></a>4）Stream高可用？</h5><p>集群、分区。</p>
<h3 id="Pub-Sub"><a href="#Pub-Sub" class="headerlink" title="Pub/Sub"></a>Pub/Sub</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 订阅频道： </span></span><br><span class="line">SUBSCRIBE channel [channel ....] # 订阅给定的一个或多个频道的信息 PSUBSCRIBE pattern [pattern ....] # 订阅一个或多个符合给定模式的频道 </span><br><span class="line"><span class="meta">#</span><span class="bash"> 发布频道： </span></span><br><span class="line">PUBLISH channel message # 将消息发送到指定的频道 </span><br><span class="line"><span class="meta">#</span><span class="bash"> 退订频道： </span></span><br><span class="line">UNSUBSCRIBE [channel [channel ....]] # 退订指定的频道 </span><br><span class="line">PUNSUBSCRIBE [pattern [pattern ....]] #退订所有给定模式的频道</span><br></pre></td></tr></table></figure>

<h4 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h4><p><strong>每个 Redis 服务器进程维持着一个标识服务器状态</strong> 的 <code>redis.h/redisServer</code> 结构，其中就 <strong>保存着有订阅的频道</strong> 以及 <strong>订阅模式</strong> 的信息：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisServer</span> &#123;</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    dict *pubsub_channels;  <span class="comment">// 订阅频道</span></span><br><span class="line">    <span class="built_in">list</span> *pubsub_patterns;  <span class="comment">// 订阅模式</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h5 id="pubsub-channels"><a href="#pubsub-channels" class="headerlink" title="pubsub_channels"></a>pubsub_channels</h5><p>当客户端订阅某一个频道之后，Redis 就会往 <code>pubsub_channels</code> 这个字典中新添加一条数据，实际上这个 <code>dict</code> 字典维护的是一张链表，比如，下图展示的 <code>pubsub_channels</code> 示例中，<code>client 1</code>、<code>client 2</code> 就订阅了 <code>channel 1</code>，而其他频道也分别被其他客户端订阅：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707205838.jpg" alt="pubsub-image"></p>
<h5 id="pubsub-patterns"><a href="#pubsub-patterns" class="headerlink" title="pubsub_patterns"></a>pubsub_patterns</h5><p>当发送一条消息到 <code>wmyskxz.chat</code> 这个频道时，Redis 不仅仅会发送到当前的频道，还会发送到匹配于当前模式的所有频道，实际上，<code>pubsub_patterns</code> 背后还维护了一个 <code>redis.h/pubsubPattern</code> 结构：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">pubsubPattern</span> &#123;</span> </span><br><span class="line">	redisClient *client; <span class="comment">// 订阅模式的客户端 </span></span><br><span class="line">	robj *pattern; <span class="comment">// 订阅的模式 </span></span><br><span class="line">&#125; pubsubPattern;</span><br></pre></td></tr></table></figure>

<p>每当调用 <code>PSUBSCRIBE</code> 命令订阅一个模式时，程序就创建一个包含客户端信息和被订阅模式的 <code>pubsubPattern</code> 结构，并将该结构添加到 <code>redisServer.pubsub_patterns</code> 链表中。</p>
<h4 id="命令-7"><a href="#命令-7" class="headerlink" title="命令"></a>命令</h4><ul>
<li><p><strong>SUBSCRIBE（订阅）</strong></p>
<p>通过 <code>pubsub_channels</code> 字典，程序只要检查某个频道是否为字典的键，就可以知道该频道是否正在被客户端订阅；只要取出某个键的值，就可以得到所有订阅该频道的客户端的信息。</p>
</li>
<li><p><strong>PUBLISH（发布）</strong></p>
<p>通过<code>pubsub_channels</code>字典定位到具体的客户端，再把消息发送给它们，它还会将 <code>channel</code> 和 <code>pubsub_patterns</code> 中的 <strong>模式</strong> 进行对比，如果 <code>channel</code> 和某个模式匹配的话，那么也将 <code>message</code> 发送到 <strong>订阅那个模式的客户端</strong>。</p>
</li>
<li><p><strong>UNSUBSCRIBE（取消订阅）</strong></p>
<p>从 <code>pubsub_channels</code> 字典的给定频道（键）中，删除关于当前客户端的信息。</p>
</li>
<li><p><strong>PUNSUBSCRIBE</strong></p>
<p>使用 <code>PUNSUBSCRIBE</code> 命令可以退订指定的模式，这个命令执行的是订阅模式的反操作：会删除 <code>redisServer.pubsub_patterns</code> 链表中，所有和被退订模式相关联的 <code>pubsubPattern</code> 结构，这样客户端就不会再收到和模式相匹配的频道发来的信息。</p>
</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol>
<li><strong>没有 Ack 机制，也不保证数据的连续：</strong> <code>PubSub</code> 的生产者传递过来一个消息，<code>Redis</code> 会直接找到相应的消费者传递过去。如果没有一个消费者，那么消息会被直接丢弃。如果开始有三个消费者，其中一个突然挂掉了，过了一会儿等它再重连时，那么重连期间的消息对于这个消费者来说就彻底丢失了；</li>
<li><strong>不持久化消息：</strong> 如果 <code>Redis</code> 停机重启，<code>PubSub</code> 的消息是不会持久化的，毕竟 <code>Redis</code> 宕机就相当于一个消费者都没有，所有的消息都会被直接丢弃；</li>
</ol>
<h3 id="PipLine"><a href="#PipLine" class="headerlink" title="PipLine"></a>PipLine</h3><p><code>pipeline 管道</code>可以将<code>一组redis 命令</code>进行封装，一次性将<code>多个命令</code>传输到redis服务端，并将数据一次性带回。<br>这样<code>pipeline</code>可以通过一次<code>RTT</code> ，将多个数据带回，减少了数据传输的<code>RTT</code>消耗。</p>
<h4 id="Pipeline有什么好处，为什么要用pipeline？"><a href="#Pipeline有什么好处，为什么要用pipeline？" class="headerlink" title="Pipeline有什么好处，为什么要用pipeline？"></a>Pipeline有什么好处，为什么要用pipeline？</h4><p>减少RTT。</p>
<h4 id="原生批命令-mset-mget-与Pipeline对比？"><a href="#原生批命令-mset-mget-与Pipeline对比？" class="headerlink" title="原生批命令(mset, mget)与Pipeline对比？"></a>原生批命令(mset, mget)与Pipeline对比？</h4><ol>
<li><p>原生批命令是原子性，pipeline是非原子性<br>原子性概念：</p>
<p><strong>事务是一个不可分割的最小工作单位,要么都成功要么都失败。</strong></p>
<p>原子操作是指你的一个业务逻辑必须是不可拆分的。</p>
<p>处理一件事情要么都成功，要么都失败，原子不可拆分）；</p>
</li>
<li><p>原生批命令一命令多个key， 但pipeline支持多命令（存在事务），非原子性；</p>
</li>
<li><p>原生批命令是服务端实现，而pipeline需要服务端与客户端共同完成；</p>
</li>
</ol>
<h1 id="基础数据结构"><a href="#基础数据结构" class="headerlink" title="基础数据结构"></a>基础数据结构</h1><h3 id="SDS（Simple-Dynamic-String）"><a href="#SDS（Simple-Dynamic-String）" class="headerlink" title="SDS（Simple Dynamic String）"></a>SDS（Simple Dynamic String）</h3><h4 id="结构-2"><a href="#结构-2" class="headerlink" title="结构"></a>结构</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707143539.jpg" alt="sds-string-struct"></p>
<pre><code>数据有多重定义，可以根据数据大小，定义不同的数据类型：`sdshdr5/8/16/32/64`</code></pre><h4 id="与String区别"><a href="#与String区别" class="headerlink" title="与String区别"></a>与String区别</h4><ol>
<li>获取字符串长度<ul>
<li>string获取字符串长度，耗时O(n)；</li>
<li>SDS记录了字符串长度；</li>
</ul>
</li>
<li>内存管理<ul>
<li>SDS若需调整空间，如果容量不够容纳追加的内容，就会重新分配字节数组并复制原字符串的内容到新数组中；</li>
<li>string不能很好杜绝“缓冲区溢出/内存泄漏的问题“；</li>
</ul>
</li>
</ol>
<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><ul>
<li>缓存功能</li>
<li>计数器</li>
<li>共享用户Session</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注：Redis 规定了字符串的长度不得超过 512 MB</span><br></pre></td></tr></table></figure>

<h3 id="Dict（HashTable）"><a href="#Dict（HashTable）" class="headerlink" title="Dict（HashTable）"></a>Dict（HashTable）</h3><blockquote>
<p><a href="https://juejin.im/post/5edf43aaf265da76fd4ef18c#heading-14" target="_blank" rel="noopener">https://juejin.im/post/5edf43aaf265da76fd4ef18c#heading-14</a></p>
</blockquote>
<h4 id="结构-3"><a href="#结构-3" class="headerlink" title="结构"></a>结构</h4><ul>
<li><p>内部由Hash表构成。（数组+链表，类似HashMap，扩容2*n，第一维2^n）</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707141914.jpg" alt="dict-image"></p>
<p>通过链表解决Hash冲突；</p>
<p>字典内部包含两个dictht结构组成。</p>
</li>
<li><p>属性</p>
<ul>
<li><code>sizemask</code> 表示索引掩码，用于计算索引值，总是等于<code>size-1</code>；</li>
<li><code>type</code> 为函数指针；</li>
<li><code>rehashidx=0</code>，开始<code>rehash</code>，记录<code>rehash</code>进度：<ul>
<li>0 表示要开始进行<code>rehash</code>；</li>
<li>-1 表示<code>rehash</code>结束或目前没有进行；</li>
<li>&gt;0 就是<code>rehash</code>过程中的进度表示了；</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="渐进式rehash"><a href="#渐进式rehash" class="headerlink" title="渐进式rehash"></a><strong>渐进式rehash</strong></h4><h5 id="执行条件"><a href="#执行条件" class="headerlink" title="执行条件"></a>执行条件</h5><ol>
<li>正常情况下，hash表元素个数==一维数组长度，扩容；</li>
<li>若正在<code>bgSave/AOF</code>，则尽量不扩容，当个数为数组长度的五倍，强制扩容；</li>
<li>元素个数地狱数组长度的10%，则缩容（不考虑<code>bgSave/AOF</code>）；</li>
</ol>
<p>==扩容：长度为原始长度*2（最近的2的n次方）<br>缩容：长度为原始长度/2（最近的2的n次方）==</p>
<h5 id="执行过程"><a href="#执行过程" class="headerlink" title="执行过程"></a>执行过程</h5><ol>
<li>新建<code>ht[1]</code>空间；</li>
<li>将<code>rehashIdx=0</code>，表示从第一个元素开始，<code>rehashidx</code>递增；</li>
<li><code>rehash</code> 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 <code>ht[0]</code> 哈希表在 <code>rehashidx</code> 索引上的所有键值对 <code>rehash</code> 到 <code>ht[1]</code> ， 当 <code>rehash</code> 工作完成之后， 程序将 <code>rehashidx</code> 属性的值<code>+1</code>；</li>
<li>随着字典操作的不断执行， 最终在某个时间点上， <code>ht[0]</code> 的所有键值对都会被 <code>rehash</code> 至 <code>ht[1]</code> ， 这时程序将 <code>rehashidx</code> 属性的值设为 <code>-1</code> ， 表示 <code>rehash</code> 操作已完成。</li>
</ol>
<h5 id="倘若rehash时有其他操作"><a href="#倘若rehash时有其他操作" class="headerlink" title="倘若rehash时有其他操作"></a>倘若rehash时有其他操作</h5><p>因为在进行<code>rehash</code>的时候，两个表中都有值，所以不能确定具体在哪个表中，所以要在两个表中进行字典的删除（delete）、查找（find）、更新（update）等操作：</p>
<ul>
<li><p>如果是查找的话，就会现在<code>ht[0]</code>中查找，没有就去<code>ht[1]</code>中找；</p>
</li>
<li><p>但是如果是增加的话，就会一律保存到<code>ht[1]</code>中，不会再像<code>ht[0]</code>中进行任何添加操作，不会多此一举，保证<code>ht[0]</code>中的数据只减不增，直到他变成一个空表。</p>
</li>
</ul>
<h3 id="List-1"><a href="#List-1" class="headerlink" title="List"></a>List</h3><h4 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h4><ul>
<li>可以取范围（<code>LRANGE</code>）、指定下标（<code>INDEX</code>）的数据。</li>
<li><code>LPUSH</code>、<code>RPUSH</code> 可以向链表首尾新增数据。</li>
<li><code>LBPUSH</code>、<code>RBPOP</code> 可以阻塞<code>push/pop</code>数据，倘若没有数据，则阻塞等待，来数据后立即唤醒。</li>
</ul>
<h4 id="结构-4"><a href="#结构-4" class="headerlink" title="结构"></a>结构</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707143212.jpg" alt="list-data-struct"></p>
<h3 id="ZipList"><a href="#ZipList" class="headerlink" title="ZipList"></a>ZipList</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261265&amp;idx=1&amp;sn=e105c4b86a5640c5fc8212cd824f750b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261265&amp;idx=1&amp;sn=e105c4b86a5640c5fc8212cd824f750b&amp;scene=21#wechat_redirect</a></p>
</blockquote>
<p><code>ziplist</code>是一个经过特殊编码的字节数组，它的设计目标就是为了提高存储效率。<br><code>ziplist</code>可以用于<strong>存储字符串或整数</strong>，其中<strong>整数是按真正的二进制表示进行编码的</strong>，而不是编码成字符串序列。它能以<code>O(1)</code>的时间复杂度在表的两端提供<code>push</code>和<code>pop</code>操作。</p>
<p>当<strong>元素长度较小</strong>时，采用<code>ziplist</code>可以有效<strong>节省存储空间</strong>，但<code>ziplist</code>的存储空间是连续的；</p>
<p>当<strong>元素个数比较多</strong>时，修改元素时，必须重新分配存储空间；</p>
<h4 id="结构-5"><a href="#结构-5" class="headerlink" title="结构"></a>结构</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707144403.jpg" alt="ziplist-imge-data-struct"></p>
<h5 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h5><ul>
<li><p><strong>zlbytes</strong><br>压缩列表字节长度，占4个字节；</p>
</li>
<li><p><strong>zltail</strong></p>
<p>压缩列表尾元素相对于压缩列表起始地址的偏移量，4个字节；</p>
</li>
<li><p><strong>zllen</strong></p>
<p>压缩列表的元素个数，2个字节；</p>
</li>
<li><p><strong>entryX</strong></p>
<p>压缩列表存储的元素，可以是字节数组或者整数，长度不限；</p>
</li>
<li><p><strong>zlend</strong></p>
<p>压缩列表的结尾，恒为0xFF， 1个字节；</p>
</li>
</ul>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707145523.jpg" alt="ziplist-entry-image"></p>
<p>属性值：</p>
<ul>
<li><p><strong>previous_entry_length</strong>：</p>
<p>表示前一个元素的字节长度，占1个或者5个字节，当前一个元素的长度小于254字节时，用1个字节表示；</p>
</li>
<li><p><strong>encoding</strong>：</p>
<p>表示当前元素的编码，可判断content内部存储数据类型；</p>
</li>
<li><p><strong>content</strong>：</p>
<p>元素内容；</p>
</li>
</ul>
<h4 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h4><ul>
<li>Hash</li>
<li>ZSet</li>
<li>List</li>
</ul>
<h4 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h4><ol>
<li><strong>当有序结合对象同时满足以下两个条件时，对象使用ziplist编码：</strong><ul>
<li><strong>保存的元素数量小于128；</strong></li>
<li><strong>保存的所有元素长度都小于64字节；</strong></li>
</ul>
</li>
<li><strong>节点长度由保存的内容决定；</strong></li>
</ol>
<h4 id="Hash与ZipList"><a href="#Hash与ZipList" class="headerlink" title="Hash与ZipList"></a>Hash与ZipList</h4><pre><code>hash随着数据的增大，其底层数据结构的实现是会发生变化的，当然存储效率也就不同：</code></pre><ul>
<li><p>在<code>field</code>比较少，各个<code>value</code>值也比较小的时候，<code>hash</code>采用<code>ziplist</code>来实现；</p>
</li>
<li><p>而随着<code>field</code>增多和<code>value</code>值增大，<code>hash</code>可能会变成<code>dict</code>来实现。</p>
</li>
</ul>
<p>   当我们为某个<code>key</code>第一次执行 <code>hset key field value</code> 命令的时候，Redis会创建一个<code>hash</code>结构，这个新创建的<code>hash</code>底层就是一个<code>ziplist</code>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">robj *<span class="title">createHashObject</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> *zl = ziplistNew();</span><br><span class="line">    robj *o = createObject(OBJ_HASH, zl);</span><br><span class="line">    o-&gt;encoding = OBJ_ENCODING_ZIPLIST;</span><br><span class="line">    <span class="keyword">return</span> o;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>每执行一次<code>hset</code>命令，插入的<code>field</code>和<code>value</code>分别作为一个新的数据项插入到<code>ziplist</code>中（即每次<code>hset</code>产生两个数据项）。</p>
<p>当随着数据的插入，hash底层的这个ziplist就可能会转成dict。</p>
<h5 id="那么到底插入多少才会转Hash呢？"><a href="#那么到底插入多少才会转Hash呢？" class="headerlink" title="那么到底插入多少才会转Hash呢？"></a><strong>那么到底插入多少才会转Hash呢？</strong></h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hash-<span class="built_in">max</span>-ziplist-entries <span class="number">512</span></span><br><span class="line">hash-<span class="built_in">max</span>-ziplist-value <span class="number">64</span></span><br></pre></td></tr></table></figure>

<p>在如下两个条件之一满足的时候，ziplist会转成dict：</p>
<ul>
<li>当hash中的数据项（即<code>field-value</code>对）的数目超过512的时候，也就是<code>ziplist</code>数据项超过<code>1024</code>的时候（请参考<code>t_hash.c</code>中的<code>hashTypeSet</code>函数）。</li>
<li>当hash中插入的任意一个value的长度超过了64的时候（请参考<code>t_hash.c</code>中的<code>hashTypeTryConversion</code>函数）。</li>
</ul>
<h5 id="为什么这么设计？"><a href="#为什么这么设计？" class="headerlink" title="为什么这么设计？"></a><strong>为什么这么设计？</strong></h5><p>当<code>ziplist</code>变得很大的时候，它有如下几个缺点：</p>
<ul>
<li>每次插入或修改引发的<code>realloc</code>操作会有更大的概率造成内存拷贝，从而降低性能。</li>
<li>一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。</li>
<li>当<code>ziplist</code>数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为<code>ziplist</code>上的查找需要进行遍历。</li>
</ul>
<h4 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h4><h5 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h5><p>创建压缩列表（11字节 –<code>zlbyte + zltail + zllen + zlend</code>）</p>
<h5 id="插入元素"><a href="#插入元素" class="headerlink" title="插入元素"></a>插入元素</h5><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707145523.jpg" alt="zipList-insert-image"></p>
<ul>
<li>1）当压缩列表为空、插入位置为<code>P0</code>时，不存在前一个元素，即前一个元素的长度为0；</li>
</ul>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707145801.jpg" alt="ziplist-insert2-image"></p>
<ul>
<li>2）当插入位置为<code>P1</code>，需要获取<code>entryX</code>元素的长度，而<code>entryX+1</code>元素的<code>previous_entry_length</code>字段存储的就是<code>entryX元素的长度</code>，比较容易获取；</li>
<li>3）当插入位置为<code>P2</code>时，需要获取<code>entryN</code>元素的长度，<code>entryN</code>是压缩列表的尾元素，计算元素长度时需要将其3个字段长度相加；</li>
</ul>
<h6 id="那么空间大小是不是添加元素前的压缩列表长度与新添加元素长度之和呢？"><a href="#那么空间大小是不是添加元素前的压缩列表长度与新添加元素长度之和呢？" class="headerlink" title="* 那么空间大小是不是添加元素前的压缩列表长度与新添加元素长度之和呢？"></a>* <strong>那么空间大小是不是添加元素前的压缩列表长度与新添加元素长度之和呢？</strong></h6><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707150002.jpg" alt="ziplist-image-sum"></p>
<p>插入元素前，<code>entryX</code>元素的长度为128字节，<code>entryX+1</code>元素的<code>previous_entry_length</code>字段占1个字节；</p>
<p>添加元素<code>entryNEW</code>，元素长度为1024字节，此时<code>entryX+1</code>元素的<code>previous_entry_length</code>字段需要占5个字节，即压缩列表的长度不仅增加了1024个字节，还要加上<code>entryX+1</code>元素扩展的4个字节。而<code>entryX+1</code>元素的长度可能增加4个字节、减少4个字节或不变；</p>
<p>由于重新分配了空间，新元素插入的位置<code>指针P</code>会失效，可以预先计算好指针P相对于压缩列表首地址的偏移量，待分配空间之后再偏移即可。</p>
<h5 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a>删除元素</h5><p>① 计算待删除元素的总长度；</p>
<p>② 数据复制；</p>
<p>③ 重新分配空间（<code>ZipList</code>）。</p>
<h3 id="IntSet"><a href="#IntSet" class="headerlink" title="IntSet"></a>IntSet</h3><h4 id="特点-3"><a href="#特点-3" class="headerlink" title="特点"></a>特点</h4><p>当Redis集合类型的元素都是整数并且都处在64位有符号整数范围之内时，使用该结构体存储。</p>
<ul>
<li><code>inset</code>会随着数据的添加改变它的数据编码，最开始是<code>INTSET_ENC_INT16</code>（值为2）；</li>
<li>每添加一个元素，则根据元素大小决定是否对数据编码进行升级；</li>
</ul>
<h4 id="用途-1"><a href="#用途-1" class="headerlink" title="用途"></a>用途</h4><ul>
<li>Set</li>
</ul>
<h4 id="结构-6"><a href="#结构-6" class="headerlink" title="结构"></a>结构</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707150539.jpg" alt="intset-data-struct-image"></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707150611.jpg" alt="inset-struct-image"></p>
<ul>
<li><p><strong>encoding</strong></p>
<p>数据编码，表示Inset中的每个数据元素用几个字节存储：</p>
<ul>
<li><strong>INTSET_ENC_INT16（两个字节）</strong></li>
<li><strong>INTSET_ENC_INT32（四个字节）</strong></li>
<li><strong>INTSET_ENC_INT64（八个字节）</strong></li>
</ul>
</li>
<li><p><strong>length</strong></p>
<p>表示Inset中的元素个数；</p>
</li>
<li><p><strong>contents</strong></p>
<p><strong>柔性数组</strong>，表示<code>inset</code>的<code>header</code>后面紧跟着数据元素。（<code>数组总长度（总字节数） = encoding*length</code>）</p>
</li>
</ul>
<h4 id="操作流程"><a href="#操作流程" class="headerlink" title="操作流程"></a>操作流程</h4><ul>
<li><p>查找</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707151206.jpg" alt="IntSet-image-search"></p>
</li>
<li><p>新增</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707151443.jpg" alt="inset-image-insert"></p>
</li>
<li><p>删除</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707151443.jpg" alt="intset-image-del"></p>
</li>
</ul>
<h3 id="QuickList（List-ZipList）"><a href="#QuickList（List-ZipList）" class="headerlink" title="QuickList（List + ZipList）"></a>QuickList（List + ZipList）</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s/6aFwnnnYIv3mWm0YkXWn9w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/6aFwnnnYIv3mWm0YkXWn9w</a></p>
</blockquote>
<p>由<code>List</code>和<code>ZipList</code>结合而成，<code>zipList</code>节省内存空间；</p>
<p>用来代替<code>ZipList+List</code>；</p>
<p><code>quicklist</code>是一个双向链表，链表中的每个节点是一个<code>ziplist</code>结构。<br><code>quicklist</code>可以看成是用双向链表将若干小型的<code>ziplist</code>连接到一起组成的一种数据结构。</p>
<ul>
<li>当<code>ziplist</code>节点个数过多，<code>quicklist</code>退化为双向链表，一个极端的情况就是每个<code>ziplist</code>节点只包含一个entry，即只有一个元素。</li>
<li>当<code>ziplist</code>元素个数过少时，<code>quicklist</code>可退化为ziplist，一种极端的情况就是<code>quicklist</code>中只有一个<code>ziplist</code>节点。</li>
</ul>
<h4 id="用途-2"><a href="#用途-2" class="headerlink" title="用途"></a>用途</h4><ul>
<li>List</li>
</ul>
<h4 id="结构-7"><a href="#结构-7" class="headerlink" title="结构"></a>结构</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707151915.jpg" alt="quicklist-image-struct"></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707152258.jpg" alt="ziplist-image-struct"></p>
<p>如图参数配置为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list-max-ziplist-size 3 （一个ziplist最大存储数量为3）</span><br><span class="line">list-compress-depth 2 （两端各有2个node中ziplist数据不压缩）</span><br></pre></td></tr></table></figure>



<h5 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> *zl;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> sz;             <span class="comment">/* ziplist size in bytes */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> count : <span class="number">16</span>;     <span class="comment">/* count of items in ziplist */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> encoding : <span class="number">2</span>;   <span class="comment">/* RAW==1 or LZF==2 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> container : <span class="number">2</span>;  <span class="comment">/* NONE==1 or ZIPLIST==2 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> recompress : <span class="number">1</span>; <span class="comment">/* was this node previous compressed? */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> attempted_compress : <span class="number">1</span>; <span class="comment">/* node can't compress; too small */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> extra : <span class="number">10</span>; <span class="comment">/* more bits to steal for future usage */</span></span><br><span class="line">&#125; quicklistNode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistLZF</span> &#123;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> sz; <span class="comment">/* LZF size in bytes*/</span></span><br><span class="line">    <span class="keyword">char</span> compressed[];</span><br><span class="line">&#125; quicklistLZF;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklist</span> &#123;</span></span><br><span class="line">    quicklistNode *head;</span><br><span class="line">    quicklistNode *tail;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> count; <span class="comment">/* total count of all entries in all ziplists */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> len; <span class="comment">/* number of quicklistNodes */</span></span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">fill</span> : <span class="number">16</span>; <span class="comment">/* fill factor for individual nodes */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> compress : <span class="number">16</span>; <span class="comment">/* depth of end nodes not to compress;0=off */</span></span><br><span class="line">&#125; quicklist;</span><br></pre></td></tr></table></figure>

<p><code>quicklistNode</code>结构代表<code>quicklist</code>的一个节点，其中各个字段的含义如下：</p>
<ul>
<li><p><code>prev</code>: 指向链表前一个节点的指针。</p>
</li>
<li><p><code>next</code>: 指向链表后一个节点的指针。</p>
</li>
<li><p><code>zl</code>: 数据指针。如果当前节点的数据没有压缩，那么它指向一个ziplist结构；否则，它指向一个quicklistLZF结构。</p>
</li>
<li><p><code>sz</code>: 表示<code>zl</code>指向的<code>ziplist</code>的总大小（包括<code>zlbytes</code>, <code>zltail</code>,<code>zllen</code>, <code>zlend</code>和各个数据项）。</p>
<p>需要注意的是：如果<code>ziplist</code>被压缩了，那么这个sz的值仍然是压缩前的<code>ziplist</code>大小。</p>
</li>
<li><p><code>count</code>: 表示ziplist里面包含的数据项个数。这个字段只有16bit。稍后我们会一起计算一下这16bit是否够用。</p>
</li>
<li><p><code>encoding</code>: 表示<code>ziplist</code>是否压缩了（以及用了哪个压缩算法）。</p>
<p>目前只有两种取值：</p>
<ul>
<li>*<em>2 *</em>表示被压缩了（而且用的是LZF压缩算法）;</li>
<li><strong>1</strong> 表示没有压缩。</li>
</ul>
</li>
<li><p><code>container</code>: 是一个预留字段。</p>
<p>本来设计是用来表明一个<code>quicklist</code>节点下面是直接存数据，还是使用<code>ziplist</code>存数据，或者用其它的结构来存数据（用作一个数据容器，所以叫container）。但是，在目前的实现中，这个值是一个固定的值2，表示使用<code>ziplist</code>作为数据容器。</p>
</li>
<li><p><code>recompress</code>: 当我们使用类似<code>lindex</code>这样的命令查看了某一项本来压缩的数据时，需要把数据暂时解压，这时就设置<code>recompress=1</code>做一个标记，等有机会再把数据重新压缩。</p>
</li>
<li><p><code>attempted_compress</code>: 这个值只对Redis的自动化测试程序有用。我们不用管它。</p>
</li>
<li><p><code>extra</code>: 其它扩展字段。目前Redis的实现里也没用上。</p>
</li>
</ul>
<p><code>quicklistLZF</code>结构表示一个<strong>被压缩过的ziplist</strong>。其中：</p>
<ul>
<li><code>sz</code>: 表示压缩后的<code>ziplist</code>大小。</li>
<li><code>compressed</code>: 是个柔性数组（flexible array member），存放压缩后的ziplist字节数组。</li>
</ul>
<p>真正表示quicklist的数据结构是同名的quicklist这个struct：</p>
<ul>
<li><code>head</code>: 指向头节点（左侧第一个节点）的指针。</li>
<li><code>tail</code>: 指向尾节点（右侧第一个节点）的指针。</li>
<li><code>count</code>: 所有ziplist数据项的个数总和。</li>
<li><code>len</code>: <code>quicklist</code>节点的个数。</li>
<li><strong><code>fill</code>: 16bit，ziplist大小设置，存放<code>list-max-ziplist-size</code>参数的值。</strong></li>
<li><strong><code>compress</code>: 16bit，节点压缩深度设置，存放<code>list-compress-depth</code>参数的值。</strong></li>
</ul>
<h5 id="结构为什么这样设计？"><a href="#结构为什么这样设计？" class="headerlink" title="结构为什么这样设计？"></a><strong>结构为什么这样设计？</strong></h5><ul>
<li><p>双向链表便于在表的两端进行<code>push</code>和<code>pop</code>操作，但是它的内存开销比较大。</p>
<ul>
<li><p>首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；</p>
</li>
<li><p>其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。</p>
</li>
</ul>
</li>
<li><p><code>ziplist</code>由于是一整块连续内存，所以<strong>存储效率很高</strong>。</p>
<p>但是，它<strong>不利于修改操作</strong>，<strong>每次数据变动都会引发一次内存的<code>realloc</code></strong>。</p>
<p>特别是当<code>ziplist</code>长度很长的时候，一次<code>realloc</code>可能会导致大批量的数据拷贝，进一步降低性能。</p>
</li>
</ul>
<p><strong>于是，结合了双向链表和ziplist的优点，quicklist就应运而生了。</strong></p>
<h5 id="一个quicklist节点包含多长的ziplist合适呢？"><a href="#一个quicklist节点包含多长的ziplist合适呢？" class="headerlink" title="一个quicklist节点包含多长的ziplist合适呢？"></a>一个<code>quicklist</code>节点包含多长的<code>ziplist</code>合适呢？</h5><p>存储效率分析：</p>
<ul>
<li><p>每个<code>quicklist</code>节点上的<code>ziplist</code>越短，则<strong>内存碎片越多</strong>。</p>
<p>内存碎片多了，有可能在内存中产生很多无法被利用的小碎片，从而降低存储效率。</p>
<p>这种情况的极端是每个<code>quicklist</code>节点上的<code>ziplist</code>只包含一个数据项，这就蜕化成一个<strong>普通的双向链表</strong>了。</p>
</li>
<li><p>每个<code>quicklist</code>节点上的<code>ziplist</code>越长，则为<code>ziplist</code><strong>分配大块连续内存空间的难度就越大</strong>。</p>
<p><strong>有可能出现内存里有很多小块的空闲空间（它们加起来很多），但却找不到一块足够大的空闲空间分配给ziplist的情况。</strong>这同样会降低存储效率。</p>
<p>这种情况的极端是整个<code>quicklist</code>只有一个节点，所有的数据项都分配在这仅有的一个节点的<code>ziplist</code>里面。这其实蜕化成一个<code>ziplist</code>了。</p>
</li>
</ul>
<h5 id="每个-ziplist-存多少元素？"><a href="#每个-ziplist-存多少元素？" class="headerlink" title="每个 ziplist 存多少元素？"></a><strong>每个 ziplist 存多少元素？</strong></h5><pre><code>quicklist 内部默认单个 ziplist 长度为 8k 字节，超出了这个字节数，就会新起一个 ziplist。ziplist 的长度由配置参数`list-max-ziplist-size`决定。</code></pre><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span>-<span class="built_in">max</span>-ziplist-<span class="built_in">size</span>：</span><br><span class="line"></span><br><span class="line"><span class="number">-5</span>: 每个quicklist节点上的ziplist大小不能超过<span class="number">64</span> Kb。（注：<span class="number">1</span>kb =&gt; <span class="number">1024</span> bytes）</span><br><span class="line"><span class="number">-4</span>: 每个quicklist节点上的ziplist大小不能超过<span class="number">32</span> Kb。</span><br><span class="line"><span class="number">-3</span>: 每个quicklist节点上的ziplist大小不能超过<span class="number">16</span> Kb。</span><br><span class="line"><span class="number">-2</span>: 每个quicklist节点上的ziplist大小不能超过<span class="number">8</span> Kb。（<span class="number">-2</span>是Redis给出的默认值）</span><br><span class="line"><span class="number">-1</span>: 每个quicklist节点上的ziplist大小不能超过<span class="number">4</span> Kb。</span><br></pre></td></tr></table></figure>



<h4 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h4><p>当列表很长的时候，最容易被访问的很可能是两端的数据，中间的数据被访问的频率比较低（访问起来性能也很低）。如果应用场景符合这个特点，那么list还提供了一个选项，能够把中间的数据节点进行压缩，从而进一步节省内存空间。</p>
<p>这个参数表示一个quicklist两端不被压缩的节点个数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">list-compress-depth 0 （默认值）</span><br><span class="line"></span><br><span class="line">0: 是个特殊值，表示都不压缩。这是Redis的默认值。</span><br><span class="line">1: 表示quicklist两端各有1个节点不压缩，中间的节点压缩。</span><br><span class="line">2: 表示quicklist两端各有2个节点不压缩，中间的节点压缩。</span><br><span class="line">3: 表示quicklist两端各有3个节点不压缩，中间的节点压缩。</span><br><span class="line">依此类推...</span><br></pre></td></tr></table></figure>

<h4 id="压缩算法-LZF"><a href="#压缩算法-LZF" class="headerlink" title="压缩算法 LZF"></a>压缩算法 LZF</h4><p>LZF – 一种无损压缩算法。</p>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s/6aFwnnnYIv3mWm0YkXWn9w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/6aFwnnnYIv3mWm0YkXWn9w</a></p>
</blockquote>
<h3 id="SkipList"><a href="#SkipList" class="headerlink" title="SkipList"></a>SkipList</h3><blockquote>
<p>参考：<a href="https://www.wmyskxz.com/2020/02/29/redis-2-tiao-yue-biao/" target="_blank" rel="noopener">https://www.wmyskxz.com/2020/02/29/redis-2-tiao-yue-biao/</a></p>
</blockquote>
<h4 id="结构-8"><a href="#结构-8" class="headerlink" title="结构"></a>结构</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710150506356.png" alt="image-20200710150506356"></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707161430.jpg" alt="skiplist-image-struct"></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707161512.jpg" alt="skiplist-code-struct-image"></p>
<p>初始化：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707161554.jpg" alt="skiplist-initial-image"></p>
<h4 id="随机层数"><a href="#随机层数" class="headerlink" title="随机层数"></a>随机层数</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">zslRandomLevel</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">int</span> level = <span class="number">1</span>; </span><br><span class="line">    <span class="keyword">while</span> ((<span class="built_in">random</span>()&amp;<span class="number">0xFFFF</span>) &lt; (ZSKIPLIST_P * <span class="number">0xFFFF</span>)) </span><br><span class="line">        level += <span class="number">1</span>; </span><br><span class="line">    <span class="keyword">return</span> (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="元素排名实现"><a href="#元素排名实现" class="headerlink" title="元素排名实现"></a>元素排名实现</h4><p>跳跃表本身是有序的，Redis 在 <code>skiplist</code> 的 <code>forward</code> 指针上进行了优化，给每一个 <code>forward</code> 指针都增加了 <code>span</code> 属性，用来 <strong>表示从前一个节点沿着当前层的 forward 指针跳到当前这个节点中间会跳过多少个节点</strong>。在上面的源码中我们也可以看到 Redis 在插入、删除操作时都会小心翼翼地更新 <code>span</code> 值的大小。</p>
<p>所以，沿着 <strong>“搜索路径”</strong>，把所有经过节点的跨度 <code>span</code> 值进行累加就可以算出当前元素的最终 rank 值了</p>
<h4 id="特点-4"><a href="#特点-4" class="headerlink" title="特点"></a>特点</h4><ul>
<li>查询为二分法，时间复杂度：O(n)；</li>
<li>对于每一个新插入的节点，都需要调用一个随机算法给它分配一个合理的层数；</li>
<li>插入操作只需要修改节点前后的指针，而不需要对多个节点都进行调整，这就降低了插入操作的复杂度；</li>
<li>Redis 跳跃表默认允许最大的层数是 32（默认也是32层），当<code>Level[0]</code>有 264 个元素时，才能达到 32 层。</li>
</ul>
<h4 id="为什么不用平衡树、Hash表？"><a href="#为什么不用平衡树、Hash表？" class="headerlink" title="为什么不用平衡树、Hash表？"></a>为什么不用平衡树、Hash表？</h4><ol>
<li><p><strong>Hash不适合做范围查找</strong>：skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。</p>
</li>
<li><p><strong>范围查找skiplist更高效</strong>：在做范围查找的时候，平衡树比skiplist操作要复杂。</p>
<p>在<strong>平衡树</strong>上，我们找到指定范围的小值之后，还需要<strong>以中序遍历的顺序继续寻找其它不超过大值的节点</strong>。</p>
<p>如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。</p>
<p>而在<strong>skiplist</strong>上进行范围查找就非常简单，只需要在<strong>找到小值之后，对第1层链表进行若干步的遍历就可以实现。</strong></p>
</li>
<li><p><strong>Skiplist插入不需要移动节点</strong>：平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。</p>
</li>
<li><p><strong>内存占用Skiplist更少</strong>：从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为<code>1/(1-p)</code>，具体取决于参数p的大小。</p>
<p>如果像Redis里的实现一样，取<code>p=1/4</code>，那么平均每个节点包含1.33个指针，比平衡树更有优势。</p>
</li>
<li><p><strong>查询SkipList与平衡树相当，但劣于Hash</strong>：查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；</p>
<p>而<strong>哈希表</strong>在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。</p>
</li>
<li><p><strong>算法实现更简单</strong>：skiplist比平衡树要简单得多。</p>
</li>
</ol>
<p><strong>跳跃表算法实现</strong>：<a href="https://www.wmyskxz.com/2020/02/29/redis-2-tiao-yue-biao/#toc-heading-5" target="_blank" rel="noopener">https://www.wmyskxz.com/2020/02/29/redis-2-tiao-yue-biao/#toc-heading-5</a></p>
<h3 id="Bitmap（位图）"><a href="#Bitmap（位图）" class="headerlink" title="Bitmap（位图）"></a>Bitmap（位图）</h3><p>存储bool数据。</p>
<p>位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。</p>
<p>我们可以使用普通的<code>get/set</code> 直接获取和设置整个位图的内容，也可以使用位图操作 <code>getbit/setbit</code> 等将 byte 数组看成「位数组」来处理。</p>
<h4 id="使用位操作设置字符串he"><a href="#使用位操作设置字符串he" class="headerlink" title="使用位操作设置字符串he"></a>使用位操作设置字符串<code>he</code></h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707164818.jpg" alt="bitmap-struct-image"></p>
<ol>
<li><p>首先使用<code>bin(ord(&#39;h&#39;))</code>命令获取ASCII码：<code>0b1101000</code></p>
<p><code>bin(order(&#39;e&#39;))</code>获取ASCII码：<code>0b1100101</code></p>
</li>
<li><p>然后设置第一个字符，也就是位数组的前 8 位，我们只需要设置值为 1 的位，如上图所示，h 字符只有 1/2/4 位需要设置，e 字符只有 9/10/13/15 位需要设置。值得注意的是位数组的顺序和字符的位顺序是相反的。</p>
<p><strong>（零存整取：「零存」就是使用 setbit 对位值进行逐个设置，「整存」就是使用字符串一次性填充所有位数组，覆盖掉旧值。）</strong></p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setbit s 1 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit s 2 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit s 4 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit s 9 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit s 10 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit s 13 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit s 15 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; get s</span><br><span class="line">&quot;he&quot;</span><br></pre></td></tr></table></figure>



<h4 id="命令-8"><a href="#命令-8" class="headerlink" title="命令"></a>命令</h4><ul>
<li><p><strong>bitcount</strong> </p>
<p>用来统计指定位置范围内 1 的个数。</p>
</li>
<li><p><strong>bitpos</strong></p>
<p>用来查找指定范围内出现的第一个 0 或 1。</p>
</li>
<li><p><strong>bitfield</strong></p>
<p>有三个子指令，分别是 <code>get/set/incrby</code>，它们都可以对指定位片段进行读写，但是最多只能处理 64 个连续的位，如果超过 64 位，就得使用多个子指令，<code>bitfield</code> 可以一次执行多个子指令。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set w hello</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bitfield w get u4 0  # 从第一个位开始取 4 个位，结果是无符号数 (u)</span><br><span class="line">(integer) 6</span><br><span class="line">127.0.0.1:6379&gt; bitfield w get u3 2  # 从第三个位开始取 3 个位，结果是无符号数 (u)</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; bitfield w get i4 0  # 从第一个位开始取 4 个位，结果是有符号数 (i)</span><br><span class="line">1) (integer) 6</span><br><span class="line">127.0.0.1:6379&gt; bitfield w get i3 2  # 从第三个位开始取 3 个位，结果是有符号数 (i)</span><br><span class="line">1) (integer) -3</span><br></pre></td></tr></table></figure>

<p>所谓有符号数是指获取的位数组中第一个位是符号位，剩下的才是值。如果第一位是 1，那就是负数。无符号数表示非负数，没有符号位，获取的位数组全部都是值。有符号数最多可以获取 64 位，无符号数只能获取 63 位 (因为 Redis 协议中的 integer 是有符号数，最大 64 位，不能传递 64 位无符号值)。如果超出位数限制，Redis 就会告诉你参数错误。</p>
<h1 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h1><p><strong>不管是RDB还是AOF都是先写入一个临时文件，然后通过 <code>rename</code> 完成文件的替换工作。</strong></p>
<h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3><h4 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708031046412.png" alt="image-20200708031046412"></p>
<h5 id="手动触发"><a href="#手动触发" class="headerlink" title="手动触发"></a>手动触发</h5><ul>
<li><code>save</code>：会阻塞当前Redis服务器，直到持久化完成，线上应该禁止使用。</li>
<li><code>bgsave</code>：该触发方式会<code>fork</code>一个子进程，由子进程负责持久化过程，因此阻塞只会发生在<code>fork</code>子进程的时候。</li>
</ul>
<h5 id="自动触发"><a href="#自动触发" class="headerlink" title="自动触发"></a>自动触发</h5><ul>
<li>根据我们的 <code>save m n</code> 配置规则自动触发；</li>
<li>从节点<strong>全量复制</strong>时，主节点发送<code>rdb</code>文件给从节点完成复制操作，主节点会触发 <code>bgsave</code>；</li>
<li>执行 <code>debug reload</code> 时；</li>
<li>执行 <code>shutdown</code>时，如果没有开启aof，也会触发。</li>
</ul>
<h4 id="命令-amp-配置"><a href="#命令-amp-配置" class="headerlink" title="命令&amp;配置"></a>命令&amp;配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 时间策略 900秒内执行一条指令就产生快照</span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line"></span><br><span class="line"># 文件名称</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line"></span><br><span class="line"># 文件保存路径</span><br><span class="line">dir &#x2F;home&#x2F;work&#x2F;app&#x2F;redis&#x2F;data&#x2F;</span><br><span class="line"></span><br><span class="line"># 如果持久化出错，主进程是否停止写入</span><br><span class="line">stop-writes-on-bgsave-error yes</span><br><span class="line"></span><br><span class="line"># 是否压缩</span><br><span class="line">rdbcompression yes</span><br><span class="line"></span><br><span class="line"># 导入时是否检查	</span><br><span class="line">rdbchecksum yes</span><br><span class="line"></span><br><span class="line"># 禁用RDB</span><br><span class="line">save &quot;&quot;</span><br></pre></td></tr></table></figure>

<h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><h5 id="SAVE"><a href="#SAVE" class="headerlink" title="SAVE"></a>SAVE</h5><p>在执行时会直接阻塞当前的线程，由于 Redis 是 <a href="https://draveness.me/whys-the-design-redis-single-thread" target="_blank" rel="noopener">单线程</a> 的，所以 <code>SAVE</code> 命令会直接阻塞来自客户端的所有其他请求，这在很多时候对于需要提供较强可用性保证的 Redis 服务都是无法接受的。</p>
<h5 id="BGSAVE（fork-Copy-On-Write）"><a href="#BGSAVE（fork-Copy-On-Write）" class="headerlink" title="BGSAVE（fork + Copy-On-Write）"></a>BGSAVE（fork + Copy-On-Write）</h5><p> 当我们使用 <code>BGSAVE</code> 命令时，Redis 会立刻 <code>fork</code> 出一个子进程，子进程会执行『将内存中的数据以 RDB 格式保存到磁盘中』这一过程，而 <strong>Redis 服务在 <code>BGSAVE</code> 工作期间仍然可以处理来自客户端的请求</strong>。</p>
<p>（<a href="https://github.com/antirez/redis/blob/e916058f0ba59e964f5de3dee17f46ae08f1d385/src/rdb.c#L1343-L1378" target="_blank" rel="noopener"><code>rdbSaveBackground</code></a> 就是用来处理在后台将数据保存到磁盘上的函数）</p>
<ol>
<li>通过 <code>fork</code> 生成的父子进程会共享包括内存空间在内的资源；</li>
<li><code>fork</code> 函数并不会带来明显的性能开销，尤其是对内存进行大量的拷贝，它能通过写时拷贝将拷贝内存这一工作推迟到真正需要的时候；</li>
</ol>
<p><strong>注：</strong></p>
<p>在<code>BGSAVE</code>命令执行期间，客户端发送的<code>SAVE</code>命令会被服务器拒绝，服务器禁止<code>SAVE</code>命令和<code>BGSAVE</code>命令同时执行是为了<strong>避免父进程（服务器进程）和子进程同时执行两个rdbSave调用</strong>，<strong>防止产生竞争条件</strong>。</p>
<p>在<code>BGSAVE</code>命令执行期间，客户端发送的<code>BGSAVE</code>命令会被服务器拒绝，因为同时执行两个<code>BGSAVE</code>命令也会<strong>产生竞争条件。</strong></p>
<p><code>BGREWRITEAOF</code>和<code>BGSAVE</code>两个命令不能同时执行：</p>
<ul>
<li>如果<code>BGSAVE</code>命令正在执行，那么客户端发送的<code>BGREWRITEAOF</code>命令会被延迟到<code>BGSAVE</code>命令执行完毕之后执行；</li>
<li>如果<code>BGREWRITEAOF</code>命令正在执行，那么客户端发送的<code>BGSAVE</code>命令会被服务器拒绝；</li>
</ul>
<h4 id="文件结构（经过压缩的二进制文件-dump-rdb）"><a href="#文件结构（经过压缩的二进制文件-dump-rdb）" class="headerlink" title="文件结构（经过压缩的二进制文件 dump.rdb）"></a>文件结构（经过压缩的二进制文件 dump.rdb）</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709103907289.png" alt="image-20200709103907289"></p>
<ul>
<li><strong>REDIS</strong>：<code>RDB文件</code>的最开头是<code>REDIS</code>部分，这个部分的长度为<code>5字节</code>，保存着“<code>REDIS</code>”五个字符。通过这五个字符，程序可以在载入文件时，快速检查所载入的文件是否为RDB文件；</li>
<li><strong>db_version</strong>：长度为4字节，它的值是一个字符串表示的整数，这个整数记录了RDB文件的版本号；</li>
<li><strong>databases</strong>：部分包含着零个或任意多个数据库，以及各个数据库中的键值对数据：<ul>
<li>如果服务器的数据库状态为空（所有数据库都是空的），那么这个部分也为空，长度为0字节。</li>
<li>如果服务器的数据库状态为非空（有至少一个数据库非空），那么这个部分也为非空，根据数据库所保存键值对的数量、类型和内容不同，这个部分的长度也会有所不同。</li>
</ul>
</li>
<li><strong>EOF</strong>常量：长度为1字节，这个常量标志着RDB文件正文内容的结束，当读入程序遇到这个值的时候，它知道所有数据库的所有键值对都已经载入完毕了。</li>
<li><strong>check_sum</strong>：是一个8字节长的无符号整数，保存着一个校验和，这个校验和是程序通过对REDIS、db_version、databases、EOF四个部分的内容进行计算得出的。服务器在载入RDB文件时，会将载入数据所计算出的校验和与check_sum所记录的校验和进行对比，以此来检查RDB文件是否有出错或者损坏的情况出现。</li>
</ul>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li><p><strong>RDB是Redis数据的非常紧凑的单文件时间点表示</strong>。</p>
<p>RDB文件非常适合备份。例如，您可能希望在最近的24小时内每小时存档一次RDB文件，并在30天之内每天保存一次RDB快照。这使您可以在发生灾难时轻松还原数据集的不同版本。</p>
</li>
<li><p>RDB对灾难恢复非常有用，它是一个紧凑的文件，可以传输到远程数据中心或Amazon S3（可能已加密）上。</p>
</li>
<li><p>RDB最大限度地提高了Redis的性能，因为Redis父进程为了持久化而需要做的唯一工作就是分叉一个孩子，其余所有工作都要做。父实例将永远不会执行磁盘I / O或类似操作。</p>
</li>
<li><p>与AOF相比，RDB允许大型数据集更快地重启。</p>
</li>
</ul>
<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>因为RDB不是实时写入文件的，假如中途停电/服务器宕掉，则会丢失一部分数据。</li>
<li>RDB需要经常使用<code>fork（）</code>才能使用子进程将其持久化在磁盘上。如果数据集很大，<code>fork（）</code>可能很耗时，并且如果数据集很大且CPU性能不佳，则可能导致Redis停止为客户端服务几毫秒甚至一秒钟。AOF还需要<code>fork（）</code>，但您可以调整要重写日志的频率，而无需在持久性上进行权衡。</li>
</ul>
<h4 id="fork函数会带来额外的性能开销，开销如何避免？"><a href="#fork函数会带来额外的性能开销，开销如何避免？" class="headerlink" title="fork函数会带来额外的性能开销，开销如何避免？"></a><strong>fork函数会带来额外的性能开销，开销如何避免？</strong></h4><p>当程序调用了 <code>fork</code> 方法之后，我们就可以通过 <code>fork</code> 的返回值确定父子进程，以此来执行不同的操作：</p>
<ul>
<li><p><code>fork</code> 函数返回 0 时，意味着当前进程是子进程；</p>
</li>
<li><p><code>fork</code> 函数返回非 0 时，意味着当前进程是父进程，返回值是子进程的 <code>pid</code>；</p>
</li>
</ul>
<p>  调用 <code>fork</code> 后的父子进程会运行在不同的内存空间中，当 <code>fork</code> 发生时两者的内存空间有着完全相同的内容，对内存的写入和修改、文件的映射都是独立的，两个进程不会相互影响。</p>
<p><strong>子进程特点</strong>：</p>
<ul>
<li><p><strong>子进程用于独立且唯一的进程 ID；</strong></p>
</li>
<li><p><strong>子进程的父进程 ID 与父进程 ID 完全相同；</strong></p>
</li>
<li><p><strong>子进程不会继承父进程的内存锁；</strong></p>
</li>
<li><p><strong>子进程会重新设置进程资源利用率和 CPU 计时器；</strong></p>
</li>
</ul>
<p>  既然父进程和子进程拥有完全相同的内存空间并且两者对内存的写入都不会相互影响，<strong>那么是否意味着子进程在 <code>fork</code> 时需要对父进程的内存进行全量的拷贝呢？</strong></p>
<p>  但是在以下两个场景都是<strong>灾难性</strong>的：</p>
<ol>
<li>内存中存储大量的数据，<code>fork</code> 时拷贝内存空间会消耗大量的时间和资源，会导致程序一段时间的不可用；</li>
<li>Redis 占用了 <code>10G</code> 的内存，而物理机或者虚拟机的资源上限只有 <code>16G</code>，在这时我们就无法对 Redis 中的数据进行持久化，也就是说 Redis 对机器上内存资源的最大利用率不能超过 <code>50%</code>；</li>
</ol>
<h4 id="全量的拷贝解决方式：写时复制（Copy-on-Write）"><a href="#全量的拷贝解决方式：写时复制（Copy-on-Write）" class="headerlink" title="全量的拷贝解决方式：写时复制（Copy-on-Write）"></a><strong>全量的拷贝解决方式：写时复制（Copy-on-Write）</strong></h4><p>主要作用：</p>
<p> <strong>将拷贝推迟到写操作真正发生时</strong>，这也就避免了大量无意义的拷贝操作。在一些早期的 Unix 系统上，系统调用 <code>fork</code> 确实会立刻对父进程的内存空间进行复制，但是在今天的多数系统中，<code>fork</code> 并不会立刻触发这一过程。</p>
<p> 在 <code>fork</code> 函数调用时，父进程和子进程会被 <code>Kernel</code> 分配到不同的虚拟内存空间中，所以在两个进程看来它们访问的是不同的内存：</p>
<ul>
<li><p>在真正访问虚拟内存空间时，<code>Kernel</code> 会将虚拟内存映射到物理内存上，所以父子进程共享了物理上的内存空间；</p>
</li>
<li><p><strong>当父进程或者子进程对共享的内存进行修改时</strong>，共享的内存才会<strong>以页为单位进行拷贝</strong>，父进程会保留原有的物理空间，而子进程会使用拷贝后的新物理空间；</p>
<p><strong>在 Redis 服务中，子进程只会读取共享内存中的数据，它并不会执行任何写操作，只有父进程会在写入时才会触发这一机制，而对于大多数的 Redis 服务或者数据库，写请求往往都是远小于读请求的，所以使用 <code>fork</code> 加上写时拷贝这一机制能够带来非常好的性能，也让 <code>BGSAVE</code> 这一操作的实现变得非常简单。</strong></p>
</li>
</ul>
<h3 id="AOF（-Append-Only-File-仅追加文件-appendonly-aof）"><a href="#AOF（-Append-Only-File-仅追加文件-appendonly-aof）" class="headerlink" title="AOF（*Append Only File - 仅追加文件 *appendonly.aof）"></a>AOF（*<em>Append Only File - 仅追加文件 *</em>appendonly.aof）</h3><h4 id="执行流程-1"><a href="#执行流程-1" class="headerlink" title="执行流程"></a>执行流程</h4><p>AOF持久化功能的实现可以分为<code>命令追加（append）</code>、<code>文件写入</code>、<code>文件同步（sync）</code>三个步骤。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisServer</span> &#123;</span></span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// AOF缓冲区</span></span><br><span class="line">	sds aof_buf;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的<code>aof_buf缓冲区</code>的末尾。</p>
<p>然后会调用<code>flushAppendOnlyFile函数</code>，考虑是否需要将<code>aof_buf缓冲区</code>中的内容写入和保存到AOF文件里面，且由<code>appendfsync</code>决定：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709234601158.png" alt="image-20200709234601158"></p>
<h5 id="手动触发-1"><a href="#手动触发-1" class="headerlink" title="手动触发"></a>手动触发</h5><p><code>bgrewriteaof</code></p>
<h5 id="自动触发-1"><a href="#自动触发-1" class="headerlink" title="自动触发"></a>自动触发</h5><p>命令实时写入 =&gt; 对AOF文件的重写</p>
<p><strong>频率控制</strong>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> aof文件至少要达到64M才会自动重写</span></span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"><span class="meta">#</span><span class="bash"> aof文件自上一次重写后文件大小增长了100%则再次触发重写</span></span><br><span class="line">auto-aof-rewrite-percentage 100</span><br></pre></td></tr></table></figure>



<h4 id="重写"><a href="#重写" class="headerlink" title="重写"></a>重写</h4><p>为了解决AOF文件体积膨胀的问题，Redis提供了<code>AOF文件重写（rewrite）</code>功能。重写不是通过读取旧的进行，而是直接访问内存中的数据，这样Redis可以创建可能生成的最短的AOF，并且在写入新的AOF时不需要读取磁盘。</p>
<p>通过该功能，Redis服务器可以创建一个<code>新的AOF文件</code>来替代<code>现有的AOF文件</code>，新旧两个AOF文件所保存的数据库状态相同，但新AOF文件不会包含任何浪费空间的冗余命令，所以新AOF文件的体积通常会比旧AOF文件的<code>体积要小得多</code>。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708031153195.png" alt="image-20200708031153195"></p>
<ul>
<li><p>在重写期间，由于主进程依然在响应命令，为了保证最终备份的完整性；</p>
<p>因此它依然会写入旧的AOF file中，如果重写失败，能够保证数据不丢失。</p>
</li>
<li><p>为了把重写期间响应的写入信息也写入到新的文件中，因此也会为子进程保留一个buf，防止新写的file丢失数据。</p>
</li>
<li><p>重写是直接把当前内存的数据生成对应命令，并不需要读取老的AOF文件进行分析、命令合并。</p>
</li>
<li><p>AOF文件直接采用的文本协议，主要是兼容性好、追加方便、可读性高可认为修改修复。</p>
</li>
</ul>
<p>在子进程执行AOF重写期间，服务器进程需要执行以下三个工作：</p>
<p>1）执行客户端发来的命令；</p>
<p>2）将执行后的写命令追加到<code>AOF缓冲区</code>；</p>
<p>3）将执行后的写命令追加到<code>AOF重写缓冲区</code>。</p>
<p>这样一来可以保证：</p>
<ul>
<li><code>AOF缓冲区</code>的内容会定期被写入和同步到<code>AOF文件</code>，对现有AOF文件的处理工作会如常进行。</li>
<li>从创建子进程开始，服务器执行的所有写命令都会被记录到AOF重写缓冲区里面。</li>
</ul>
<p>当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接到该信号之后，会调用一个信号处理函数，并执行以下工作：</p>
<p>1）将<code>AOF重写缓冲区</code>中的所有内容写入到<code>新AOF文件</code>中，这时新AOF文件所保存的数据库状态将和服务器当前的数据库状态一致；</p>
<p>2）对<code>新的AOF文件</code>进行改名，<code>原子地（atomic）</code>覆盖现有的AOF文件，完成新旧两个AOF文件的替换。</p>
<h4 id="命令-amp-配置-1"><a href="#命令-amp-配置-1" class="headerlink" title="命令&amp;配置"></a>命令&amp;配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 是否开启aof</span><br><span class="line">appendonly yes</span><br><span class="line"></span><br><span class="line"># 文件名称</span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"></span><br><span class="line"># 同步方式</span><br><span class="line">appendfsync everysec</span><br><span class="line"></span><br><span class="line"># aof重写期间是否同步</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line"># 重写触发配置</span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"></span><br><span class="line"># 加载aof时如果有错如何处理</span><br><span class="line">aof-load-truncated yes</span><br><span class="line"></span><br><span class="line"># 文件重写策略</span><br><span class="line">aof-rewrite-incremental-fsync yes</span><br></pre></td></tr></table></figure>

<p><code>appendfsync</code>有三种模式：</p>
<ul>
<li><code>always</code>：把每个写命令都立即同步到aof，很慢，但是很安全</li>
<li><code>everysec</code>：每秒同步一次，是折中方案</li>
<li><code>no</code>：redis不处理交给OS来处理，非常快，但是也最不安全</li>
</ul>
<p><code>aof-load-truncated yes</code> 如果该配置启用，在加载时发现aof尾部不正确是，会向客户端写入一个log，但是会继续执行，如果设置为 <code>no</code> ，发现错误就会停止，必须修复后才能重新加载。</p>
<p><strong>持久化数据恢复</strong></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708031851418.png" alt="image-20200708031851418"></p>
<p>文件与存储</p>
<h3 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h3><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708032118324.png" alt="image-20200708032118324"></p>
<p>配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开启混合持久化</span></span><br><span class="line">aof-use-rdb-preamble yes</span><br></pre></td></tr></table></figure>

<p>如果开启了混合持久化，AOF在重写时，不再是单纯<strong>将内存数据转换为RESP命令写入AOF文件</strong>，而是<strong>将重写这一刻之前的内存做RDB快照处理</strong>，并且<strong>将RDB快照内容和增量的AOF修改内存数据的命令存在一起</strong>，都写入新的AOF文件，新的文件一开始不叫<code>appendonly.aof</code>，等到重写完新的AOF文件才会进行改名，原子的覆盖原有的AOF文件，完成新旧两个AOF文件的替换。</p>
<p>于是在Redis重启的时候，可以先加载RDB的内容，然后再重放增量AOF文件就可以完全替代之前的AOF全量文件重放，因此重启效率大幅得到提升。</p>
<h3 id="区别？"><a href="#区别？" class="headerlink" title="区别？"></a>区别？</h3><h4 id="RDB-优点"><a href="#RDB-优点" class="headerlink" title="RDB | 优点"></a>RDB | 优点</h4><ol>
<li>只有一个文件 <code>dump.rdb</code>，<strong>方便持久化</strong>。</li>
<li><strong>容灾性好</strong>，一个文件可以保存到安全的磁盘。</li>
<li><strong>性能最大化</strong>，<code>fork</code> 子进程来完成写操作，让主进程继续处理命令，所以使 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 Redis 的高性能</li>
<li>相对于数据集大时，比 AOF 的 <strong>启动效率</strong> 更高。</li>
</ol>
<h4 id="RDB-缺点"><a href="#RDB-缺点" class="headerlink" title="RDB | 缺点"></a>RDB | 缺点</h4><ol>
<li><strong>数据安全性低</strong>。RDB 是间隔一段时间进行持久化，如果持久化之间 Redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候；</li>
</ol>
<h4 id="AOF-优点"><a href="#AOF-优点" class="headerlink" title="AOF | 优点"></a>AOF | 优点</h4><ol>
<li><strong>数据安全</strong>，aof 持久化可以配置 <code>appendfsync</code> 属性，有 <code>always</code>，每进行一次命令操作就记录到 aof 文件中一次。</li>
<li>通过 append 模式写文件，即使中途服务器宕机，可以通过 <code>redis-check-aof</code>工具解决数据一致性问题。</li>
<li><strong>AOF 机制的 rewrite 模式</strong>。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 <code>flushall</code>）</li>
</ol>
<h4 id="AOF-缺点"><a href="#AOF-缺点" class="headerlink" title="AOF | 缺点"></a>AOF | 缺点</h4><ol>
<li>AOF 文件比 RDB <strong>文件大</strong>，且 <strong>恢复速度慢</strong>。</li>
<li><strong>数据集大</strong> 的时候，比 rdb <strong>启动效率低</strong>。</li>
<li>AOF 将 Redis 执行的每一条命令追加到磁盘中，处理巨大的写入会降低 Redis 的性能。</li>
</ol>
<h1 id="内存回收策略"><a href="#内存回收策略" class="headerlink" title="内存回收策略"></a>内存回收策略</h1><h2 id="内存过期"><a href="#内存过期" class="headerlink" title="内存过期"></a>内存过期</h2><h3 id="定时删除"><a href="#定时删除" class="headerlink" title="定时删除"></a>定时删除</h3><p>在设置键的过期时间的同时，创建一个定时器（timer），让定时器在键的过期时间来临时，立即执行对键的删除操作。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 设置过期时间</span><br><span class="line">redis&gt; EXPIRE KEY TTL</span><br><span class="line">redis&gt; PEXPIRE KEY TTL</span><br><span class="line"># 用于将键key的过期时间设置为timestamp所指定的秒数时间戳</span><br><span class="line">redis&gt; EXPIREAT KEY timestamp</span><br><span class="line"># 用于将键key的过期时间设置为timestamp所指定的毫秒数时间戳</span><br><span class="line">redis&gt; PEXPIREAT KEY timestamp</span><br></pre></td></tr></table></figure>

<p>最终，<code>EXPIRE</code>、<code>PEXPIRE</code>和<code>EXPIREAT</code>三个命令都会转换成<code>PEXPIREAT</code>命令来执行。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708155658200.png" alt="image-20200708155658200"></p>
<p>计算并返回剩余生存时间：</p>
<ul>
<li><p>TTL：以秒为单位返回键的剩余生存时间；</p>
</li>
<li><p>PTTL：以毫秒为单位返回键的剩余生存时间；</p>
<p>缺点：</p>
<p><strong>对CPU时间是最不友好的</strong>：在过期键比较多的情况下，删除过期键这一行为可能会占用相当一部分CPU时间，在内存不紧张但是CPU时间非常紧张的情况下，将CPU时间用在删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。</p>
</li>
</ul>
<h3 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h3><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708160803367.png" alt="image-20200708160803367"></p>
<p>放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。</p>
<p>缺点：</p>
<p><strong>对内存是最不友好的</strong>：如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会释放。</p>
<h3 id="定期删除"><a href="#定期删除" class="headerlink" title="定期删除"></a>定期删除</h3><p>每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。</p>
<p><code>Redis</code>的服务器周期性操作<code>redis.c/serverCron函数</code>执行时，<code>activeExpireCycle函数</code>就会被调用，它在规定的时间内，分多次遍历服务器中的各个数据库，从数据库的<code>expires字典</code>中随机检查一部分键的过期时间，并删除其中的过期键，它的工作模式：</p>
<ul>
<li>函数每次运行时，都从一定数量的数据库中取出一定数量的随机键进行检查，并删除其中的过期键。</li>
<li>全局变量<code>current_db</code>会记录当前<code>activeExpireCycle函数</code>检查的进度，并在下一次<code>activeExpireCycle函数</code>调用时，接着上一次的进度进行处理。比如说，如果当前<code>activeExpireCycle函数</code>在遍历10号数据库时返回了，那么下次<code>activeExpireCycle函数</code>执行时，将从11号数据库开始查找并删除过期键。</li>
<li>随着<code>activeExpireCycle函数</code>的不断执行，服务器中的所有数据库都会被检查一遍，这时函数将<code>current_db</code>变量重置为<code>0</code>，然后再次开始新一轮的检查工作。</li>
</ul>
<p>Redis默认每秒进行10次过期扫描：</p>
<ol>
<li><strong>从过期字典中随机20个key</strong>；</li>
<li><strong>删除这20个key中已过期的；</strong></li>
<li><strong>如果超过25%的key过期，则重复第一步；</strong></li>
<li><strong>为了保证不出现循环过度的情况，Redis还设置了扫描的时间上限，默认不会超过25ms。</strong></li>
</ol>
<h3 id="RDB、AOF和复制功能对过期键处理"><a href="#RDB、AOF和复制功能对过期键处理" class="headerlink" title="RDB、AOF和复制功能对过期键处理"></a>RDB、AOF和复制功能对过期键处理</h3><h4 id="RDB-1"><a href="#RDB-1" class="headerlink" title="RDB"></a>RDB</h4><h5 id="生成"><a href="#生成" class="headerlink" title="生成"></a>生成</h5><p>在执行<code>SAVE命令</code>或者<code>BGSAVE命令</code>创建一个新的<code>RDB文件</code>时，程序会对数据库中的键进行检查，已过期的键不会被保存到新创建的<code>RDB文件</code>中。</p>
<h5 id="载入"><a href="#载入" class="headerlink" title="载入"></a>载入</h5><ul>
<li><p>主服务器：</p>
<p>在载入<code>RDB文件</code>时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会被忽略；</p>
</li>
<li><p>从服务器：</p>
<p>在载入<code>RDB文件</code>时，文件中保存的所有键，不论是否过期，都会被载入到数据库中。</p>
<p>不过，因为主从服务器在进行<strong>数据同步</strong>的时候，<strong>从服务器的数据库就会被清空</strong>，所以一般来讲，过期键对载入<code>RDB文件</code>的从服务器也不会造成影响。</p>
</li>
</ul>
<h4 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h4><h5 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h5><p>  当服务器以<code>AOF持久化</code>模式运行时，如果数据库中的某个键已经过期，但它还没有被<code>惰性删除</code>或者<code>定期删除</code>，那么<code>AOF文件</code>不会因为这个过期键而产生任何影响。</p>
<p>  当过期键被惰性删除或者定期删除之后，程序会向<code>AOF文件</code>追加（<code>append</code>一条<code>DEL命令</code>，来显式地记录该键已被删除。</p>
<h5 id="重写-1"><a href="#重写-1" class="headerlink" title="重写"></a>重写</h5><p>  在执行<code>AOF重写</code>的过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的<code>AOF文件</code>中。</p>
<h5 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h5><p>  <strong>从服务器的过期键删除动作由主服务器控制</strong>：</p>
<ul>
<li>主服务器在删除一个过期键之后，会显式地向所有从服务器发送一个<code>DEL命令</code>，告知从服务器删除这个过期键。</li>
<li>从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期键删除，而是继续像处理未过期的键一样来处理过期键。</li>
<li>从服务器只有在接到主服务器发来的<code>DEL命令</code>之后，才会删除过期键。</li>
</ul>
<h2 id="内存淘汰"><a href="#内存淘汰" class="headerlink" title="内存淘汰"></a>内存淘汰</h2><h3 id="淘汰策略"><a href="#淘汰策略" class="headerlink" title="淘汰策略"></a>淘汰策略</h3><ul>
<li>noeviction： 不淘汰策略，若超过最大内存，返回错误信息；</li>
<li>volatile-lru：从已设置过期时间的 KV 集中优先对<strong>最近最少使用</strong>(<code>less recently used</code>)的数据淘汰；</li>
<li>volatile-lfu：从已设置过期时间的数据集(<code>server.db[i].expires</code>)中挑选最不经常使用的数据淘汰；</li>
<li>volatile-ttl：从已设置过期时间的 KV 集中优先对<strong>剩余时间短</strong>(<code>time to live</code>)的数据淘汰；</li>
<li>volatile-random：从已设置过期时间的 KV 集中<strong>随机选择数据淘汰</strong>；</li>
<li>allkeys-lru</li>
<li>allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key；</li>
<li>allkeys-random</li>
<li>allkeys-ttl</li>
</ul>
<h4 id="淘汰算法"><a href="#淘汰算法" class="headerlink" title="淘汰算法"></a>淘汰算法</h4><ul>
<li>LRU</li>
<li>LFU</li>
<li>FIFO</li>
</ul>
<h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><blockquote>
<p>参考：<a href="https://blog.csdn.net/lwjhxn/article/details/104635261" target="_blank" rel="noopener">https://blog.csdn.net/lwjhxn/article/details/104635261</a></p>
<p><a href="https://www.wmyskxz.com/2020/03/17/redis-9-shi-shang-zui-qiang-ji-qun-ru-men-shi-jian-jiao-cheng/" target="_blank" rel="noopener">https://www.wmyskxz.com/2020/03/17/redis-9-shi-shang-zui-qiang-ji-qun-ru-men-shi-jian-jiao-cheng/</a></p>
<p><a href="https://blog.csdn.net/qianlia/article/details/105491761" target="_blank" rel="noopener">https://blog.csdn.net/qianlia/article/details/105491761</a></p>
</blockquote>
<h2 id="主从"><a href="#主从" class="headerlink" title="主从"></a>主从</h2><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708032855726.png" alt="image-20200708032855726">        </p>
<p><strong>主从复制</strong>，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。</p>
<p>前者称为 <strong>主节点(master)</strong>，后者称为 <strong>从节点(slave)</strong>。且数据的复制是 <strong>单向</strong>（主节点 =&gt; 从节点） 的，只能由<strong>主节点到从节点</strong>。</p>
<p>Redis 主从复制支持 <strong>主从同步</strong> 和 <strong>从从同步</strong> 两种，后者是 Redis 后续版本新增的功能，以减轻主节点的同步负担。（仅能从节点发起：<code>slaveof 127.0.0.1 8080</code>）</p>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ul>
<li><strong>数据冗余：</strong> 主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li>
<li><strong>故障恢复：</strong> 当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复 <em>(实际上是一种服务的冗余)</em>。</li>
<li><strong>负载均衡：</strong> 在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 <em>（即写 Redis 数据时应用连接主节点，读 Redis 数据时应用连接从节点）</em>，分担服务器负载。尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。</li>
<li><strong>高可用基石：</strong> 除了上述作用以外，主从复制还是哨兵和集群能够实施的 <strong>基础</strong>，因此说主从复制是 Redis 高可用的基础。</li>
</ul>
<h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708032635442.png" alt="image-20200708032635442"></p>
<p><strong>三个阶段：准备阶段 =&gt; 数据同步阶段 =&gt; 命令传播阶段</strong>。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709155424603.png" alt="image-20200709155424603"></p>
<ul>
<li><p><strong>建立套接字连接</strong></p>
<p>从服务器根据设置的套接字创建连向主服务器的套接字连接，主服务器接收从服务器的套接字连接之后，为该套接字创建响应的客户端状态，并将此时的从服务器看做是主服务器的客户端，也就是该从服务器同时具备服务器与客户端两个身份。</p>
</li>
<li><p><strong>发送PING命令</strong></p>
<p><code>PING</code>命令主要有两种作用：</p>
<ul>
<li>虽然建立了套接字连接，但是还未使用过，通过发送PING命令检查套接字的读写状态是否正常；</li>
<li>通过发送<code>PING命令</code>检查主服务器能否正常处理命令请求，能处理主服务器回复<code>PONG</code>。</li>
</ul>
</li>
<li><p><strong>身份验证</strong></p>
<p>从服务器接收到主服务器返回的“<code>PONG</code>”回复，接下来就需要考虑身份验证的事。如果从服务器设置了<code>masterauth</code>选项，那么进行身份验证，如果从服务器没有设置<code>masterauth</code>选项，那么不进行身份验证。</p>
</li>
<li><p><strong>发送端口信息</strong></p>
<p>在身份验证步骤之后，从服务器将执行命令<code>REPLCONF listening-port &lt;port&gt;</code>，向主服务器发送从服务器的监听端口号。</p>
</li>
<li><p><strong>同步</strong></p>
<p>从服务器向主服务器发送<code>SYNC命令</code>、<code>PSYNC命令</code>，执行同步操作。</p>
</li>
<li><p><strong>命令传播</strong></p>
<p>主从服务器就会进入命令传播阶段，主服务器只要将自己执行的写命令发送给从服务器，而从服务器只要一直执行并接收主服务器发来的写命令。</p>
<ul>
<li><p><strong>心跳检测</strong></p>
<p>在命令传播阶段，从服务器默认会以<strong>每秒一次的频率</strong>，向主服务器发送命令：<strong><code>REPLCONF ACK &lt;replication_offset&gt;</code></strong>。其中<code>replication_offset</code>是从服务器当前的复制偏移量。</p>
<p>发送<code>REPLCONF ACK</code>命令对于主从服务器有三个作用：</p>
<ul>
<li><p><strong>检测主从服务器的网络连接状态；</strong></p>
<p>1）如果主服务器<code>超过一秒钟</code>没有收到从服务器发来的<code>REPLCONF ACK命令</code>，那么主服务器就知道主从服务器之间的连接出现问题了。</p>
<p>2）通过向主服务器发送<strong><code>INFO replication命令</code></strong>，在列出的从服务器列表的lag一栏中，我们可以看到相应从服务器最后一次向主服务器发送<code>REPLCONF ACK命令</code>距离现在过了多少秒。</p>
</li>
<li><p><strong>辅助实现<code>min-slaves</code>选项；</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 3</span><br><span class="line">min-slaves-max-lag 10</span><br></pre></td></tr></table></figure>

<p>   可以<strong>防止主服务器在不安全的情况下执行写命令</strong>。</p>
<p>   <strong>从服务器的数量少于3个，或者三个从服务器的延迟（lag）值都大于或等于10秒时</strong>，主服务器将拒绝执行写命令。</p>
</li>
<li><p><strong>检测命令丢失。</strong></p>
<p>如果因为网络故障，主服务器传播给从服务器的写命令在半路丢失，那么当从服务器向主服务器发送<code>REPLCONFACK命令</code>时，主服务器将发觉<code>从服务器当前的复制偏移量</code>少于<code>自己的复制偏移量</code>，然后主服务器就会根据从服务器提交的复制偏移量，在<code>复制积压缓冲区里面找到从服务器缺少的数据</code>，并将这些数据重新发送给从服务器。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="执行SYNC命令"><a href="#执行SYNC命令" class="headerlink" title="执行SYNC命令"></a>执行SYNC命令</h3><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709152643001.png" alt="image-20200709152643001"></p>
<h4 id="执行过程-1"><a href="#执行过程-1" class="headerlink" title="执行过程"></a>执行过程</h4><ul>
<li><strong>主服务器</strong> 需要执行 <code>BGSAVE</code> 命令来生成 RDB 文件，这个生成操作会 <strong>消耗</strong> 主服务器大量的 <strong>CPU、内存和磁盘 I/O 的资源</strong>；</li>
<li><strong>主服务器</strong> 需要将自己生成的 RDB 文件 发送给从服务器，这个发送操作会 <strong>消耗</strong> 主服务器 <strong>大量的网络资源</strong> <em>(带宽和流量)</em>，并对主服务器响应命令请求的时间产生影响；</li>
<li>接收到 RDB 文件的 <strong>从服务器</strong> 需要载入主服务器发来的 RDB 文件，并且在载入期间，从服务器 <strong>会因为阻塞而没办法处理命令请求</strong>；</li>
<li>master节点每执行一个写命令就会向slave节点发送相同的写命令，slave节点接收并执行收到的写命令。<strong>（命令传播操作，slave节点初始化完成后的操作）</strong></li>
<li>当<strong>多个从服务器尝试连接同一个主服务器</strong>的时候，就会出现以下两种情况：<ul>
<li>一是：如果master节点保存快照还未执行，所有从服务器都会接收到相同的快照文件和相同缓冲区写命令。</li>
<li>二是：master节点保存快照正已经执行完毕，当主服务器与较早的从服务器完成以上全部步骤之后，主服务器会跟新连接的从服务器重新执行RDB保存快照。</li>
</ul>
</li>
</ul>
<h4 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h4><blockquote>
<p><a href="https://blog.csdn.net/Seky_fei/article/details/106877329" target="_blank" rel="noopener">https://blog.csdn.net/Seky_fei/article/details/106877329</a></p>
</blockquote>
<p>1）master服务器执行BGSAVE命令生成RDB文件，这个生成过程会大量<strong>消耗主服务器资源</strong>（CPU、内存和磁盘I/O资源）。</p>
<p>2）master需要将生成的RDB文件发送给slave，这个发送操作会<strong>消耗主从服务器大量的网络资源</strong>（带宽与流量）。</p>
<p>3）接收到RDB文件后，slave需要载入RDB文件，载入期间slave会因为阻塞而导致没办法处理命令请求（master不会阻塞）。</p>
<p>4）最大的问题是<strong>重连接后回全量同步数据</strong>。如上面例子，slave在断开后，再进行重新连时，slave丢掉以前的数据，行全量同步master数据，要是断开到重连期间执行的写命令很少，这种操作就没有必要了。</p>
<h3 id="执行PSYNC命令"><a href="#执行PSYNC命令" class="headerlink" title="执行PSYNC命令"></a>执行PSYNC命令</h3><ol>
<li><p><strong>全量复制：</strong> 用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作；</p>
</li>
<li><p><strong>部分复制：</strong> 用于网络中断等情况后的复制，只将 ==<strong>中断期间主节点执行的写命令</strong>== 发送给从节点，与全量复制相比更加高效。<strong>需要注意</strong> 的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制；</p>
<p><strong>部分复制的原理：</strong></p>
<p>主要是靠主从节点分别维护一个 <strong>复制偏移量</strong>，有了这个偏移量之后断线重连之后一比较，之后就可以仅仅把从服务器断线之后确实的这部分数据给补回来了。</p>
</li>
</ol>
<h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PSYNC &#123;runId&#125; &#123;offset&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>runId</strong>：每个 Redis 节点启动都会生成唯一的 uuid，每次 Redis 重启后，runId 都会发生变化；</p>
</li>
<li><p><strong>offset</strong>（replication offset）：主节点和从节点都各自维护自己的主从复制偏移量 offset。</p>
<p>当主节点有写入命令时，<code>offset=offset+命令的字节长度</code>。</p>
<p>从节点在收到主节点发送的命令后，也会增加自己的 offset，并把自己的 offset 发送给主节点。</p>
<p>这样，主节点同时保存自己的 offset 和从节点的 offset，通过对比 offset 来判断主从节点数据是否一致；</p>
</li>
<li><p><strong>复制积压缓冲区</strong>（replication backlog）：保存在主节点上的一个固定长度的FIFO队列，默认大小是 1MB；==（固定大小）==</p>
<ul>
<li>如果<code>offset偏移量</code>之后的数据（也即是偏移量<code>offset+1</code>开始的数据）仍然<code>存在于复制积压缓冲区</code>里面，那么主服务器将对从服务器执行部分重同步操作；</li>
<li>相反，如果<code>offset偏移量</code>之后的数据已经<code>不存在于复制积压缓冲区</code>，那么主服务器将对从服务器执行完整重同步操作。</li>
</ul>
</li>
</ul>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置复制积压缓冲区大小，积压队列越大，允许主从数据库断线的时间就越长</span></span><br><span class="line">repl-backlog-size 1mb</span><br></pre></td></tr></table></figure>

<p><code>复制积压缓冲区</code>本质上是一个固定长度的循环队列，默认情况下积压队列的大小为1MB，可以通过配置文件设置队列大小。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="comment">#没有salve连接时，多久释放一次复制积压缓冲区</span></span></span><br><span class="line">repl-backlog-ttl 3600</span><br></pre></td></tr></table></figure>

<p>Redis同时也提供了当没有slave需要同步的时候，多久可以<code>释放环形队列</code>，默认一小时。</p>
<h4 id="执行过程-2"><a href="#执行过程-2" class="headerlink" title="执行过程"></a>执行过程</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709154901864.png" alt="image-20200709154901864"></p>
<p><strong>与SYNC区别：salve连接时，判断是否需要全量同步，全量同步的逻辑过程和SYNC一样。</strong></p>
<ol>
<li><p>客户端向服务器发送<code>SLAVEOF</code>命令，即<code>salve</code>向<code>master</code>发起连接请求时，<code>slave</code>根据自己是否保存<code>Master runid</code>来判断是否是第一次连接；</p>
</li>
<li><p>如果是第一次同步则向<code>Master</code>发送 <code>PSYNC ? -1</code> 命令来进行<strong>完整同步</strong>；</p>
<p>如果是重连接，会向<code>Master</code>发送<code>PSYNC runid offset</code>命令（<code>runid</code>是<code>master</code>的<code>身份ID</code>，<code>offset</code>是<code>从节点</code>同步命令的<code>全局迁移量</code>）；</p>
</li>
<li><p>Master接收到<code>PSYNC</code> 命令后，首先判断<code>runid是否和本机的id一致</code>，如果一致则会再次判断<code>offset偏移量</code>和<code>本机的偏移量</code>相差有没有<strong>超过复制积压缓冲区大小</strong>，如果没有那么就给Slave发送CONTINUE，此时Slave只需要等待Master传回失去连接期间丢失的命令；</p>
</li>
<li><p>如果<code>runid</code>和<code>本机id</code>不一致或者<code>offset</code>差距<strong>超过了复制积压缓冲区大小</strong>，那么就会返回<code>FULLRESYNC runid offset</code>，<code>Slave</code>将<code>runid</code>保存起来，并进行<code>全量同步</code>。</p>
</li>
</ol>
<p>接收到PSYNC命令的主服务器会向从服务器返回以下三种回复的其中一种：</p>
<ul>
<li>如果主服务器返回<code>+FULLRESYNC ＜runid＞ ＜offset＞</code>回复，那么表示主服务器将与从服务器执行完整重同步操作：<ul>
<li>其中<code>runid</code>是这个主服务器的<code>运行ID</code>，从服务器会将这个ID保存起来，在下一次发送<code>PSYNC命令</code>时使用；</li>
<li>而<code>offset</code>则是主服务器当前的复制偏移量，从服务器会将这个值作为自己的初始化偏移量。</li>
</ul>
</li>
<li>如果主服务器返回<code>+CONTINUE</code>回复，那么表示主服务器将与从服务器执行部分重同步操作，从服务器只要等着主服务器将自己缺少的那部分数据发送过来就可以了。</li>
<li>如果主服务器返回<code>-ERR</code>回复，那么表示主服务器的版本低于Redis 2.8，它识别不了PSYNC命令，从服务器将向主服务器发送<code>SYNC命令</code>，并与主服务器执行完整同步操作。</li>
</ul>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709174851468.png" alt="image-20200709174851468"></p>
<h3 id="主从存在的问题"><a href="#主从存在的问题" class="headerlink" title="主从存在的问题"></a>主从存在的问题</h3><ol>
<li><p>一旦<strong>主节点宕机，从节点晋升为主节点</strong>，同时需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。</p>
</li>
<li><p><strong>主节点的写能力受到单机的限制</strong>。</p>
</li>
<li><p><strong>主节点的存储能力受到单机的限制</strong>。</p>
</li>
<li><p><strong>原生复制的弊端</strong>在早期的版本中也会比较突出，比如：redis 复制中断后，从节点会发起 <code>psync</code>。</p>
<p>此时如果同步不成功，则会进行全量同步，主库执行全量备份的同时，可能会造成毫秒或秒级的卡顿。</p>
</li>
</ol>
<p><strong>解决方案：Sentinel（哨兵）</strong></p>
<h2 id="Sentinel-哨兵"><a href="#Sentinel-哨兵" class="headerlink" title="Sentinel(哨兵)"></a>Sentinel(哨兵)</h2><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708033501008.png" alt="image-20200708033501008"></p>
<h5 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h5><ul>
<li><strong>监控（Monitoring）：</strong> 哨兵会不断地检查主节点和从节点是否运作正常。</li>
<li><strong>自动故障转移（Automatic failover）：</strong> 当 <strong>主节点</strong> 不能正常工作时，哨兵会开始 <strong>自动故障转移操作</strong>，它会将失效主节点的其中一个 <strong>从节点升级为新的主节点</strong>，并让其他从节点改为复制新的主节点。</li>
<li><strong>配置提供者（Configuration provider）：</strong> 客户端在初始化时，通过连接哨兵来获得当前 Redis 服务的主节点地址。</li>
<li><strong>通知（Notification）：</strong> 哨兵可以将故障转移的结果发送给客户端。</li>
</ul>
<h5 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h5><ol>
<li>每个 Sentinel 节点都需要定期执行以下任务：每个 Sentinel 以每秒一次的频率，向它所知的主服务器、从服务器以及其他的 Sentinel 实例发送一个 PING 命令；</li>
<li>如果一个实例距离最后一次有效回复 PING 命令的时间超过<code>down-after-milliseconds</code>所指定的值，那么这个实例会被 Sentinel 标记为<strong>主观下线（sdown）</strong>。</li>
<li>如果一个主服务器被标记为<strong>主观下线（sdown）</strong>，那么正在监视这个服务器的所有 Sentinel 节点，要以每秒一次的频率确认主服务器的确进入了主观下线状态，当<code>Sentinel</code>从其他<code>Sentinel</code>那里接收到足够数量（<code>quorum</code>）的已下线判断之后，<code>Sentinel</code>就会将从服务器判定为客观下线，并对主服务器执行<code>故障转移</code>操作。</li>
<li>一般情况下，每个 Sentinel 会以每 10 秒一次的频率向它已知的所有主服务器和从服务器发送 INFO 命令，当一个主服务器被标记为<strong>客观下线（odown）</strong>时，Sentinel 向下线主服务器的所有从服务器发送 INFO 命令的频率，会从 10 秒一次改为每秒一次。</li>
<li>当一个主服务器被判断为客观下线时，监视这个下线主服务器的各个Sentinel会进行协商，选举出一个<code>领头Sentinel</code>，并由<code>领头Sentinel</code>对下线主服务器执行<code>故障转移操作</code>。（Raft算法）</li>
<li>当没有足够数量的 Sentinel 同意主服务器下线时，主服务器的客观下线状态就会被移除。当主服务器重新向 Sentinel 的 PING 命令返回有效回复时，主服务器的主观下线状态就会被移除。</li>
</ol>
<h5 id="客户端访问哨兵？"><a href="#客户端访问哨兵？" class="headerlink" title="客户端访问哨兵？"></a>客户端访问哨兵？</h5><p>（不需要显式的指定主节点的地址，就可以连接到主节点）</p>
<ul>
<li><strong>遍历哨兵节点，获取主节点信息：</strong> 遍历哨兵节点，通过其中一个<code>哨兵节点 + masterName</code> 获得主节点的信息；该功能是通过调用哨兵节点的 <code>sentinel get-master-addr-by-name</code> 命令实现；</li>
<li><strong>增加对哨兵的监听：</strong> 这样当发生故障转移时，客户端便可以收到哨兵的通知，从而完成主节点的切换。具体做法是：利用 Redis 提供的 <strong>发布订阅</strong> 功能，为每一个哨兵节点开启一个单独的线程，订阅哨兵节点的 + switch-master 频道，当收到消息时，重新初始化连接池。</li>
</ul>
<h5 id="初始化Sentinel"><a href="#初始化Sentinel" class="headerlink" title="初始化Sentinel"></a>初始化Sentinel</h5><ol>
<li><p>初始化Sentinel状态（初始化如下对象）；</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709180519642.png" alt="image-20200709180519642"></p>
</li>
<li><p>初始化Sentinel状态的masters属性；</p>
<p>Sentinel状态中的masters字典记录了所有被Sentinel监视的主服务器的相关信息，其中：</p>
<ul>
<li><p>字典的键是被监视主服务器的名字。</p>
</li>
<li><p>而字典的值则是被监视主服务器对应的<code>sentinel.c/sentinelRedisInstance</code>结构。</p>
<p>每个<code>sentinelRedisInstance</code>结构（后面简称“实例结构”）代表一个被Sentinel监视的Redis服务器实例（instance），这个实例可以是主服务器、从服务器，或者另外一个Sentinel。</p>
</li>
</ul>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709180800213.png" alt="image-20200709180800213"></p>
</li>
<li><p>创建连向主服务器的异步网络连接；</p>
<ul>
<li>一个是==命令连接==，这个连接专门用于向主服务器发送命令，并接收命令回复。</li>
<li>另一个是==订阅连接==，这个连接专门用于订阅主服务器的<code>__sentinel__:hello</code>频道。</li>
</ul>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709223540755.png" alt="image-20200709223540755"></p>
</li>
</ol>
<p><strong>为什么有两个链接？</strong></p>
<ul>
<li>如果在信息发送时，想要<strong>接收信息的客户端不在线或者断线</strong>，那么这个客户端就会丢失这条信息。因此，为了不丢失<code>__sentinel__:hello</code>频道的任何信息，<code>Sentinel</code>必须专门用一个订阅连接来接收该频道的信息。</li>
<li>除了订阅频道之外，<code>Sentinel</code>还必须<strong>向主服务器发送命令</strong>，以此来与主服务器进行通信，所以<code>Sentinel</code>还必须向主服务器创建命令连接。</li>
</ul>
<h5 id="获取主服务器信息"><a href="#获取主服务器信息" class="headerlink" title="获取主服务器信息"></a>获取主服务器信息</h5><p>Sentinel默认会以每十秒一次的频率，通过命令连接向被监视的主服务器发送INFO命令，并通过分析<code>INFO</code>命令的回复来获取主服务器的当前信息。</p>
<p>通过分析主服务器返回的<code>INFO</code>命令回复信息，<code>Sentinel</code>可以获取以下信息：</p>
<ul>
<li><p>关于主服务器本身的信息，包括<code>run_id</code>域记录的服务器<code>运行ID</code>，以及<code>role</code>域记录的服务器角色；</p>
</li>
<li><p>关于主服务器属下所有从服务器的信息，每个从服务器都由一个”<code>slave</code>“字符串开头的行记录，每行的<code>ip=域</code>记录了从服务器的IP地址，而<code>port=域</code>则记录了从服务器的端口号。根据这些IP地址和端口号，<code>Sentinel</code>无须用户提供从服务器的地址信息，就可以自动发现从服务器。</p>
<p>根据<code>run_id域</code>和<code>role域</code><strong>记录的信息</strong>，<code>Sentinel</code>将对主服务器的实例结构进行更新。例如，主服务器重启之后，它的<code>运行ID</code>就会和实例结构之前保存的<code>运行ID</code>不同，<code>Sentinel</code>检测到这一情况之后，就会对实例结构的<code>运行ID</code>进行更新。至于主服务器返回的<strong>从服务器信息</strong>，则会被用于更新主服务器实例结构的<code>slaves字典</code>。</p>
</li>
</ul>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709224458594.png" alt="image-20200709224458594"></p>
<h5 id="检测主观下线状态"><a href="#检测主观下线状态" class="headerlink" title="检测主观下线状态"></a>检测主观下线状态</h5><p>默认情况下，<code>Sentinel</code>会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器、从服务器、其他<code>Sentinel</code>在内）发送<code>PING</code>命令，并通过实例返回的<code>PING</code>命令回复来判断实例是否在线。</p>
<p>如果一个实例在<code>down-after-milliseconds</code>毫秒内，连续向<code>Sentinel</code>返回无效回复，那么<code>Sentinel</code>会修改这个实例所对应的实例结构，在<code>SentinelRedisInstance</code>结构的<code>flags</code>属性中打开<code>SRI_S_DOWN</code>标识，以此来表示这个实例已经进入<code>主观下线状态</code>。    </p>
<p>用户设置的<code>down-after-milliseconds</code>选项的值，不仅会被<code>Sentinel</code>用来判断主服务器的主观下线状态，还会被用于判断主服务器属下的所有从服务器，以及所有同样监视这个主服务器的其他<code>Sentinel</code>的<code>主观下线状态</code>。举个例子，如果用户向<code>Sentinel</code>设置了以下配置：    </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor master 127.0.0.1 6379 2</span><br><span class="line">sentinel down-after-milliseconds master 50000</span><br></pre></td></tr></table></figure>

<p>那么<code>50000毫秒</code>不仅会成为<code>Sentinel</code>判断<code>master</code>进入主观下线的标准，还会成为<code>Sentinel</code>判断<code>master属下</code>所有从服务器，以及所有同样监视<code>master</code>的其他<code>Sentinel</code>进入主观下线的标准。</p>
<p><strong><code>down-after-milliseconds</code>选项另一个需要注意的地方是，对于监视同一个主服务器的<code>多个Sentinel</code>来说，这些Sentinel所设置的<code>down-after-milliseconds</code>选项的值也可能不同，因此，当一个<code>Sentinel</code>将主服务器判断为主观下线时，其他<code>Sentinel</code>可能仍然会认为主服务器处于在线状态。</strong></p>
<h5 id="检测客观下线状态"><a href="#检测客观下线状态" class="headerlink" title="检测客观下线状态"></a>检测客观下线状态</h5><p>当<code>Sentinel</code>将一个主服务器判断为主观下线之后，为了确认这个主服务器是否真的下线了，它会向同样监视这一主服务器的其他<code>Sentinel</code>进行询问，看它们是否也认为主服务器已经进入了<code>下线状态</code>（可以是主观下线或者客观下线）。</p>
<p>当<code>Sentinel</code>从其他<code>Sentinel</code>那里接收到足够数量的已下线判断之后，<code>Sentinel</code>就会将从服务器判定为客观下线，并对主服务器执行<code>故障转移</code>操作。</p>
<ul>
<li><p>询问其他Sentinel是否同意主服务器已下线：</p>
<p>发送<code>SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt;</code>命令；</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709230707930.png" alt="image-20200709230707930"></p>
</li>
<li><p>接收<code>SENTINEL is-master-down-by-addr</code>命令：</p>
<p>当一个<code>Sentinel</code>（<code>目标Sentinel</code>）接收到另一个<code>Sentinel</code>（<code>源Sentinel</code>）发来的<code>SENTINEL is-master-down-by</code>命令时，<code>目标Sentinel</code>会分析并取出命令请求中包含的各个参数，并根据其中的<code>主服务器IP</code>和<code>端口号</code>，检查主服务器是否已下线，然后向<code>源Sentinel</code>返回一条<code>包含三个参数的Multi Bulk回复</code>作为SENTINEL is-master-down-by命令的回复：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709230551121.png" alt="image-20200709230551121"></p>
</li>
</ul>
<p>当认为主服务器已经进入下线状态的<code>Sentinel</code>的数量，超过<code>Sentinel</code>配置中设置的<code>quorum参数</code>的值，那么该<code>Sentinel</code>就会认为主服务器已经进入客观下线状态：<code>sentinel monitor master 127.0.0.1 6379 5</code></p>
<p>那么包括当前<code>Sentinel</code>在内，总共要有<code>五个Sentinel</code>都认为主服务器已经下线，当前<code>Sentinel</code>才会将主服务器判断为<code>客观下线</code>。</p>
<p>当然也存在每个Sentine的monitor配置quorum参数不一样，则会造成A认为已经下线，但是B认为还没下线。</p>
<p>当一个主服务器被判断为客观下线时，监视这个下线主服务器的各个Sentinel会进行协商，选举出一个<code>领头Sentinel</code>，并由<code>领头Sentinel</code>对下线主服务器执行<code>故障转移操作</code>。</p>
<h5 id="选举Sentinel-Leader"><a href="#选举Sentinel-Leader" class="headerlink" title="选举Sentinel Leader"></a>选举Sentinel Leader</h5><p>Raft算法；</p>
<p>《Redis设计与实现》 16.8</p>
<h5 id="Raft算法"><a href="#Raft算法" class="headerlink" title="Raft算法"></a>Raft算法</h5><h6 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h6><p>三种角色：</p>
<ul>
<li><strong>Candidate</strong>：</li>
<li><strong>Follower</strong>：</li>
<li><strong>Leader</strong>：</li>
</ul>
<h6 id="日志复制（Log-Replicate）"><a href="#日志复制（Log-Replicate）" class="headerlink" title="日志复制（Log Replicate）"></a>日志复制（Log Replicate）</h6><h6 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h6><h4 id="新的主服务器是怎样被挑选出来的？"><a href="#新的主服务器是怎样被挑选出来的？" class="headerlink" title="新的主服务器是怎样被挑选出来的？"></a>新的主服务器是怎样被挑选出来的？</h4><p><strong>选举</strong>：</p>
<ul>
<li>1）删除列表中所有<strong>处于下线或者断线状态</strong>的从服务器，这可以保证列表中剩余的从服务器都是正常在线的。（<code>状态正常</code>）</li>
<li>2）删除列表中所有<strong>最近五秒内没有回复过领头Sentinel的INFO命令的从服务器</strong>，这可以保证列表中剩余的从服务器都是最近成功进行过通信的。（<code>通信正常</code>）</li>
<li>3）删除所有与已下线主服务器连接断开超过<code>down-after-milliseconds*10毫秒</code>的从服务器：<code>down-after-milliseconds</code>选项指定了判断主服务器下线所需的时间，而删除断开时长超过<code>down-after-milliseconds*10毫秒</code>的从服务器，则可以保证列表中剩余的从服务器都没有过早地与主服务器断开连接，换句话说，列表中剩余的从服务器保存的数据都是比较新的。（<code>排序：优先级 -&gt; 复制偏移量offset -&gt; 运行ID runId</code>）<ul>
<li>之后，领头Sentinel将根据<code>从服务器的优先级</code>，对列表中剩余的从服务器进行<code>排序</code>，并选出其中<code>优先级最高的从服务器</code>。</li>
<li>如果有<strong>多个具有相同最高优先级的从服务器</strong>，那么<code>领头Sentinel</code>将按照从服务器的<code>复制偏移量（offeset）</code>，对具有相同最高优先级的所有从服务器进行排序，并选出其中<strong>偏移量最大的从服务器</strong>（复制偏移量最大的从服务器就是保存着最新数据的从服务器）。</li>
<li>最后，如果有<strong>多个优先级最高、复制偏移量最大的从服务器</strong>，那么领头Sentinel将按照<code>运行ID（runId）</code>对这些从服务器进行排序，并选出其中<code>运行ID（runId）最小</code>的从服务器。</li>
</ul>
</li>
</ul>
<h2 id="RedisCluster"><a href="#RedisCluster" class="headerlink" title="RedisCluster"></a>RedisCluster</h2><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708034042256.png" alt="image-20200708034042256"></p>
<h4 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708034116188.png" alt="image-20200708034116188"></p>
<p>Redis 集群中内置了 <code>16384</code> 个哈希槽。当客户端连接到 Redis 集群之后，会同时得到一份关于这个 <strong>集群的配置信息</strong>，当客户端具体对某一个 <code>key</code> 值进行操作时，会计算出它的一个 Hash 值，然后把结果对 <code>16384</code> <strong>求余数</strong>，这样每个 <code>key</code> 都会对应一个编号在 <code>0-16383</code> 之间的哈希槽，Redis 会根据节点数量 <strong>大致均等</strong> 的将哈希槽映射到不同的节点。</p>
<h4 id="内部数据结构"><a href="#内部数据结构" class="headerlink" title="内部数据结构"></a>内部数据结构</h4><p><code>ClusterNode</code>结构：</p>
<ul>
<li><code>clusterNode</code> 结构保存了 <strong>一个节点的当前状态</strong>，包括创建时间、节点 id、ip 和端口号等。</li>
<li>每个节点都会用一个 <code>clusterNode</code> 结构记录自己的状态，并为集群内所有其他节点都创建一个 <code>clusterNode</code> 结构来记录节点状态。</li>
</ul>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709233823043.png" alt="image-20200709233823043"></p>
<p><code>ClusterState</code>结构：</p>
<p><code>clusterState</code> 结构保存了在当前节点视角下，集群所处的状态。包括故障转移、槽迁移等。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709233945811.png" alt="image-20200709233945811"></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710012755077.png" alt="image-20200710012755077"></p>
<p>集群中执行命令：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710012717507.png" alt="image-20200710012717507"></p>
<p>计算属于哪个槽：<code>CRC(KEY) &amp; 16383;</code></p>
<ul>
<li>当节点发现键所在的槽并非由自己负责处理的时候，节点就会向客户端返回一个<code>MOVED</code>错误，指引客户端转向至正在负责槽的节点。例如：<code>MOVED 10086 127.0.0.1:7002</code> ；</li>
<li>当客户端接收到节点返回的<code>MOVED</code>错误时，客户端会根据<code>MOVED</code>错误中提供的<code>IP地址</code>和<code>端口号</code>，转向至负责处理<code>槽slot</code>的节点，并向该节点重新发送之前想要执行的命令。</li>
</ul>
<p>用<code>slots_to_keys</code>保存槽和键的关系：</p>
<p><code>slots_to_keys</code>跳跃表每个节点的分值（<code>score</code>）都是一个槽号，而每个节点的成员（<code>member</code>）都是一个数据库键：</p>
<ul>
<li>每当节点往数据库中添加一个新的键值对时，节点就会将这个键以及键的槽号关联到<code>slots_to_keys</code>跳跃表；</li>
<li>当节点删除数据库中的某个键值对时，节点就会在<code>slots_to_keys</code>跳跃表解除被删除键与槽号的关联。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">clusterState</span> &#123;</span></span><br><span class="line"> 	<span class="comment">// ...</span></span><br><span class="line">  zskiplist *slots_to_keys;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure>

<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710013155895.png" alt="image-20200710013155895"></p>
<h4 id="重新分片"><a href="#重新分片" class="headerlink" title="重新分片"></a>重新分片</h4><p><code>Redis集群</code>的重新分片操作可以将任意数量已经指派给<code>某个节点（源节点）</code>的槽改为指派给<code>另一个节点（目标节点）</code>，并且相关槽所属的键值对也会从源节点被移动到目标节点。</p>
<p>重新分片操作可以在线（online）进行，在重新分片的过程中，集群不需要下线，并且源节点和目标节点都可以继续处理命令请求。</p>
<h5 id="实现原理-2"><a href="#实现原理-2" class="headerlink" title="实现原理"></a>实现原理</h5><p>由Redis集群管理软件<code>redis-trib</code>负责，Redis提供了进行重新分片所需的所有命令，而<code>redis-trib</code>则通过向源节点和目标节点发送命令来进行重新分片操作。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710013629213.png" alt="image-20200710013629213"></p>
<img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710013644451.png" alt="image-20200710013644451" style="zoom:67%;" />



<h4 id="集群的故障转移"><a href="#集群的故障转移" class="headerlink" title="集群的故障转移"></a>集群的故障转移</h4><p>Redis集群中的节点分为<code>主节点（master）</code>和<code>从节点（slave）</code>，其中<strong>主节点用于处理槽</strong>，而<strong>从节点则用于复制某个主节点</strong>，并在被复制的主节点下线时，代替下线主节点继续处理命令请求。</p>
<h5 id="故障检测"><a href="#故障检测" class="headerlink" title="故障检测"></a>故障检测</h5><p>集群中的每个节点都会<strong>定期地向集群中的其他节点发送PING消息</strong>，以此来<strong>检测对方是否在线</strong>，如果接收PING消息的节点<strong>没有在规定的时间内，向发送PING消息的节点返回PONG消息</strong>，那么<code>发送PING消息的节点</code>就会将<code>接收PING消息的节点</code>标记为<code>疑似下线（probable fail，PFAIL）</code>。</p>
<p>集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点的状态信息，例如某个节点是处于<code>在线状态</code>、<code>疑似下线状态（PFAIL）</code>，还是<code>已下线状态（FAIL）</code>。</p>
<h5 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h5><p>当一个从节点发现自己正在复制的主节点进入了已下线状态时，从节点将开始对下线主节点进行故障转移，以下是故障转移的执行步骤：</p>
<p>1）复制下线主节点的所有从节点里面，会有一个从节点被选中。</p>
<p>2）被选中的从节点会执行<code>SLAVEOF no one</code>命令，成为新的主节点。</p>
<p>3）新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己。</p>
<p>4）新的主节点向集群<code>广播一条PONG消息</code>，这条<code>PONG消息</code>可以让集群中的其他节点立即知道<strong>这个节点已经由从节点变成了主节点</strong>，并且这个主节点已经接管了原本由已下线节点负责处理的槽。</p>
<p>5）新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。</p>
<h5 id="选举新节点"><a href="#选举新节点" class="headerlink" title="选举新节点"></a>选举新节点</h5><p>1）集群的配置纪元是一个<code>自增计数器</code>，它的初始值为0。</p>
<p>2）当集群里的某个节点开始一次故障转移操作时，集群<code>配置纪元的值会被增一</code>。</p>
<p>3）对于每个配置纪元，集群里每个负责处理槽的主节点都有一次投票的机会，而第一个向主节点要求投票的从节点将获得主节点的投票。</p>
<p>4）当从节点发现自己正在复制的主节点进入已下线状态时，从节点会向集群广播一条<code>CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST</code>消息，要求所有收到这条消息、并且具有投票权的主节点向这个从节点投票。</p>
<p>5）如果一个主节点具有投票权（它正在负责处理槽），并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条<code>CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK</code>消息，表示这个主节点支持从节点成为新的主节点。</p>
<p>6）每个参与选举的从节点都会接收<code>CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK</code>消息，并根据自己收到了多少条这种消息来统计自己获得了多少主节点的支持。</p>
<p>7）如果集群里有N个具有投票权的主节点，那么当一个从节点收集到<code>大于等于N/2+1</code>张支持票时，这个从节点就会当选为新的主节点。</p>
<p>8）因为在每一个配置纪元里面，每个具有投票权的主节点只能投一次票，所以如果有N个主节点进行投票，那么具有<code>大于等于N/2+1张支持票的从节点只会有一个</code>，这确保了新的主节点只会有一个。</p>
<p>9）如果在一个配置纪元里面没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，直到选出新的主节点为止。</p>
<h4 id="主要作用"><a href="#主要作用" class="headerlink" title="主要作用"></a>主要作用</h4><ul>
<li><strong>数据分区：</strong> 数据分区 <em>(或称数据分片)</em> 是集群最核心的功能。集群将数据分散到多个节点，<strong>一方面</strong> 突破了 Redis 单机内存大小的限制，<strong>存储容量大大增加</strong>；<strong>另一方面</strong> 每个主节点都可以对外提供读服务和写服务，<strong>大大提高了集群的响应能力</strong>。Redis 单机内存大小受限问题，在介绍持久化和主从复制时都有提及，例如，如果单机内存太大，<code>bgsave</code> 和 <code>bgrewriteaof</code> 的 <code>fork</code> 操作可能导致主进程阻塞，主从环境下主机切换时可能导致从节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能溢出……</li>
<li><strong>高可用：</strong> 集群支持主从复制和主节点的 <strong>自动故障转移</strong> <em>（与哨兵类似）</em>，当任一节点发生故障时，集群仍然可以对外提供服务。</li>
</ul>
<h4 id="分区方案"><a href="#分区方案" class="headerlink" title="分区方案"></a>分区方案</h4><ol>
<li><p><strong>方案一：哈希值 % 节点数</strong></p>
</li>
<li><p><strong>方案二：一致性哈希分区</strong></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708034627815.png" alt="image-20200708034627815"></p>
</li>
<li><p><strong>方案三：带有虚拟节点的一致性哈希分区</strong></p>
<p>该方案在 <strong>一致性哈希分区的基础上</strong>，引入了 <strong>虚拟节点</strong> 的概念。Redis 集群使用的便是该方案，其中的虚拟节点称为 <strong>槽（slot）</strong>。</p>
<p>槽是介于数据和实际节点之间的虚拟概念，每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据。</p>
<p>在使用了槽的一致性哈希分区中，<strong>槽是数据管理和迁移的基本单位</strong>。槽 <strong>解耦</strong> 了 <strong>数据和实际节点</strong> 之间的关系，增加或删除节点对系统的影响很小。仍以上图为例，系统中有 <code>4</code> 个实际节点，假设为其分配 <code>16</code> 个槽(0-15)；</p>
<ul>
<li>槽 0-3 位于 node1；4-7 位于 node2；以此类推….</li>
</ul>
<p>如果此时删除 <code>node2</code>，只需要将槽 4-7 重新分配即可，例如槽 4-5 分配给 <code>node1</code>，槽 6 分配给 <code>node3</code>，槽 7 分配给 <code>node4</code>；可以看出删除 <code>node2</code> 后，数据在其他节点的分布仍然较为均衡。</p>
</li>
</ol>
<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><h3 id="用途-3"><a href="#用途-3" class="headerlink" title="用途"></a>用途</h3><p>分布式锁，首先看分布式，分布式主要解决什么问题呢？</p>
<p>解决持久化数据太大，单个节点的硬盘无法存储的问题；解决运算量太大，单个节点的内存、CPU无法处理的问题。</p>
<h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s/gOYWLg3xYt4OhS46woN_Lg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/gOYWLg3xYt4OhS46woN_Lg</a></p>
</blockquote>
<h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><ul>
<li><strong>互斥性</strong>： 同一时刻只能有一个线程持有锁；</li>
<li><strong>可重入性</strong>： 同一节点上的同一个线程如果获取了锁之后能够再次获取锁；</li>
<li><strong>锁超时</strong>：和J.U.C中的锁一样支持锁超时，防止死锁；</li>
<li><strong>高性能和高可用</strong>： 加锁和解锁需要高效，同时也需要保证高可用，防止分布式锁失效；</li>
<li><strong>具备阻塞和非阻塞性</strong>：能够及时从阻塞状态中被唤醒；</li>
</ul>
<h3 id="SET-NX（普通锁）"><a href="#SET-NX（普通锁）" class="headerlink" title="SET NX（普通锁）"></a>SET NX（普通锁）</h3><p><code>setnx</code>和<code>expire</code>是分开的两步操作，<strong>不具有原子性</strong>，如果执行完第一条指令应用异常或者重启了，锁将无法过期。</p>
<p><strong>改善方案</strong>一：==使用Lua脚本来保证原子性（包含setnx和expire两条指令）==；</p>
<p><strong>改善方案二</strong>： <code>set key value [EX seconds][PX milliseconds][NX|XX]</code>；</p>
<ul>
<li>EX seconds: 设定过期时间，单位为秒</li>
<li>PX milliseconds: 设定过期时间，单位为毫秒</li>
<li>NX: 仅当key不存在时设置值</li>
<li>XX: 仅当key存在时设置值</li>
</ul>
<p><strong>问题</strong></p>
<blockquote>
<p>引自：<a href="https://juejin.im/post/5e6727e16fb9a07cc845b9ba" target="_blank" rel="noopener">https://juejin.im/post/5e6727e16fb9a07cc845b9ba</a></p>
</blockquote>
<ol>
<li><strong>单点问题。</strong>上面的实现只要一个master节点就能搞定，这里的单点指的是单master，就算是个集群，如果加锁成功后，锁从master复制到slave的时候挂了，也是会出现同一资源被多个client加锁的。</li>
<li><strong>执行时间超过了锁的过期时间。</strong>上面写到为了不出现一直上锁的情况，加了一个兜底的过期时间，时间到了锁自动释放，但是，如果在这期间任务并没有做完怎么办？由于GC或者网络延迟导致的任务时间变长，很难保证任务一定能在锁的过期时间内完成。</li>
</ol>
<h3 id="RedLock（redisson）"><a href="#RedLock（redisson）" class="headerlink" title="RedLock（redisson）"></a>RedLock（redisson）</h3><blockquote>
<p>引用：<a href="https://mp.weixin.qq.com/s/y_Uw3P2Ll7wvk_j5Fdlusw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/y_Uw3P2Ll7wvk_j5Fdlusw</a></p>
</blockquote>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710111524760.png" alt="image-20200710111524760"></p>
<p>如果客户端长期阻塞导致锁过期，那么它接下来访问共享资源就不安全了（没有了锁的保护）。显然，这样的问题在Redlock中是依然存在的。</p>
<h4 id="RedLock特点"><a href="#RedLock特点" class="headerlink" title="RedLock特点"></a>RedLock特点</h4><p><strong>（1）加锁机制</strong></p>
<p><strong>（2）锁互斥机制</strong></p>
<p><strong>（3）watch dog自动延期机制</strong></p>
<p><strong>（4）可重入加锁机制</strong></p>
<p><strong>（5）释放锁机制</strong></p>
<h4 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a><strong>解决的问题</strong></h4><p>单机锁的情况下，假如Redis节点宕机了，那么所有客户端就都无法获得锁了，服务变得不可用。<br>为了提高可用性，我们可以给这个<code>Redis</code>节点挂一个<code>Slave</code>，当<code>Master</code>节点不可用的时候，系统自动切到<code>Slave</code>上（<code>failover</code>）。<br>但由于Redis的主从复制（<code>replication</code>）是异步的，这可能导致在<code>failover</code>过程中丧失锁的安全性。</p>
<p>考虑下面的执行序列：</p>
<ol>
<li>客户端1从<code>Master</code>获取了锁。</li>
<li><code>Master</code>宕机了，存储锁的<code>key</code>还没有来得及同步到<code>Slave</code>上。</li>
<li><code>Slave</code>升级为<code>Master</code>。</li>
<li>客户端2从新的<code>Master</code>获取到了对应同一个资源的锁。</li>
</ol>
<h4 id="加解锁"><a href="#加解锁" class="headerlink" title="加解锁"></a><strong>加解锁</strong></h4><ul>
<li><p><strong>加锁</strong></p>
<ol>
<li>获取锁的操作有一个超时时间(<code>time out</code>)，它要远小于锁的有效时间（几十毫秒量级）。</li>
<li>向过半节点发送<code>setKey(key, value, nx=True, ex=xxx)</code>指令，只要过半节点set成功，则认为加锁成功，且不能超时。</li>
<li>客户端在向某个<code>Redis</code>节点获取锁失败以后，应该立即尝试下一个Redis节点。这里的失败，应该包含任何类型的失败。<br><strong>比如该<code>Redis</code>节点不可用，或者该<code>Redis</code>节点上的锁已经被其它客户端持有。</strong></li>
<li>如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去获取锁过程总消耗时间，计算出来的获取锁消耗的时间。</li>
<li>如果最终获取锁失败了（可能由于获取到锁的<code>Redis</code>节点个数少于<code>N/2+1</code>，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有<code>Redis</code>节点发起释放锁的操作。</li>
</ol>
</li>
<li><p><strong>解锁</strong></p>
<p>向所有节点发送del。</p>
</li>
</ul>
<h4 id="安全性影响"><a href="#安全性影响" class="headerlink" title="安全性影响"></a><strong>安全性影响</strong></h4><ul>
<li><p>问题：</p>
<p>假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列：</p>
<ol>
<li>客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）。</li>
<li>节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。</li>
<li>节点C重启后，客户端2锁住了C, D, E，获取锁成功。</li>
</ol>
<p>这样，客户端1和客户端2同时获得了锁（针对同一资源）。</p>
</li>
<li><p>在默认情况下，Redis的<code>AOF</code>持久化方式是每秒写一次磁盘（即执行fsync），因此最坏情况下可能丢失1秒的数据。<br>为了尽可能不丢数据，Redis允许设置成每次修改数据都进行<code>fsync</code>，但这会降低性能。当然，即使执行了<code>fsync</code>也仍然有可能丢失数据（这取决于系统而不是Redis的实现）。所以，上面分析的由于节点重启引发的锁失效问题，总是有可能出现的。</p>
</li>
</ul>
<p> 为了应对这一问题，antirez又提出了==<strong>延迟重启(delayed restarts)</strong>==的概念：<br>  <strong>也就是说，一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间(lock validity time)。这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。</strong></p>
<h4 id="可用条件"><a href="#可用条件" class="headerlink" title="可用条件"></a><strong>可用条件</strong></h4><ol>
<li>互斥性;</li>
<li>不会发生死锁；</li>
<li>容错性</li>
<li>加锁的释放锁</li>
</ol>
<h4 id="高并发场景下的问题"><a href="#高并发场景下的问题" class="headerlink" title="高并发场景下的问题"></a>高并发场景下的问题</h4><blockquote>
<p>引自：<a href="https://juejin.im/post/5e6727e16fb9a07cc845b9ba" target="_blank" rel="noopener">https://juejin.im/post/5e6727e16fb9a07cc845b9ba</a></p>
</blockquote>
<h5 id="性能问题"><a href="#性能问题" class="headerlink" title="==性能问题=="></a><strong>==性能问题==</strong></h5><ol>
<li><p><strong>获取锁的时间上</strong>。如果redlock运用在高并发的场景下，存在N个master节点，一个一个去请求，耗时会比较长，从而影响性能。这个好解决。</p>
<p>通过上面描述不难发现，从多个节点获取锁的操作并不是一个同步操作，可以是<strong>异步操作</strong>，这样可以<strong>多个节点同时获取</strong>。即使是<strong>并行处理</strong>的，还是得<strong>预估好获取锁的时间</strong>，保证<code>锁的TTL &gt; 获取锁的时间+任务处理时间</code>。</p>
</li>
<li><p><strong>被加锁的资源太大</strong>。加锁的方案本身就是会为了正确性而牺牲并发的，牺牲和资源大小成正比。这个时候可以考虑对资源做拆分，拆分的方式有两种：</p>
<ul>
<li><p><strong>从业务上将锁住的资源拆分成多段，每段分开加锁</strong>。比如，我要对一个商户做若干个操作，操作前要锁住这个商户，这时我可以将若干个操作拆成多个独立的步骤分开加锁，提高并发。</p>
</li>
<li><p><strong>用分桶的思想，将一个资源拆分成多个桶，一个加锁失败立即尝试下一个</strong>。</p>
<p>比如批量任务处理的场景，要处理<code>200w</code>个商户的任务，为了提高处理速度，用多个线程，每个线程取100个商户处理，就得给这100个商户加锁，如果不加处理，很难保证同一时刻两个线程加锁的商户没有重叠，这时可以按一个维度，比如某个标签，对商户进行分桶，然后一个任务处理一个分桶，处理完这个分桶再处理下一个分桶，减少竞争。</p>
</li>
</ul>
</li>
</ol>
<h5 id="重试的问题"><a href="#重试的问题" class="headerlink" title="==重试的问题=="></a><strong>==重试的问题==</strong></h5><p>无论是简单实现还是redlock实现，都会有重试的逻辑。如果直接按上面的算法实现，是会<strong>存在多个client几乎在同一时刻获取同一个锁，然后每个client都锁住了部分节点</strong>，但是没有一个client获取大多数节点的情况。</p>
<h6 id="解决的方案"><a href="#解决的方案" class="headerlink" title="解决的方案"></a><strong>解决的方案</strong></h6><p>在重试的时候让多个节点错开，错开的方式就是<strong>在重试时间中加一个随机时间</strong>。</p>
<h5 id="节点宕机"><a href="#节点宕机" class="headerlink" title="==节点宕机=="></a>==节点宕机==</h5><p>对于单master节点且没有做持久化的场景，宕机就挂了，这个就必须在实现上支持重复操作，自己做好幂等。</p>
<p>对于多master的场景，比如redlock，我们来看这样一个场景：</p>
<ol>
<li>假设有5个redis的节点：A、B、C、D、E，没有做持久化。</li>
<li>client1从A、B、C 3个节点获取锁成功，那么client1获取锁成功。</li>
<li>节点C挂了。</li>
<li>client2从C、D、E获取锁成功，<code>client2</code>也获取锁成功，那么在同一时刻<code>client1</code>和<code>client2</code>获取锁，<code>redlock</code>被玩坏了。</li>
</ol>
<h6 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h6><ul>
<li><p><strong>持久化</strong>：可以做到持久化每一条redis命令，但这对性能影响会很大，一般不会采用；</p>
</li>
<li><p><strong>延迟启动</strong>：就是一个节点挂了修复后，不立即加入，而是等待一段时间再加入，等待时间要大于宕机那一刻所有锁的最大TTL。</p>
<p>但这个方案依然<strong>不能解决问题</strong>，如果在上述<code>步骤3</code>中B和C都挂了呢，那么只剩A、D、E三个节点，从D和E获取锁成功就可以了，还是会出问题。</p>
<p>那么只能<code>增加master节点的总量</code>，缓解这个问题了。增加master节点会提高稳定性，但是也增加了成本，需要在两者之间权衡。</p>
</li>
</ul>
<h5 id="任务执行时间超过锁的TTL"><a href="#任务执行时间超过锁的TTL" class="headerlink" title="==任务执行时间超过锁的TTL=="></a>==任务执行时间超过锁的TTL==</h5><p><strong>锁过期</strong>，被多个线程执行的情况。 这个问题是所有分布式锁都要面临的问题，包括基于zookeeper和DB实现的分布式锁，这是锁过期了和client不知道锁过期了之间的矛盾。 在加锁的时候，我们一般都会<strong>给一个锁的TTL</strong>，这是为了<strong>防止加锁后client宕机</strong>，锁无法被释放的问题。</p>
<p><code>redisson</code>常用的加锁<code>api</code>有两个：</p>
<ul>
<li>一个是不传入<code>TTL</code>，这时是<code>redisson</code>自己维护，会主动续期（<code>internalLockLeaseTime=30s</code>，每隔10s续30s）；</li>
<li>另外一种是自己传入<code>TTL</code>，这种<code>redisson</code>就不会帮我们自动续期了，或者自己将<code>leaseTime</code>的值传成<code>-1</code>；</li>
</ul>
<p><strong>Martin Kleppmann</strong>提出问题：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710133901031.png" alt="image-20200710133901031"></p>
<h6 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h6><ol>
<li><p><strong>不设置TTL，而是在获取锁成功后，给锁加一个<code>watchdog</code></strong>，<code>watchdog</code>会起一个定时任务，在锁没有被释放且快要过期的时候会续期。</p>
<p>不过这种做法也无法百分百做到同一时刻只有一个client获取到锁，如果续期失败，比如发生了<strong>Martin Kleppmann</strong>所说的STW的GC，或者client和redis集群失联了，只要续期失败，就会造成同一时刻有多个client获得锁了。</p>
</li>
<li><p><strong>在客户端获取锁的同时，也获取到一个资源的token，这个token是单调递增的</strong>，每次在写资源时，都检查当前的token是否是较老的token，如果是就不让写。（Martin的解决方法）</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710134245283.png" alt="image-20200710134245283"></p>
<p>对于上面的场景，<code>Client1</code>获取锁的同时分配一个<code>33的token</code>，<code>Client2</code>获取锁的时候分配一个<code>34的token</code>，在<code>client1 GC</code>期间，<code>Client2</code>已经写了资源，这时<code>最大的token就是34</code>了，client1 从GC中回来，再带着33的token写资源时，会因为token过期被拒绝。这种做法<strong>需要资源那一边提供一个token生成器。</strong></p>
<p><strong>该方案问题</strong>：</p>
<ol>
<li><p><strong>无法保证事务。</strong>示意图中画的只有34访问了storage，但是在实际场景中，可能出现在一个任务内多次访问storage的情况，而且必须是原子的。如果client1带着33token在GC前访问过一次storage，然后发生了GC。</p>
<p>client2获取到锁，带着34的token也访问了storage，这时两个client写入的数据是否还能保证数据正确？如果不能，那么这种方案就有缺陷，除非storage自己有其他机制可以保证，比如事务机制；如果能，那么这里的token就是多余的，fencing的方案就是多此一举。</p>
</li>
<li><p><strong>高并发场景不实用。</strong></p>
<p>因为每次只有最大的token能写，这样storage的访问就是线性的，在高并发场景下，这种方式会极大的限制吞吐量，而分布式锁也大多是在这种场景下用的，很矛盾的设计。</p>
</li>
<li><p><strong>这是所有分布式锁的问题。</strong></p>
<p>这个方案是一个通用的方案，可以和Redlock用，也可以和其他的lock用。所以我理解仅仅是一个和Redlock无关的解决方案。</p>
</li>
</ol>
</li>
</ol>
<h5 id="系统时钟漂移"><a href="#系统时钟漂移" class="headerlink" title="==系统时钟漂移=="></a>==系统时钟漂移==</h5><p>redis的过期时间是依赖系统时钟的，如果<code>时钟漂移过大时会影响到过期时间的计算</code>。</p>
<h6 id="为什么系统时钟会存在漂移呢？"><a href="#为什么系统时钟会存在漂移呢？" class="headerlink" title="为什么系统时钟会存在漂移呢？"></a><strong>为什么系统时钟会存在漂移呢？</strong></h6><p>linux提供了两个系统时间：<code>clock realtime</code>和<code>clock monotonic</code>。</p>
<ul>
<li><p><code>clock realtime</code>也就是<code>xtime/wall time</code>，这个时间时可以被<code>用户改变</code>的，<code>被NTP改变</code>，<code>gettimeofday</code>拿的就是这个时间，<strong>redis的过期计算用的也是这个时间</strong>；</p>
</li>
<li><p><code>clock monotonic</code>，直译过来时单调时间，<strong>不会被用户改变</strong>，<strong>但是会被NTP改变</strong>。</p>
<blockquote>
<p><strong>“Network Time Protocol（NTP）是用来使计算机时间同步化的一种协议，它可以使计算机对其服务器或时钟源(如石英钟,GPS等等）做同步化，它可以提供高精准度的时间校正。</strong></p>
</blockquote>
</li>
</ul>
<p>最理想的情况时，<strong>所有系统的时钟都时时刻刻和NTP服务器保持同步</strong>，但这显然时不可能的。</p>
<p><strong>导致系统时钟漂移的原因有两个</strong>：</p>
<ul>
<li><p><strong>系统的时钟和NTP服务器不同步</strong>。这个目前没有特别好的解决方案，只能相信运维同学了。</p>
</li>
<li><p><code>clock realtime</code>被人为修改。在实现分布式锁时，不要使用<code>clock realtime</code>。不过很可惜，redis使用的就是这个时间，我看了下<a href="https://github.com/antirez/redis/blob/5.0/src/server.c#L425" target="_blank" rel="noopener">Redis 5.0源码</a>，使用的还是<code>clock realtime</code>。</p>
<p><strong>Antirez说过改成clock monotonic的，不过大佬还没有改。也就是说，人为修改redis服务器的时间，就能让redis出问题了。</strong></p>
</li>
</ul>
<h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a><strong>Zookeeper</strong></h3><p>基于<strong>临时顺序节点</strong>：</p>
<p>　　1.客户端调用<code>create()</code>方法创建名为“<code>locknode/guid-lock-</code>”的节点，需要注意的是，这里节点的创建类型需要设置为<code>EPHEMERAL_SEQUENTIAL</code>（临时顺序节点）。</p>
<p>　　2.客户端调用<code>getChildren(“locknode”)</code>方法来获取所有已经创建的子节点。</p>
<p>　　3.客户端获取到所有子节点<code>path</code>之后，如果发现自己在<code>步骤1</code>中创建的节点是所有节点中序号最小的，那么就认为这个客户端获得了锁。</p>
<p>　　4.如果<strong>创建的节点不是所有节点中序号最小的</strong>，那么则<strong>监视比自己创建节点的序列号小的最大的节点</strong>，进入等待。直到下次监视的子节点变更的时候，再进行子节点的获取，判断是否获取锁。</p>
<p>　　释放锁的过程相对比较简单，就是注册个监听器监听这个锁，释放锁就是删除这个znode，一旦释放掉就会通知客户端，然后有一个等待着的客户端就可以再次重新枷锁。</p>
<h4 id="如何保证一致性？"><a href="#如何保证一致性？" class="headerlink" title="如何保证一致性？"></a>如何保证一致性？</h4><p>通过ZAB协议保证，采用二阶段提交保证：</p>
<ul>
<li>客户端发送请求到任意Follower；</li>
<li>Follower将请求转发给Leader；</li>
<li>Leader采用二阶段提交，先发送Propose广播给Follower；</li>
<li>Follower接到Propose消息，写入日志成功后，返回ACK消息给Leader；</li>
<li>Leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * zk实现分布式锁</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZookeeperImproveLock</span> <span class="keyword">implements</span> <span class="title">Lock</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String LOCK_PATH=<span class="string">"/LOCK"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ZOOKEEPER_IP_PORT=<span class="string">"localhost:2181"</span>;</span><br><span class="line">    <span class="keyword">private</span> ZkClient client = <span class="keyword">new</span> ZkClient(ZOOKEEPER_IP_PORT,<span class="number">1000</span>,<span class="number">1000</span>,<span class="keyword">new</span> SerializableSerializer());</span><br><span class="line">    <span class="keyword">private</span> CountDownLatch cdl;</span><br><span class="line">    <span class="keyword">private</span> String beforePath; <span class="comment">// 当前请求的节点前一个节点</span></span><br><span class="line">    <span class="keyword">private</span> String currentPath; <span class="comment">// 当前请求的节点</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 判断有没有LOCK_PATH目录,没有则创建</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ZookeeperImproveLock</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(!<span class="keyword">this</span>.client.exists(LOCK_PATH))&#123;</span><br><span class="line">            <span class="keyword">this</span>.client.createPersistent(LOCK_PATH);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//非阻塞时加锁</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">//        如果currentpath为空则为第一次尝试加锁,第一次加锁赋值currentpath</span></span><br><span class="line">            <span class="keyword">if</span>(currentPath==<span class="keyword">null</span>||<span class="keyword">this</span>.client.getChildren(LOCK_PATH).size() &lt;=<span class="number">0</span>)&#123;</span><br><span class="line">    <span class="comment">//            创建一个临时顺序节点</span></span><br><span class="line">                currentPath = <span class="keyword">this</span>.client.createEphemeralSequential (LOCK_PATH + <span class="string">'/'</span>,<span class="string">"lock"</span>);</span><br><span class="line">                System.out.println(<span class="string">"创建一个临时节点---&gt;"</span>+currentPath);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//获取所有临时节点并排序,临时节点名称为自增长的字符串,如:00000000400</span></span><br><span class="line">            List&lt;String&gt; children = <span class="keyword">this</span>.client.getChildren(LOCK_PATH);</span><br><span class="line">            Collections.sort(children);</span><br><span class="line">            System.out.println(children.toString());</span><br><span class="line">            System.out.println(Thread.currentThread().getName()+ <span class="string">"get0---&gt;"</span>+ children.get(<span class="number">0</span>));</span><br><span class="line">            System.out.println(Thread.currentThread().getName()+<span class="string">"currentPath"</span>+ currentPath);</span><br><span class="line">            String realPath = LOCK_PATH+<span class="string">'/'</span>+children.get(<span class="number">0</span>);</span><br><span class="line">            System.out.println(Thread.currentThread().getName()+ <span class="string">"real---"</span>+ realPath);</span><br><span class="line">            <span class="keyword">if</span>(currentPath.equals(realPath))&#123;</span><br><span class="line">                System.out.println(Thread.currentThread().getName()+<span class="string">"成功啦---&gt;"</span> + currentPath);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">//如果当前节点在所有节点中排名不是第一,则获取前面的节点名称,并赋值给beforepath</span></span><br><span class="line"><span class="comment">//                int wz = 0;</span></span><br><span class="line"><span class="comment">//                if(children.contains(currentPath))&#123;</span></span><br><span class="line"><span class="comment">//                    wz = children.indexOf(currentPath);</span></span><br><span class="line"><span class="comment">//                &#125;</span></span><br><span class="line">                <span class="keyword">int</span> wz = Collections.binarySearch(children,currentPath.substring(<span class="number">6</span>));</span><br><span class="line">                beforePath = LOCK_PATH + <span class="string">'/'</span> + children.get(wz-<span class="number">1</span>);</span><br><span class="line">                System.out.println(Thread.currentThread().getName()+<span class="string">"beforePath"</span>+ beforePath);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (RuntimeException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(!tryLock())&#123;</span><br><span class="line">            System.out.println(<span class="string">"获取锁不成功---&gt;"</span> + currentPath);</span><br><span class="line">            waitForLock();</span><br><span class="line">            lock();</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            System.out.println(<span class="string">"获得分布式锁---&gt;"</span>+currentPath);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">waitForLock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        IZkDataListener listener = <span class="keyword">new</span> IZkDataListener() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleDataChange</span><span class="params">(String s, Object o)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleDataDeleted</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">if</span>(cdl != <span class="keyword">null</span>)&#123;</span><br><span class="line">                    System.out.println(<span class="string">"countdown"</span> + currentPath);</span><br><span class="line">                    cdl.countDown();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//给排在前面的节点增加数据删除的watcher</span></span><br><span class="line">        <span class="keyword">this</span>.client.subscribeDataChanges(beforePath,listener);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">this</span>.client.exists(beforePath))&#123;</span><br><span class="line">            cdl = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                cdl.await();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.client.unsubscribeDataChanges(beforePath,listener);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">lockInterruptibly</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> time, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//删除当前临时节点</span></span><br><span class="line">        <span class="keyword">this</span>.client.delete(currentPath);</span><br><span class="line">        System.out.println(<span class="string">"删除当前锁----&gt;"</span> + currentPath);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Condition <span class="title">newCondition</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><ul>
<li><p>redis分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能；</p>
<p>zk分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。</p>
</li>
<li><p>redis获取锁的那个客户端bug了或者挂了，那么只能等待超时时间之后才能释放锁；</p>
<p>而zk的话，因为创建的是临时znode，只要客户端挂了，znode就没了，此时就自动释放锁。</p>
</li>
</ul>
<h1 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h1><h3 id="ZSET"><a href="#ZSET" class="headerlink" title="ZSET"></a>ZSET</h3><h3 id="RateLimit"><a href="#RateLimit" class="headerlink" title="RateLimit"></a>RateLimit</h3><h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><h3 id="ZSET-1"><a href="#ZSET-1" class="headerlink" title="ZSET"></a><strong>ZSET</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ZADD KEY score member，压入集合</span><br><span class="line">ZRANGEBYSCORE，依据score获取成员</span><br></pre></td></tr></table></figure>

<p>在自己确定消息顺序ID时比较常用，使用<code>集合成员的Score</code>来作为<code>消息ID</code>，保证顺序，还可以保证消息ID的单调递增。</p>
<p>通常可以使用<code>时间戳+序号</code>的方案，确保了消息ID的单调递增，利用<code>SortedSet</code>的依据Score排序的特征，就可以制作一个有序的消息队列了。</p>
<h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><p>可以自定义消息ID，在消息ID有意义时，比较重要；</p>
<h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><p>不允许重复消息（因为是集合），同时消息ID确定有错误会导致消息的顺序出错。</p>
<h3 id="pub-sub订阅"><a href="#pub-sub订阅" class="headerlink" title="pub/sub订阅"></a><strong>pub/sub订阅</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SUBSCRIBE，用于订阅信道</span><br><span class="line">PUBLISH，向信道发送消息</span><br><span class="line">UNSUBSCRIBE，取消订阅</span><br></pre></td></tr></table></figure>

<p>生产者和消费者通过相同的一个<code>信道（Channel）</code>进行交互。信道其实也就是队列。</p>
<p>通常会有多个消费者。多个消费者订阅同一个信道，当生产者向信道发布消息时，该信道会立即将消息逐一发布给每个消费者。可见，<strong>该信道对于消费者是发散的信道，每个消费者都可以得到相同的消息。典型的对多的关系。</strong></p>
<h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4><ul>
<li>典型的<strong>广播模式</strong>，一个消息可以发布到多个消费者；</li>
<li><strong>多信道订阅</strong>，消费者可以同时订阅多个信道，从而接收多类消息；</li>
<li>消息即时发送，消息不用等待消费者读取，消费者会自动接收到信道发布的消息；</li>
<li>擅长处理广播，即时通讯，即时反馈的业务。</li>
</ul>
<h4 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li><p>消息一旦发布，不能接收。换句话就是发布时若客户端不在线，则<strong>消息丢失，不能寻回</strong>；</p>
</li>
<li><p><strong>不能保证每个消费者接收的时间是一致的</strong>；</p>
</li>
<li><p><strong>若消费者客户端出现消息积压，到一定程度，会被强制断开，导致消息意外丢失</strong>。</p>
<p>通常发生在消息的生产远大于消费速度时；</p>
</li>
<li><p><strong>没有ACK机制，不保证数据连续性</strong>；</p>
</li>
<li><p><strong>不能持久化消息</strong>。</p>
</li>
</ul>
<h3 id="List（LPUSH-BRPOP-BLPOP）"><a href="#List（LPUSH-BRPOP-BLPOP）" class="headerlink" title="List（LPUSH+BRPOP/BLPOP）"></a><strong>List（LPUSH+BRPOP/BLPOP）</strong></h3><h1 id="通信"><a href="#通信" class="headerlink" title="通信"></a>通信</h1><h3 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h3><p><strong>节点间通信</strong>，按照通信协议可以分为几种类型：<code>单对单</code>、<code>广播</code>、<code>Gossip 协议</code>等。重点是广播和 Gossip 的对比。</p>
<ul>
<li><strong>广播是指向集群内所有节点发送消息</strong>。<strong>优点</strong> 是集群的收敛速度快(集群收敛是指集群内所有节点获得的集群信息是一致的)，<strong>缺点</strong> 是每条消息都要发送给所有节点，CPU、带宽等消耗较大。</li>
<li><strong>Gossip 协议</strong>的特点是：<strong>在节点数量有限的网络中，每个节点都 “随机” 的与部分节点通信</strong> <em>（并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。</em></li>
<li><strong>Gossip 协议的优点</strong> ：<ul>
<li><em>负载 (比广播)</em> 低；</li>
<li>去中心化；</li>
<li>容错性高 <em>(因为通信有冗余)</em> 等；</li>
</ul>
</li>
<li><strong>Gossip 协议的缺点</strong>：主要是集群的收敛速度慢。</li>
</ul>
<h4 id="消息类型"><a href="#消息类型" class="headerlink" title="消息类型"></a>消息类型</h4><ul>
<li><p><strong>MEET 消息：</strong> </p>
<p>在节点握手阶段，当节点收到客户端的 <code>CLUSTER MEET</code> 命令时，会向新加入的节点发送 <code>MEET</code> 消息，请求新节点加入到当前集群；新节点收到 MEET 消息后会回复一个 <code>PONG</code> 消息。</p>
</li>
<li><p><strong>PING 消息：</strong> </p>
<p>集群里每个节点每秒钟会选择部分节点发送 <code>PING</code> 消息，接收者收到消息后会回复一个 <code>PONG</code> 消息。<strong>PING 消息的内容是自身节点和部分其他节点的状态信息</strong>，作用是彼此交换信息，以及检测节点是否在线。<code>PING</code> 消息使用 Gossip 协议发送，接收节点的选择兼顾了收敛速度和带宽成本，<strong>具体规则如下</strong>：(1)随机找 5 个节点，在其中选择最久没有通信的 1 个节点；(2)扫描节点列表，选择最近一次收到 <code>PONG</code> 消息时间大于 <code>cluster_node_timeout / 2</code> 的所有节点，防止这些节点长时间未更新。</p>
</li>
<li><p><strong>PONG消息：</strong> </p>
<p><code>PONG</code> 消息封装了自身状态数据。可以分为两种：<strong>第一种</strong> 是在接到 <code>MEET/PING</code> 消息后回复的 <code>PONG</code> 消息；<strong>第二种</strong> 是指节点向集群广播 <code>PONG</code> 消息，这样其他节点可以获知该节点的最新信息，例如故障恢复后新的主节点会广播 <code>PONG</code> 消息。</p>
</li>
<li><p><strong>FAIL 消息：</strong></p>
<p>当一个主节点判断另一个主节点进入 <code>FAIL</code> 状态时，会向集群广播这一 <code>FAIL</code> 消息；接收节点会将这一 <code>FAIL</code> 消息保存起来，便于后续的判断。</p>
</li>
<li><p><strong>PUBLISH 消息：</strong> </p>
<p>节点收到 <code>PUBLISH</code> 命令后，会先执行该命令，然后向集群广播这一消息，接收节点也会执行该 <code>PUBLISH</code> 命令。</p>
</li>
</ul>
<h3 id="客户端通信（RESP）"><a href="#客户端通信（RESP）" class="headerlink" title="客户端通信（RESP）"></a>客户端通信（RESP）</h3><p><code>RESP</code>是<code>Redis序列化协议</code>，Redis客户端RESP协议与Redis服务器通信。</p>
<p>Redis协议在以下几点之间做出了折衷：</p>
<ul>
<li>简单的实现</li>
<li>快速地被计算机解析</li>
<li>简单得可以能被人工解析</li>
<li>是二进制安全的</li>
<li>使用TCP</li>
</ul>
<p>RESP有五种最小的单元类型，单元结束时统一加上回车换行符号<code>\r\n</code>：</p>
<ul>
<li>单行字符串 以<code>+ 符号</code>开头；</li>
<li>多行字符串 以<code>$ 符号</code>开头，后跟字符串长度；</li>
<li>整数值 以<code>: 符号</code>开头，后跟整数的字符串形式；</li>
<li>错误消息 以 <code>- 符号</code>开头。；</li>
<li>数组 以 <code>* 号</code>开头，后跟数组的长度。</li>
</ul>
<h4 id="客户端-gt-服务端"><a href="#客户端-gt-服务端" class="headerlink" title="客户端 -&gt; 服务端"></a>客户端 -&gt; 服务端</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set author codehole</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> RESP序列化后</span></span><br><span class="line">*3\r\n$3\r\nset\r\n$6\r\nauthor\r\n$8\r\ncodehole\r\n</span><br></pre></td></tr></table></figure>



<h4 id="服务器-gt-客户端"><a href="#服务器-gt-客户端" class="headerlink" title="服务器 -&gt; 客户端"></a>服务器 -&gt; 客户端</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">OK</span><br><span class="line"></span><br><span class="line">+ok\r\n</span><br></pre></td></tr></table></figure>

<h1 id="事件机制（Reactor）"><a href="#事件机制（Reactor）" class="headerlink" title="事件机制（Reactor）"></a>事件机制（Reactor）</h1><blockquote>
<p>参考：<a href="http://www.web-lovers.com/redis-source-ae.html" target="_blank" rel="noopener">http://www.web-lovers.com/redis-source-ae.html</a></p>
</blockquote>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><p><code>Redis</code>通过<code>MULTI</code>、<code>EXEC</code>、<code>WATCH</code>等命令来实现事务（<code>transaction</code>）功能。</p>
<p>事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求。</p>
<img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710014826164.png" alt="image-20200710014826164" style="zoom: 50%;" />

<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>一个事务从开始到结束通常会经历以下三个阶段：</p>
<p>1）事务开始。（<code>MULTI</code>）</p>
<p>2）命令入队。</p>
<img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710015053803.png" alt="image-20200710015053803" style="zoom:50%;" />

<ul>
<li><p>如果客户端发送的命令为<code>EXEC</code>、<code>DISCARD</code>、<code>WATCH</code>、<code>MULTI</code>四个命令的其中一个，那么服务器立即执行这个命令。</p>
</li>
<li><p>与此相反，如果客户端发送的命令是<code>EXEC</code>、<code>DISCARD</code>、<code>WATCH</code>、<code>MULTI</code>四个命令以外的其他命令，那么服务器并不立即执行这个命令，而是将这个命令放入一个事务队列里面，然后向客户端返回<code>QUEUED</code>回复。</p>
</li>
</ul>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710015218880.png" alt="image-20200710015218880"></p>
<ul>
<li><p>最先入队的SET命令被放在了事务队列的<code>索引0</code>位置上。</p>
</li>
<li><p>第二入队的GET命令被放在了事务队列的<code>索引1</code>位置上。</p>
</li>
<li><p>第三入队的另一个SET命令被放在了事务队列的<code>索引2</code>位置上。</p>
</li>
<li><p>最后入队的另一个GET命令被放在了事务队列的<code>索引3</code>位置上。</p>
<p>3）事务执行。</p>
</li>
</ul>
<p><code>EXEC</code>实现原理：</p>
<ol>
<li>创建空白回复队列；</li>
<li>遍历事务中的每个项，读取命令参数、个数、执行的命令cmd；</li>
<li>循环执行命令，并且将返回值追加到回复队列尾部；</li>
<li>移除REDIS_MULTI标识，让客户端回到非事务状态；</li>
<li>清空客户端事务状态：<ul>
<li>清零入队命令计数器；</li>
<li>释放事务队列；</li>
</ul>
</li>
<li>返回回复队列；</li>
</ol>
<h3 id="WATCH"><a href="#WATCH" class="headerlink" title="WATCH"></a>WATCH</h3><p><code>WATCH</code>命令是一个<code>乐观锁（optimistic locking）</code>，它可以在<code>EXEC</code>命令执行之前，监视任意数量的数据库键，并在<code>EXEC</code>命令执行时，检查被监视的键是否至少有一个已经被修改过了，如果是的话，服务器将拒绝执行事务，并向客户端返回代表事务执行失败的空回复。</p>
<h4 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h4><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710015912795.png" alt="image-20200710015912795" style="zoom: 50%;" />

<p>通过<code>watched_keys</code>字典，服务器可以清楚地知道哪些数据库键正在被监视，以及哪些客户端正在监视这些数据库键。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WATCH "name" "age" "address"</span><br></pre></td></tr></table></figure>

<img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710020201466.png" alt="image-20200710020201466" style="zoom: 67%;" />

<ul>
<li><code>客户端c1</code>和<code>c2</code>正在监视键”name”。</li>
<li><code>客户端c3</code>正在监视键”age”。</li>
<li><code>客户端c2</code>和<code>c4</code>正在监视键”address”。</li>
</ul>
<p><strong>触发监视机制</strong>（<code>WATCH</code>）：</p>
<p>所有对数据库进行修改的命令，比如<code>SET</code>、<code>LPUSH</code>、<code>SADD</code>、<code>ZREM</code>、<code>DEL</code>、<code>FLUSHDB</code>等等，在执行之后都会调用<code>multi.c/touchWatchKey函数</code>对<code>watched_keys</code>字典进行检查，查看是否有客户端正在监视刚刚被命令修改过的数据库键，如果有的话，那么<code>touchWatchKey</code>函数会将监视被修改键的客户端的<code>REDIS_DIRTY_CAS标识</code>打开，<strong>表示该客户端的事务安全性已经被破坏。</strong></p>
<p><code>touchWatchKey</code>原理：</p>
<ul>
<li>如果key存在当前数据库的<code>watched_keys</code>字典中，那么说明至少有一个客户端在监视这个key；</li>
<li>遍历所有监视key的客户端，并打开<code>REDIS_DIRTY_CAS</code>标识；</li>
</ul>
<p><strong>判断是否事务安全：</strong></p>
<p>当服务器接收到一个客户端发来的<code>EXEC</code>命令时，服务器会根据这个客户端是否打开了<code>REDIS_DIRTY_CAS</code>标识来决定是否执行事务：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710020823998.png" alt="image-20200710020823998"></p>
<ul>
<li>如果客户端的<code>REDIS_DIRTY_CAS</code>标识已经被打开，那么说明客户端所监视的键当中，至少有一个键已经被修改过了，在这种情况下，客户端提交的事务已经<code>不再安全</code>，所以<code>服务器会拒绝执行客户端提交的事务</code>。</li>
<li>如果客户端的<code>REDIS_DIRTY_CAS</code>标识没有被打开，那么说明客户端监视的所有键都没有被修改过（或者客户端没有监视任何键），事务<code>仍然是安全的</code>，服务器将执行客户端提交的这个事务。</li>
</ul>
<h1 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h1><p>面试问题：</p>
<p><a href="https://www.cnblogs.com/wmyskxz/p/12568926.html#_label2_1" target="_blank" rel="noopener">https://www.cnblogs.com/wmyskxz/p/12568926.html#_label2_1</a></p>
<p><a href="https://mp.weixin.qq.com/s/DHTPSfmWTZpdTmlytzLz1g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/DHTPSfmWTZpdTmlytzLz1g</a></p>
<p><a href="https://juejin.im/post/5dd09f5af265da0be72aacbd" target="_blank" rel="noopener">https://juejin.im/post/5dd09f5af265da0be72aacbd</a></p>
<p><a href="https://www.wmyskxz.com/2020/03/25/dong-yi-dian-python-xi-lie-kuai-su-ru-men-1/" target="_blank" rel="noopener">https://www.wmyskxz.com/2020/03/25/dong-yi-dian-python-xi-lie-kuai-su-ru-men-1/</a></p>
<h2 id="1）Redis为什么那么快？"><a href="#1）Redis为什么那么快？" class="headerlink" title="1）Redis为什么那么快？"></a>1）Redis为什么那么快？</h2><h3 id="I-O多路复用"><a href="#I-O多路复用" class="headerlink" title="I/O多路复用"></a>I/O多路复用</h3><ul>
<li><p>epoll</p>
</li>
<li><p>select</p>
</li>
<li><p>evport</p>
</li>
<li><p>kqueue</p>
</li>
</ul>
<p>  Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于<strong>读写操作等待用户输入或输出都是阻塞的</strong>，所以 I/O 操作在一般情况下往往不能直接返回，这会导致<strong>某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务</strong>，而 <strong>I/O 多路复用</strong>就是为了解决这个问题而出现的。</p>
<h4 id="Blocking-I-O（I-O阻塞模型）"><a href="#Blocking-I-O（I-O阻塞模型）" class="headerlink" title="* Blocking I/O（I/O阻塞模型）"></a>* Blocking I/O（I/O阻塞模型）</h4><p>当使用 <code>read</code> 或者 <code>write</code> 对某一个<strong>文件描述符（File Descriptor 以下简称 FD)</strong>进行读写时，如果当前 FD 不可读或不可写，整个 Redis 服务就不会对其它的操作作出响应，导致整个服务不可用。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707201559.jpg" alt="blocking-io-image"></p>
<h4 id="I-O-多路复用"><a href="#I-O-多路复用" class="headerlink" title="* I/O 多路复用"></a>* I/O 多路复用</h4><p><img src="http://qd2x6jysb.bkt.clouddn.com/prefix_20200707201809.jpg" alt="io-muliti-image"></p>
<p>​    </p>
<h3 id="内存操作"><a href="#内存操作" class="headerlink" title="内存操作"></a>内存操作</h3><h4 id="命令操作时是单线程操作，提高效率"><a href="#命令操作时是单线程操作，提高效率" class="headerlink" title="命令操作时是单线程操作，提高效率"></a>命令操作时是单线程操作，提高效率</h4><h4 id="大量数据结构上的优化（SDS、ZipList、Dict等）"><a href="#大量数据结构上的优化（SDS、ZipList、Dict等）" class="headerlink" title="大量数据结构上的优化（SDS、ZipList、Dict等）"></a>大量数据结构上的优化（SDS、ZipList、Dict等）</h4><h4 id="自己的VM模型"><a href="#自己的VM模型" class="headerlink" title="自己的VM模型"></a>自己的VM模型</h4><p>redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</p>
<h2 id="2）缓存穿透、缓存雪崩、缓存击穿及处理方式？"><a href="#2）缓存穿透、缓存雪崩、缓存击穿及处理方式？" class="headerlink" title="2）缓存穿透、缓存雪崩、缓存击穿及处理方式？"></a>2）缓存穿透、缓存雪崩、缓存击穿及处理方式？</h2><blockquote>
<p><a href="https://mp.weixin.qq.com/s/3Fmv7h5p2QDtLxc9n1dp5A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/3Fmv7h5p2QDtLxc9n1dp5A</a></p>
</blockquote>
<h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709232449867.png" alt="image-20200709232449867"></p>
<p>缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>利用<strong>互斥锁</strong>，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试；</li>
<li><strong>采用异步更新策略</strong>，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作；</li>
<li><strong>缓存空对象</strong>；</li>
<li>提供一个能迅速判断请求是否有效的<strong>拦截机制</strong>，比如，利用<strong>布隆过滤器</strong>，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。</li>
</ul>
<h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709232428621.png" alt="image-20200709232428621"></p>
<pre><code>缓存雪崩是指，缓存层出现了错误，不能正常工作了。于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。</code></pre><p><strong>解决方案</strong>：</p>
<ul>
<li><strong>给缓存的失效时间</strong><br>加上一个随机值，避免集体失效。</li>
<li><strong>使用互斥锁</strong><br>但是该方案吞吐量明显下降了。</li>
<li><strong>双缓存（高可用）</strong><br>我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点：<ul>
<li>从缓存A读数据库，有则直接返回；</li>
<li>A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程；</li>
<li>更新线程同时更新缓存A和缓存B；</li>
</ul>
</li>
<li><strong>数据预热</strong></li>
</ul>
<h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>  缓存击穿，就是某个热点数据失效时，大量针对这个数据的请求会穿透到数据源。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>可以使用互斥锁更新，保证同一个进程中针对同一个数据不会并发请求到 DB，减小 DB 压力。</li>
<li>使用随机退避方式，失效时随机 <code>sleep</code> 一个很短的时间，再次查询，如果失败再执行更新。</li>
<li>针对多个热点 key 同时失效的问题，可以在缓存时使用固定时间加上一个小的随机数，避免大量热点 key 同一时刻失效。</li>
</ul>
<h2 id="3）数据库缓存双写一致性？"><a href="#3）数据库缓存双写一致性？" class="headerlink" title="3）数据库缓存双写一致性？"></a>3）数据库缓存双写一致性？</h2><blockquote>
<p><a href="https://www.cnblogs.com/rjzheng/p/9041659.html" target="_blank" rel="noopener">https://www.cnblogs.com/rjzheng/p/9041659.html</a></p>
</blockquote>
<h3 id="先更新数据库，再更新"><a href="#先更新数据库，再更新" class="headerlink" title="先更新数据库，再更新"></a>先更新数据库，再更新</h3><ul>
<li><p><strong>原因一（线程安全角度）</strong></p>
<p>同时有请求A和请求B进行更新操作，那么会出现：</p>
<p>（1）线程A更新了数据库</p>
<p>（2）线程B更新了数据库</p>
<p>（3）线程B更新了缓存</p>
<p>（4）线程A更新了缓存</p>
<p>这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。</p>
</li>
<li><p><strong>原因二（业务场景角度）</strong></p>
<p>有如下两点：</p>
<p>（1）如果你是一个<code>写数据库场景比较多</code>，而<code>读数据场景比较少</code>的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。</p>
<p>（2）如果你<code>写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存</code>。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。</p>
</li>
</ul>
<h3 id="先删除缓存，再更新数据库"><a href="#先删除缓存，再更新数据库" class="headerlink" title="先删除缓存，再更新数据库"></a>先删除缓存，再更新数据库</h3><p>该方案会导致不一致的原因是：</p>
<p><strong>同时有一个请求A进行更新操作，另一个请求B进行查询操作。</strong></p>
<p>那么会出现如下情形：</p>
<p>（1）请求A进行写操作，删除缓存；</p>
<p>（2）请求B查询发现缓存不存在；</p>
<p>（3）请求B去数据库查询得到旧值；</p>
<p>（4）请求B将旧值写入缓存；</p>
<p>（5）请求A将新值写入数据库；</p>
<p>采用<strong><code>延时双删策略</code></strong>解决：</p>
<p>（1）先淘汰缓存</p>
<p>（2）再写数据库（这两步和原来一样）</p>
<p>（3）休眠1秒，再次淘汰缓存</p>
<p>这么做，可以将1秒内所造成的缓存脏数据，再次删除。</p>
<h3 id="先更新数据库，再删除缓存"><a href="#先更新数据库，再删除缓存" class="headerlink" title="先更新数据库，再删除缓存"></a>先更新数据库，再删除缓存</h3><h4 id="Cache-Aside-Pattern"><a href="#Cache-Aside-Pattern" class="headerlink" title="Cache Aside Pattern"></a><strong>Cache Aside Pattern</strong></h4><p><strong>失效</strong>：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。</p>
<p><strong>命中</strong>：应用程序从cache中取数据，取到后返回。</p>
<p><strong>更新</strong>：先把数据存到数据库中，成功后，再让缓存失效。</p>
<h4 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a><strong>问题</strong></h4><h5 id="一、并发脏数据问题"><a href="#一、并发脏数据问题" class="headerlink" title="一、并发脏数据问题"></a>一、并发脏数据问题</h5><p>（1）缓存刚好失效</p>
<p>（2）请求A查询数据库，得一个旧值</p>
<p>（3）请求B将新值写入数据库</p>
<p>（4）请求B删除缓存</p>
<p>（5）请求A将查到的旧值写入缓存</p>
<p>如果发生上述情况，确实是会发生脏数据。</p>
<p>解决：</p>
<p>上述并发问题发生的几率很小，因为在操作DB时，读大部分情况下比写快。</p>
<p>首先，给缓存设有效时间是一种方案。其次，采用异步延时删除策略，保证读请求完成以后，再进行删除操作。</p>
<h5 id="二、如果删缓存失败了怎么办，那不是会有不一致的情况出现么？"><a href="#二、如果删缓存失败了怎么办，那不是会有不一致的情况出现么？" class="headerlink" title="二、如果删缓存失败了怎么办，那不是会有不一致的情况出现么？"></a>二、如果删缓存失败了怎么办，那不是会有不一致的情况出现么？</h5><p>比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。</p>
<p>解决方案：</p>
<h6 id="1）侵入代码的重试机制"><a href="#1）侵入代码的重试机制" class="headerlink" title="1）侵入代码的重试机制"></a><strong>1）侵入代码的重试机制</strong></h6><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709143640239.png" alt="image-20200709143640239"></p>
<p><strong>缺点</strong>：侵入太多业务代码。</p>
<h6 id="2）监听binlog的异步重试机制"><a href="#2）监听binlog的异步重试机制" class="headerlink" title="2）监听binlog的异步重试机制"></a><strong>2）监听binlog的异步重试机制</strong></h6><p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709143722834.png" alt="image-20200709143722834"></p>
<p>① 更新数据库数据；</p>
<p>② 数据库会将操作信息写入<code>binlog日志</code>当中；</p>
<p>③ 订阅程序提取出所需要的<code>数据以及key</code>；</p>
<p>④ 另起一段非业务代码，获得该信息；</p>
<p>⑤ 尝试删除缓存操作，发现删除失败；</p>
<p>⑥ 将这些信息发送至消息队列；</p>
<p>⑦ 重新从消息队列中获得该数据，重试操作。</p>
<p>备注说明：</p>
<p>上述的订阅<code>binlog</code>程序在mysql中有现成的中间件叫<code>canal</code>，可以完成<code>订阅binlog日志</code>的功能。</p>
<h2 id="4）BigKey问题？"><a href="#4）BigKey问题？" class="headerlink" title="4）BigKey问题？"></a>4）BigKey问题？</h2><h4 id="什么是bigkey？"><a href="#什么是bigkey？" class="headerlink" title="什么是bigkey？"></a><strong>什么是bigkey？</strong></h4><p>字符串类型：它的big体现在单个value值很大，一般认为<code>超过10KB就是bigkey</code>。</p>
<p>非字符串类型：哈希、列表、集合、有序集合，它们的big体现在<code>元素个数太多</code>。</p>
<h4 id="如何发现？"><a href="#如何发现？" class="headerlink" title="如何发现？"></a><strong>如何发现？</strong></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --bigkeys</span><br></pre></td></tr></table></figure>

<p>要查询Redis里大于5000的所有key：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">debug object $&#123;key&#125;命令</span><br></pre></td></tr></table></figure>

<ol>
<li>建议在从节点执行，因为<code>--bigkeys</code>也是通过<code>scan</code>完成的。</li>
<li>建议在节点本机执行，这样可以减少网络开销。</li>
<li>如果没有从节点，可以使用<code>--i</code>参数，例如(<code>--i 0.1</code>代表100毫秒执行一次)；</li>
<li><code>--bigkeys</code>只能计算每种数据结构的top1，如果有些数据结构非常多<code>的bigkey</code>，也搞不定。</li>
</ol>
<h4 id="危害？"><a href="#危害？" class="headerlink" title="危害？"></a>危害？</h4><ul>
<li><strong>内存空间不均匀</strong>：这样会不利于集群对内存的统一管理，存在丢失数据的隐患；</li>
<li><strong>超时阻塞</strong>：由于Redis单线程的特性，操作bigkey的通常比较耗时，也就意味着阻塞Redis可能性越大，这样会造成客户端阻塞或者引起故障切换，它们通常出现在慢查询中；</li>
<li><strong>网络拥塞</strong>：<code>bigkey</code>也就意味着每次获取要产生的网络流量较大，假设一个<code>bigkey</code>为<code>1MB</code>，客户端每秒访问量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡（按照字节算是128MB/s）的服务器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey可能会对其他实例造成影响；</li>
<li><strong>迁移困难</strong>：当需要对bigkey进行迁移（例如Redis cluster的迁移slot），实际上是通过<code>migrate命令</code>来完成的，<code>migrate</code>实际上是通过<code>dump + restore + del</code>三个命令组合成原子命令完成，如果是<code>bigkey</code>，可能会使迁移失败，而且<code>较慢的migrate会阻塞Redis</code>。</li>
</ul>
<p><strong>注：</strong></p>
<ul>
<li><p><code>string类型</code>控制在<code>10KB</code>以内，<code>hash</code>、<code>list</code>、<code>set</code>、<code>zset</code>元素个数不要超过<code>5000</code>。</p>
</li>
<li><p>非字符串的<code>bigkey</code>，不要使用<code>del</code>删除，使用hscan、sscan、zscan方式渐进式删除；<br>同时要注意防止bigkey过期时间自动删除问题（例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会出现在慢查询中（latency可查））</p>
</li>
</ul>
<h2 id="5）消息队列实现？"><a href="#5）消息队列实现？" class="headerlink" title="5）消息队列实现？"></a>5）消息队列实现？</h2><ul>
<li>ZSet实现</li>
<li>Stream实现</li>
<li>Pub/Sub实现</li>
<li>List实现</li>
</ul>
<h2 id="6）Key如何存储的？"><a href="#6）Key如何存储的？" class="headerlink" title="6）Key如何存储的？"></a>6）Key如何存储的？</h2><p>在 Redis 中所有的 key 都存储在一个很大的字典中，这个字典的结构和 Java 中的 HashMap 一样，是<code>一维数组 + 二维链表</code>结构，第一维数组的大小总是 <code>2^n(n&gt;=0)</code>，扩容一次数组大小空间加倍，也就是 <code>n++</code>。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709150825607.png" alt="image-20200709150825607"></p>
<ul>
<li><code>scan 指令</code>返回的<code>游标</code>就是第一维数组的位置索引，我们将这个位置索引称为<code>槽 (slot)</code>。</li>
<li>如果不考虑字典的扩容缩容，直接按数组下标挨个遍历就行了。</li>
<li><code>limit 参数</code>就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。</li>
<li>每一次遍历都会将<code>limit 数量的槽位</code>上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。</li>
</ul>
<h4 id="渐进式rehash-1"><a href="#渐进式rehash-1" class="headerlink" title="渐进式rehash"></a>渐进式rehash</h4><ul>
<li>会同时保留旧数组和新数组，然后在定时任务中以及后续对 hash 的指令操作中渐渐地将旧数组中挂接的元素迁移到新数组上。</li>
<li>这意味着要操作处于 rehash 中的字典，需要同时访问新旧两个数组结构。如果在旧数组下面找不到元素，还需要去新数组下面去寻找。</li>
</ul>
<h2 id="7）热Key问题？"><a href="#7）热Key问题？" class="headerlink" title="7）热Key问题？"></a>7）热Key问题？</h2><h2 id="8）redis删除很多key-内存不减少的原因？"><a href="#8）redis删除很多key-内存不减少的原因？" class="headerlink" title="8）redis删除很多key, 内存不减少的原因？"></a>8）redis删除很多key, 内存不减少的原因？</h2><p><strong>问题：</strong></p>
<p>redis内部的<code>used_memory</code>使用量已经下降到2.05G了，但是<code>used_memory_rss</code>（redis在系统中进程占用的内存量）并未降低。</p>
<p><strong>解决方案：</strong></p>
<p>定义了<code>maxmemory</code>后，并且定义了<code>maxmemory_policy</code>，那么即使内存满了，redis也会按照淘汰机制方案，清除一些不需要的key，来存放新的key。</p>
<p>倘若影响到系统内存使用了，则：</p>
<ol>
<li><p><strong>可以通过 <code>MEMORY PURGE</code>命令进行内存整理。（瞬时，能稍微腾出rss内存空间）</strong></p>
</li>
<li><p><strong>开启<code>activedefrag</code>，热碎片整理。（会占用CPU，在主线程执行，可以设置CPU占用率）</strong></p>
</li>
<li><p><strong>重启。</strong></p>
</li>
</ol>
<h2 id="9）如何解决redis的并发竞争key问题？"><a href="#9）如何解决redis的并发竞争key问题？" class="headerlink" title="9）如何解决redis的并发竞争key问题？"></a>9）如何解决redis的并发竞争key问题？</h2><ul>
<li><strong>如果对这个key操作，不要求顺序</strong><br>这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。</li>
<li><strong>如果对这个key操作，要求顺序</strong><pre><code>假设有一个key1，系统A需要将key1设置为`valueA`，系统B需要将key1设置为`valueB`，系统C需要将key1设置为`valueC`。
期望按照key1的value值按照 `valueA--&gt;valueB--&gt;valueC`的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。</code></pre></li>
<li><strong>队列实现</strong></li>
</ul>
<h2 id="10）为什么-Redis-在最初的版本中选择单线程模型？"><a href="#10）为什么-Redis-在最初的版本中选择单线程模型？" class="headerlink" title="10）为什么 Redis 在最初的版本中选择单线程模型？"></a>10）为什么 Redis 在最初的版本中选择单线程模型？</h2><blockquote>
<p><a href="https://draveness.me/whys-the-design-redis-single-thread/" target="_blank" rel="noopener">https://draveness.me/whys-the-design-redis-single-thread/</a></p>
</blockquote>
<p>原因：</p>
<ul>
<li><p><strong>可维护性</strong></p>
<p>多线程模型虽然在某些方面表现优异，但是它却引入了<strong>程序执行顺序的不确定性</strong>，代码的执行过程不再是串行的，多个线程同时访问的变量如果没有谨慎处理就会带来诡异的问题。</p>
</li>
<li><p><strong>并发处理</strong></p>
<p>使用单线程模型也并不意味着程序不能并发的处理任务，Redis 虽然使用单线程模型处理用户的请求，但是它却使用 <strong>I/O 多路复用机制并发</strong>处理来自客户端的多个连接，同时等待多个连接发送的请求。</p>
</li>
<li><p><strong>性能瓶颈</strong></p>
<p>使用分片的方式将不同的请求交给不同的 Redis 服务器来处理，而不是在同一个 Redis 服务中引入大量的多线程操作。</p>
<p>Redis 并不是 CPU 密集型的服务，如果不开启 AOF 备份，所有 Redis 的操作都会在内存中完成不会涉及任何的 I/O 操作，这些数据的读写由于只发生在内存中，所以处理速度是非常快的；整个服务的瓶颈在于网络传输带来的延迟和等待客户端的数据传输，也就是网络 I/O。</p>
</li>
</ul>
<h2 id="11）为什么-Redis-服务增加了多个非阻塞的删除操作，例如：UNLINK、FLUSHALL-ASYNC-和-FLUSHDB-ASYNC？（Redis-4-0）"><a href="#11）为什么-Redis-服务增加了多个非阻塞的删除操作，例如：UNLINK、FLUSHALL-ASYNC-和-FLUSHDB-ASYNC？（Redis-4-0）" class="headerlink" title="11）为什么 Redis 服务增加了多个非阻塞的删除操作，例如：UNLINK、FLUSHALL ASYNC 和 FLUSHDB ASYNC？（Redis 4.0）"></a>11）为什么 Redis 服务增加了多个非阻塞的删除操作，例如：<code>UNLINK</code>、<code>FLUSHALL ASYNC</code> 和 <code>FLUSHDB ASYNC</code>？（Redis 4.0）</h2><p>Redis 在最新的几个版本中加入了一些可以被其他线程异步处理的删除操作，也就是 <code>UNLINK</code>、<code>FLUSHALL ASYNC</code> 和 <code>FLUSHDB ASYNC</code>。</p>
<h4 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h4><p>倘若待删除的<strong>键值对占用了较小的内存空间</strong>，那么哪怕是<strong>同步地</strong>删除这些键值对也不会消耗太多的时间。</p>
<p>倘若待删除的<strong>键值对属于超大键值</strong>，几十 MB 或者几百 MB 的数据并不能在几毫秒的时间内处理完，Redis 可能会需要在释放内存空间上消耗较多的时间，这些操作就会阻塞待处理的任务，最终<strong>影响Redis的可用性</strong>。</p>
<p>然而释放内存空间的工作其实可以<strong>由后台线程异步进行处理</strong>，这也就是 <code>UNLINK</code> 命令的实现原理，它只会将键从元数据中删除，真正的删除操作会在后台异步执行。</p>
<h2 id="12）Redis服务器中数据的存储"><a href="#12）Redis服务器中数据的存储" class="headerlink" title="12）Redis服务器中数据的存储"></a>12）Redis服务器中数据的存储</h2><p><code>Redis</code>服务器将所有数据库都保存在服务器状态<code>redis.h/redisServer</code>结构的db数组中，db数组的每个项都是一个<code>redis.h/redisDb</code>结构，每个<code>redisDb结构</code>代表一个数据库。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisServer</span> &#123;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 保存着服务器中所有数据库的数组</span></span><br><span class="line">	redisDb *db;</span><br><span class="line">    <span class="comment">// 服务器的数据库数量</span></span><br><span class="line">    <span class="keyword">int</span> dbNum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在服务器内部，客户端状态<code>redisClient</code>结构的<code>db属性</code>记录了客户端当前的目标数据库，这个属性是一个指向<code>redisDb</code>结构的指针：</p>
<p>（<code>redisClient.db</code>指针指向<code>redisServer.db</code>数组的其中一个元素，而被指向的元素就是客户端的目标数据库。）</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisClient</span> &#123;</span></span><br><span class="line">	...</span><br><span class="line">    <span class="comment">// 记录客户端当前正在使用的数据库</span></span><br><span class="line">    redisDb *db;</span><br><span class="line">&#125; RedisClient;</span><br></pre></td></tr></table></figure>

<pre><code>Redis是一个键值对（`key-value pair`）数据库服务器，服务器中的每个数据库都由一个`redis.h/redisDb`结构表示，其中，`redisDb`结构的`dict`字典保存了数据库中的所有键值对，我们将这个字典称为键空间（`key space`）：</code></pre><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisDb</span> &#123;</span></span><br><span class="line">	....</span><br><span class="line">    <span class="comment">// 数据库键空间，存储键值对</span></span><br><span class="line">    dict * dict;</span><br><span class="line">    <span class="comment">// 过期时间</span></span><br><span class="line">    dict * expires;</span><br><span class="line">    </span><br><span class="line">&#125; redisDb;</span><br></pre></td></tr></table></figure>

<p>一个<code>database</code>内的这个映射关系是用一个<code>dict</code>来维护的（如上代码）。</p>
<p><code>dict</code>的<code>key</code>固定用一种数据结构来表达就够了，这就是<code>动态字符串SDS</code>。而<code>value</code>则比较复杂，为了在同一个<code>dict</code>内能够存储不同类型的<code>value</code>，这就需要一个通用的数据结构，这个通用的数据结构就是<code>robj（全名是redisObject）</code>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisObject</span> &#123;</span></span><br><span class="line">	<span class="comment">// 类型</span></span><br><span class="line">    <span class="keyword">unsigned</span> type:<span class="number">4</span>;</span><br><span class="line">    <span class="comment">// 编码</span></span><br><span class="line">    <span class="keyword">unsigned</span> encoding:<span class="number">4</span>;</span><br><span class="line">    <span class="comment">// 指向底层实现数据结构的指针</span></span><br><span class="line">    <span class="keyword">void</span> *ptr;</span><br><span class="line">    <span class="comment">// 引用技术</span></span><br><span class="line">    <span class="keyword">int</span> refcount;</span><br><span class="line">    <span class="comment">// lru算法用</span></span><br><span class="line">    <span class="keyword">unsigned</span> lru:LRU_BITS;</span><br><span class="line">    </span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure>

<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708144852021.png" alt="image-20200708144852021"></p>
<p>redisObject属性：</p>
<ul>
<li><p>type</p>
<p>对象的数据类型，占4个bit。</p>
<p>可能的取值有5种：<strong>OBJ_STRING, OBJ_LIST, OBJ_SET, OBJ_ZSET, OBJ_HASH</strong>，分别对应Redis对外暴露的5种数据结构。</p>
</li>
<li><p>encoding</p>
<p><strong>OBJ_ENCODING_RAW</strong>: 最原生的表示方式。其实只有string类型才会用这个encoding值（表示成sds）。</p>
<p><strong>OBJ_ENCODING_INT</strong>: 表示成数字。实际用long表示。</p>
<p><strong>OBJ_ENCODING_HT</strong>: 表示成dict。</p>
<p><strong>OBJ_ENCODING_ZIPMAP</strong>: 是个旧的表示方式，已不再用。在小于Redis 2.6的版本中才有。</p>
<p><strong>OBJ_ENCODING_LINKEDLIST</strong>: 也是个旧的表示方式，已不再用。</p>
<p><strong>OBJ_ENCODING_ZIPLIST</strong>: 表示成ziplist。</p>
<p><strong>OBJ_ENCODING_INTSET</strong>: 表示成intset。用于set数据结构。</p>
<p><strong>OBJ_ENCODING_SKIPLIST</strong>: 表示成skiplist。用于sorted set数据结构。</p>
<p><strong>OBJ_ENCODING_EMBSTR</strong>: 表示成一种特殊的嵌入式的sds。</p>
<p><strong>OBJ_ENCODING_QUICKLIST</strong>: 表示成quicklist。用于list数据结构。</p>
</li>
<li><p>lru</p>
<p>做LRU替换算法用，占24个bit。</p>
</li>
<li><p>refcount</p>
<p>引用计数。它允许robj对象在某些情况下被共享。</p>
</li>
<li><p>ptr</p>
<p>数据指针。指向真正的数据。<br>比如，一个代表string的robj，它的ptr可能指向一个sds结构；<br>一个代表list的robj，它的ptr可能指向一个quicklist。</p>
</li>
</ul>
<p><strong>新增<code>k-v键值对</code>流程图</strong>：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200709222510535.png" alt="image-20200709222510535"></p>
<h2 id="13）Redis中的字符串对象编码？"><a href="#13）Redis中的字符串对象编码？" class="headerlink" title="13）Redis中的字符串对象编码？"></a>13）Redis中的字符串对象编码？</h2><ul>
<li><p><strong>raw</strong></p>
<p>如果字符串对象保存的是一个字符串值，并且这个字符串值的<code>长度大于32字节</code>，那么字符串对象将使用一个<code>简单动态字符串（SDS）</code>来保存这个字符串值，并将对象的编码设置为<code>raw</code>：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708150012598.png" alt="image-20200708150012598"></p>
</li>
<li><p><strong>embstr</strong></p>
<p>如果字符串对象保存的是一个字符串值，并且这个字符串值的<code>长度小于等于32字节</code>，那么字符串对象将使用<code>embstr编码</code>的方式来保存这个字符串值：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708151458048.png" alt="image-20200708151458048"></p>
<p><strong><code>raw编码</code>会调用两次内存分配函数来分别创建<code>redisObject结构</code>和<code>sdshdr结构</code>，而<code>embstr编码</code>则通过调用一次内存分配函数来分配一块连续的空间，空间中依次包含<code>redisObject</code>和<code>sdshdr</code>两个结构。</strong></p>
</li>
<li><p><strong>int</strong></p>
<p>如果一个字符串对象保存的是整数值，并且这个整数值可以用<code>long类型</code>来表示，那么字符串对象会<code>将整数值保存在字符串对象结构的ptr属性</code>里面（<code>将void*转换成long</code>），并将字符串对象的编码设置为int：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708150416421.png" alt="image-20200708150416421"></p>
</li>
</ul>
<h2 id="14）RedisObject详解"><a href="#14）RedisObject详解" class="headerlink" title="14）RedisObject详解"></a>14）RedisObject详解</h2><h3 id="内存回收"><a href="#内存回收" class="headerlink" title="内存回收"></a>内存回收</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisObject</span> &#123;</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 引用计数</span></span><br><span class="line">    <span class="keyword">int</span> refcount;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure>

<p>对象的引用计数信息<strong>会随着对象的使用状态而不断变化</strong>：</p>
<ul>
<li>在<strong>创建一个新对象</strong>时，引用计数的值会被初始化为1；</li>
<li>当对象<strong>被一个新程序使用</strong>时，它的引用计数值会被增一；</li>
<li>当对象<strong>不再被一个程序使用</strong>时，它的引用计数值会被减一；</li>
<li>当对象的<strong>引用计数值变为0</strong>时，对象所占用的内存会被释放。</li>
</ul>
<h3 id="对象共享"><a href="#对象共享" class="headerlink" title="对象共享"></a>对象共享</h3><p><code>refcount</code></p>
<p>在Redis中，让多个键共享同一个值对象需要执行以下两个步骤：</p>
<p>1）将数据库键的值指针指向一个现有的值对象；</p>
<p>2）将被共享的值对象的引用计数增一。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200708154259838.png" alt="image-20200708154259838"></p>
<h3 id="为什么Redis不共享包含字符串的对象？"><a href="#为什么Redis不共享包含字符串的对象？" class="headerlink" title="为什么Redis不共享包含字符串的对象？"></a><strong>为什么Redis不共享包含字符串的对象？</strong></h3><pre><code>当服务器考虑将一个共享对象设置为键的值对象时，程序需要先检查给定的共享对象和键想创建的目标对象是否完全相同，只有在共享对象和目标对象完全相同的情况下，程序才会将共享对象用作键的值对象，而一个共享对象保存的值越复杂，验证共享对象和目标对象是否相同所需的复杂度就会越高，消耗的CPU时间也会越多：</code></pre><ul>
<li><p>如果共享对象是<strong>保存整数值的字符串对象（值为0-9999）</strong>，那么验证操作的复杂度为<code>O（1）</code>；</p>
</li>
<li><p>如果共享对象是<strong>保存字符串值的字符串对象</strong>，那么验证操作的复杂度为<code>O（N）</code>；</p>
</li>
<li><p>如果共享对象是<strong>包含了多个值（或者对象的）对象</strong>，比如列表对象或者哈希对象，那么验证操作的复杂度将会是<code>O（N^2）</code>。</p>
</li>
</ul>
<p>  因此，尽管共享更复杂的对象可以节约更多的内存，但受到CPU时间的限制，Redis只对包含整数值的字符串对象进行共享。</p>
<h3 id="对象空转时长"><a href="#对象空转时长" class="headerlink" title="对象空转时长"></a>对象空转时长</h3><p>属性：<code>lru</code></p>
<p>这一空转时长就是通过<strong>将当前时间减去键的值对象的lru时间计算得出的</strong>。</p>
<ul>
<li><p>可以被<code>OBJECT IDLETIME</code>命令打印出来。</p>
</li>
<li><p>如果服务器打开了<code>maxmemory选项</code>，并且服务器用于回收内存的算法为<code>volatile-lru</code>或者<code>allkeys-lru</code>，那么当服务器占用的内存数超过了<code>maxmemory选项</code>所设置的上限值时，空转时长较高的那部分键会优先被服务器释放，从而回收内存。</p>
</li>
</ul>
<h2 id="15）全局key搜索方式及原理？"><a href="#15）全局key搜索方式及原理？" class="headerlink" title="15）全局key搜索方式及原理？"></a>15）全局key搜索方式及原理？</h2><h4 id="SCAN"><a href="#SCAN" class="headerlink" title="SCAN"></a>SCAN</h4><blockquote>
<p><a href="https://mp.weixin.qq.com/s/ufoLJiXE0wU4Bc7ZbE9cDQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ufoLJiXE0wU4Bc7ZbE9cDQ</a></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scan 0 match key99* count 1000</span><br><span class="line">（从游标0开始在前1000个槽中匹配符合key99为前缀的key）</span><br></pre></td></tr></table></figure>

<h5 id="遍历顺序"><a href="#遍历顺序" class="headerlink" title="遍历顺序"></a>遍历顺序</h5><p>scan 的遍历顺序非常特别，它不是从第一维数组的第 0 位一直遍历到末尾，而是采用了<strong>高位进位加法来遍历</strong>。<br>之所以使用这样特殊的方式进行遍历，是考虑到<strong>字典的扩容和缩容时避免槽位的遍历重复和遗漏</strong>。</p>
<h5 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h5><p>scan 参数提供了三个参数：</p>
<ul>
<li>第一个是 cursor 整数值；</li>
<li>第二个是 key 的正则模式；</li>
<li>第三个是遍历的 limit hint；</li>
</ul>
<p>第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。<br>一直遍历到返回的 cursor 值为 0 时结束。</p>
<h5 id="优点-3"><a href="#优点-3" class="headerlink" title="优点"></a>优点</h5><p>1、复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程;</p>
<p>2、提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的结果可多可少; </p>
<p>3、同 keys 一样，它也提供模式匹配功能; </p>
<p>4、服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数; </p>
<p>5、返回的结果可能会有重复，需要客户端去重复，这点非常重要; </p>
<p>6、遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的; </p>
<p>7、单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;</p>
<h4 id="KEYS"><a href="#KEYS" class="headerlink" title="KEYS"></a>KEYS</h4><h5 id="缺点-4"><a href="#缺点-4" class="headerlink" title="缺点"></a>缺点</h5><p>1、没有 offset、limit 参数，一次性吐出所有满足条件的 key，万一实例中有几百 w 个 key 满足条件，<br>当你看到满屏的字符串刷的没有尽头时，你就知道难受了。</p>
<p>2、keys 算法是遍历算法，复杂度是 O(n)，如果实例中有千万级以上的 key，<br>这个指令就会<code>导致 Redis 服务卡顿</code>，<code>所有读写 Redis 的其它的指令都会被延后</code>甚至会超时报错，<br>因为 Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才可以继续。</p>
<h2 id="16）慢查询日志（SLOW-LOG）"><a href="#16）慢查询日志（SLOW-LOG）" class="headerlink" title="16）慢查询日志（SLOW LOG）?"></a>16）慢查询日志（SLOW LOG）?</h2><p><code>Redis</code>的慢查询日志功能用于记录执行时间超过给定时长的命令请求，用户可以通过这个功能产生的日志来监视和优化查询速度。</p>
<p>配置：</p>
<ul>
<li><code>slowlog-log-slower-than</code>选项指定执行时间超过多少微秒（1秒等于1000 000微秒）的命令请求会被记录到日志上。</li>
<li><code>slowlog-max-len</code>选项指定服务器最多保存多少条慢查询日志。</li>
</ul>
<p>命令：</p>
<p>使用<code>SLOWLOG GET</code>命令查看服务器所保存的慢查询日志。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisServer</span> &#123;</span></span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 下一条慢查询日志ID，初始为0，每当创建一条新的则+1</span></span><br><span class="line">	<span class="keyword">long</span> <span class="keyword">long</span> slowlog_entry_id;</span><br><span class="line">	<span class="comment">// 保存了所有慢查询日志链表，内部结构为slowlogEntry</span></span><br><span class="line">	<span class="built_in">list</span> *slowlog;</span><br><span class="line">	<span class="comment">// 服务器配置slowlog_log_slower_than选项的值</span></span><br><span class="line">	<span class="keyword">long</span> <span class="keyword">long</span> slowlog_log_slower_than;</span><br><span class="line">	<span class="comment">// 服务器配置slowlog_max_len选项的值</span></span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">long</span> slowlog_max_len;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710021600585.png" alt="image-20200710021600585"></p>
<img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710021422829.png" alt="image-20200710021422829" style="zoom:50%;" />

<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710021440495.png" alt="image-20200710021440495"></p>
<h2 id="17）Redis监视器（Monitor）？"><a href="#17）Redis监视器（Monitor）？" class="headerlink" title="17）Redis监视器（Monitor）？"></a>17）Redis监视器（<code>Monitor</code>）？</h2><p>通过执行<code>MONITOR</code>命令，客户端可以将自己变为一个监视器，实时地接收并打印出服务器当前处理的命令请求的相关信息。</p>
<p>服务器在每次处理命令请求之前，都会调用<code>replicationFeedMonitors</code>函数，由这个函数将被处理的命令请求的相关信息发送给各个监视器。</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710164026287.png" alt="image-20200710164026287"></p>
<p>如图，服务器执行客户端发送的MONITOR命令后，monitors链表会在尾部新增节点。</p>
<p>​    </p>
<h2 id="18）那么在Dict非稳定状态，即发生Rehash的情况下，Scan要如何保证原有的Key都能遍历出来，又尽少可能重复扫描呢？"><a href="#18）那么在Dict非稳定状态，即发生Rehash的情况下，Scan要如何保证原有的Key都能遍历出来，又尽少可能重复扫描呢？" class="headerlink" title="18）那么在Dict非稳定状态，即发生Rehash的情况下，Scan要如何保证原有的Key都能遍历出来，又尽少可能重复扫描呢？"></a>18）那么在Dict非稳定状态，即发生Rehash的情况下，<strong>Scan要如何保证原有的Key都能遍历出来，又尽少可能重复扫描呢？</strong></h2><p>参考：<a href="https://mp.weixin.qq.com/s/ufoLJiXE0wU4Bc7ZbE9cDQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ufoLJiXE0wU4Bc7ZbE9cDQ</a></p>
<p>Scan通过==Hash桶掩码的高位顺序访问==来解决，为了实现Redis Dict在Rehash时尽可能少重复扫描返回Key。</p>
<blockquote>
<p>为了兼容迭代间隔期间可能发生的缩容与扩容操作，每次迭代时都会对v变量（游标值）进行修改，以确保迭代出的数据无遗漏，游标具体变更算法为：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710102739043.png" alt="image-20200710102739043"></p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710102711968.png" alt="image-20200710102711968"></p>
<p>引自：《Redis 5设计与源码分析》 - 5.4 字典的遍历</p>
</blockquote>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710103110995.png" alt="image-20200710103110995"></p>
<p>高位顺序访问即按照<code>Dict sizemask（掩码）</code>，在<code>有效位</code>（上图中<code>Dict sizemask</code>为3）上从高位开始加一枚举；低位则按照有效位的低位逐步加一访问。</p>
<p>低位序：<code>0→1→2→3→4→5→6→7</code></p>
<p>高位序：<code>0→4→2→6→1→5→3→7</code></p>
<p><strong>栗子</strong>：</p>
<p><img src="http://qd2x6jysb.bkt.clouddn.com/image-20200710103522864.png" alt="image-20200710103522864"></p>
<p>举个例子，如果<code>Dict</code>的<code>tablesize</code>从<code>8</code>扩展到了<code>16</code>，梳理一下<code>Scan</code>扫描方式:</p>
<ol>
<li><code>Dict(8)</code>从<code>Cursor 0</code>开始扫描；</li>
<li>准备扫描<code>Cursor 6</code>时发生<code>Resize</code>，扩展为之前的2倍，并完成<code>Rehash</code>；</li>
<li>客户端这时开始从<code>Dict(16)</code>的<code>Cursor 6</code>继续迭代；</li>
<li>这时按照 <code>6→14→1→9→5→13→3→11→7→15 Scan</code>完成。</li>
</ol>
<h2 id="19）技术选型？"><a href="#19）技术选型？" class="headerlink" title="19）技术选型？"></a>19）技术选型？</h2><p>Redis优势：</p>
<ol>
<li>性能极高；</li>
<li>数据类型丰富，支持数据结构动态变更；</li>
<li>I/O多路复用；</li>
<li>支持事务、pipLine、发布/订阅、内存回收策略、持久化到磁盘、支持主从、集群等。</li>
<li>单一操作原子；</li>
</ol>
<h2 id="20）QPS过万，redis大量连接超时怎么解决？"><a href="#20）QPS过万，redis大量连接超时怎么解决？" class="headerlink" title="20）QPS过万，redis大量连接超时怎么解决？"></a>20）QPS过万，redis大量连接超时怎么解决？</h2><blockquote>
<p><a href="https://juejin.im/post/5effe8f45188252e603add35" target="_blank" rel="noopener">https://juejin.im/post/5effe8f45188252e603add35</a></p>
</blockquote>
<ul>
<li><p>大Key问题</p>
</li>
<li><p>热Key问题</p>
</li>
</ul>
<h2 id="21）设置过期时间的key操作注意事项"><a href="#21）设置过期时间的key操作注意事项" class="headerlink" title="21）设置过期时间的key操作注意事项"></a>21）设置过期时间的key操作注意事项</h2><h4 id="1、-DEL-SET-GETSET等命令会清除过期时间"><a href="#1、-DEL-SET-GETSET等命令会清除过期时间" class="headerlink" title="1、 DEL/SET/GETSET等命令会清除过期时间"></a>1、 <a href="http://doc.redisfans.com/key/del.html" target="_blank" rel="noopener">DEL</a>/<a href="http://doc.redisfans.com/string/set.html" target="_blank" rel="noopener">SET</a>/<a href="http://doc.redisfans.com/string/getset.html" target="_blank" rel="noopener">GETSET</a>等命令会清除过期时间</h4><h4 id="2、INCR-LPUSH-HSET等命令则不会清除过期时间；"><a href="#2、INCR-LPUSH-HSET等命令则不会清除过期时间；" class="headerlink" title="2、INCR/LPUSH/HSET等命令则不会清除过期时间；"></a>2、<a href="http://doc.redisfans.com/string/incr.html" target="_blank" rel="noopener">INCR</a>/<a href="http://doc.redisfans.com/list/lpush.html" target="_blank" rel="noopener">LPUSH</a>/<a href="http://doc.redisfans.com/hash/hset.html" target="_blank" rel="noopener">HSET</a>等命令则不会清除过期时间；</h4><h4 id="3、PERSIST命令会清除过期时间；"><a href="#3、PERSIST命令会清除过期时间；" class="headerlink" title="3、PERSIST命令会清除过期时间；"></a>3、<a href="http://doc.redisfans.com/key/persist.html" target="_blank" rel="noopener">PERSIST</a>命令会清除过期时间；</h4><h4 id="4、使用RENAME命令，老key的过期时间将会转到新key上；"><a href="#4、使用RENAME命令，老key的过期时间将会转到新key上；" class="headerlink" title="4、使用RENAME命令，老key的过期时间将会转到新key上；"></a>4、使用<a href="http://doc.redisfans.com/key/rename.html" target="_blank" rel="noopener">RENAME</a>命令，老key的过期时间将会转到新key上；</h4><h4 id="5、使用EXPIRE-PEXPIRE设置的过期时间为负数，或者使用EXPIREAT-PEXPIREAT设置过期时间戳为过去的时间会导致key被删除；"><a href="#5、使用EXPIRE-PEXPIRE设置的过期时间为负数，或者使用EXPIREAT-PEXPIREAT设置过期时间戳为过去的时间会导致key被删除；" class="headerlink" title="5、使用EXPIRE/PEXPIRE设置的过期时间为负数，或者使用EXPIREAT/PEXPIREAT设置过期时间戳为过去的时间会导致key被删除；"></a>5、使用<a href="http://doc.redisfans.com/key/expire.html" target="_blank" rel="noopener">EXPIRE</a>/<a href="http://doc.redisfans.com/key/pexpire.html" target="_blank" rel="noopener">PEXPIRE</a>设置的过期时间为负数，或者使用<a href="http://doc.redisfans.com/key/expireat.html" target="_blank" rel="noopener">EXPIREAT</a>/<a href="http://doc.redisfans.com/key/pexpireat.html" target="_blank" rel="noopener">PEXPIREAT</a>设置过期时间戳为过去的时间会导致key被删除；</h4><h4 id="6、EXPIRE命令可以更新过期时间"><a href="#6、EXPIRE命令可以更新过期时间" class="headerlink" title="6、EXPIRE命令可以更新过期时间;"></a>6、<a href="http://doc.redisfans.com/key/expire.html" target="_blank" rel="noopener">EXPIRE</a>命令可以更新过期时间;</h4>
      </div>
      
        <div class="prev-or-next">
          <div class="post-foot-next">
            
          </div>
          <div class="post-attach">
            <span class="post-pubtime">2020-07-23</span>
            
          </div>
          <div class="post-foot-prev">
            
          </div>
        </div>
      
    </div>
    
  <div class="post-catalog" id="catalog">
    <div class="title">目录</div>
    <div class="catalog-content">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#基础数据类型"><span class="toc-text">基础数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#String"><span class="toc-text">String</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#List"><span class="toc-text">List</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#编码转换"><span class="toc-text">编码转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#链表的缺陷"><span class="toc-text">链表的缺陷</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#命令"><span class="toc-text">命令</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Set"><span class="toc-text">Set</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#编码转换-1"><span class="toc-text">编码转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#命令-1"><span class="toc-text">命令</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ZSet"><span class="toc-text">ZSet</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#命令-2"><span class="toc-text">命令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#编码转换-2"><span class="toc-text">编码转换</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#ZipList编码（REDIS-ENCODING-ZIPLIST）"><span class="toc-text">ZipList编码（REDIS_ENCODING_ZIPLIST）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#SkipList编码（REDIS-ENCODING-SKIPLIST）"><span class="toc-text">SkipList编码（REDIS_ENCODING_SKIPLIST）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#为什么有序集合需要同时使用跳跃表和字典来实现？"><span class="toc-text">为什么有序集合需要同时使用跳跃表和字典来实现？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hash"><span class="toc-text">Hash</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#编码转换-3"><span class="toc-text">编码转换</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GEO"><span class="toc-text">GEO</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#存储结构"><span class="toc-text">存储结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#命令-3"><span class="toc-text">命令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GEO算法"><span class="toc-text">GEO算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#步骤"><span class="toc-text">步骤</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HyperLogLog"><span class="toc-text">HyperLogLog</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#结构"><span class="toc-text">结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#指令"><span class="toc-text">指令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实现原理"><span class="toc-text">实现原理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BloomFilter"><span class="toc-text">BloomFilter</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#指令-1"><span class="toc-text">指令</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#bf-add-bf-madd"><span class="toc-text">bf.add&#x2F;bf.madd</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#bf-exists-bf-mexists"><span class="toc-text">bf.exists&#x2F;bf.mexists</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#原理"><span class="toc-text">原理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#add操作"><span class="toc-text">add操作</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#exists操作"><span class="toc-text">exists操作</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stream"><span class="toc-text">Stream</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#结构-1"><span class="toc-text">结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#消息"><span class="toc-text">消息</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#语法格式"><span class="toc-text">语法格式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#组成"><span class="toc-text">组成</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#消费组"><span class="toc-text">消费组</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#特点"><span class="toc-text">特点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#命令-4"><span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#组内消费原理"><span class="toc-text">组内消费原理</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#消费者"><span class="toc-text">消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#命令-5"><span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#顺序消费"><span class="toc-text">顺序消费</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#消费"><span class="toc-text">消费</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#命令-6"><span class="toc-text">命令</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#xadd"><span class="toc-text">xadd</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#xdel"><span class="toc-text">xdel</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#xrange"><span class="toc-text">xrange</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#xlen"><span class="toc-text">xlen</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#del"><span class="toc-text">del</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#问题"><span class="toc-text">问题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1）Stream消息太多怎么办？"><span class="toc-text">1）Stream消息太多怎么办？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2）PEL（Pending-Entries-List）如何避免消息丢失？"><span class="toc-text">2）PEL（Pending Entries List）如何避免消息丢失？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3）忘记ACK怎么办？"><span class="toc-text">3）忘记ACK怎么办？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4）Stream高可用？"><span class="toc-text">4）Stream高可用？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pub-Sub"><span class="toc-text">Pub&#x2F;Sub</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#实现原理-1"><span class="toc-text">实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#pubsub-channels"><span class="toc-text">pubsub_channels</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#pubsub-patterns"><span class="toc-text">pubsub_patterns</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#命令-7"><span class="toc-text">命令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#缺点"><span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PipLine"><span class="toc-text">PipLine</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Pipeline有什么好处，为什么要用pipeline？"><span class="toc-text">Pipeline有什么好处，为什么要用pipeline？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#原生批命令-mset-mget-与Pipeline对比？"><span class="toc-text">原生批命令(mset, mget)与Pipeline对比？</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#基础数据结构"><span class="toc-text">基础数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SDS（Simple-Dynamic-String）"><span class="toc-text">SDS（Simple Dynamic String）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#结构-2"><span class="toc-text">结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#与String区别"><span class="toc-text">与String区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#使用场景"><span class="toc-text">使用场景</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dict（HashTable）"><span class="toc-text">Dict（HashTable）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#结构-3"><span class="toc-text">结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#渐进式rehash"><span class="toc-text">渐进式rehash</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#执行条件"><span class="toc-text">执行条件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#执行过程"><span class="toc-text">执行过程</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#倘若rehash时有其他操作"><span class="toc-text">倘若rehash时有其他操作</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#List-1"><span class="toc-text">List</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#特点-1"><span class="toc-text">特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#结构-4"><span class="toc-text">结构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ZipList"><span class="toc-text">ZipList</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#结构-5"><span class="toc-text">结构</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#属性"><span class="toc-text">属性</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#用途"><span class="toc-text">用途</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#特点-2"><span class="toc-text">特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hash与ZipList"><span class="toc-text">Hash与ZipList</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#那么到底插入多少才会转Hash呢？"><span class="toc-text">那么到底插入多少才会转Hash呢？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#为什么这么设计？"><span class="toc-text">为什么这么设计？</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据操作"><span class="toc-text">数据操作</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#初始化"><span class="toc-text">初始化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#插入元素"><span class="toc-text">插入元素</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#那么空间大小是不是添加元素前的压缩列表长度与新添加元素长度之和呢？"><span class="toc-text">* 那么空间大小是不是添加元素前的压缩列表长度与新添加元素长度之和呢？</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#删除元素"><span class="toc-text">删除元素</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#IntSet"><span class="toc-text">IntSet</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#特点-3"><span class="toc-text">特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#用途-1"><span class="toc-text">用途</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#结构-6"><span class="toc-text">结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#操作流程"><span class="toc-text">操作流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#QuickList（List-ZipList）"><span class="toc-text">QuickList（List + ZipList）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#用途-2"><span class="toc-text">用途</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#结构-7"><span class="toc-text">结构</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#数据结构"><span class="toc-text">数据结构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#结构为什么这样设计？"><span class="toc-text">结构为什么这样设计？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#一个quicklist节点包含多长的ziplist合适呢？"><span class="toc-text">一个quicklist节点包含多长的ziplist合适呢？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#每个-ziplist-存多少元素？"><span class="toc-text">每个 ziplist 存多少元素？</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据压缩"><span class="toc-text">数据压缩</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#压缩算法-LZF"><span class="toc-text">压缩算法 LZF</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SkipList"><span class="toc-text">SkipList</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#结构-8"><span class="toc-text">结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#随机层数"><span class="toc-text">随机层数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#元素排名实现"><span class="toc-text">元素排名实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#特点-4"><span class="toc-text">特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#为什么不用平衡树、Hash表？"><span class="toc-text">为什么不用平衡树、Hash表？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bitmap（位图）"><span class="toc-text">Bitmap（位图）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#使用位操作设置字符串he"><span class="toc-text">使用位操作设置字符串he</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#命令-8"><span class="toc-text">命令</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#持久化"><span class="toc-text">持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#RDB"><span class="toc-text">RDB</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#执行流程"><span class="toc-text">执行流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#手动触发"><span class="toc-text">手动触发</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#自动触发"><span class="toc-text">自动触发</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#命令-amp-配置"><span class="toc-text">命令&amp;配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#分类"><span class="toc-text">分类</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#SAVE"><span class="toc-text">SAVE</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#BGSAVE（fork-Copy-On-Write）"><span class="toc-text">BGSAVE（fork + Copy-On-Write）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#文件结构（经过压缩的二进制文件-dump-rdb）"><span class="toc-text">文件结构（经过压缩的二进制文件 dump.rdb）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#优点"><span class="toc-text">优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#缺点-1"><span class="toc-text">缺点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#fork函数会带来额外的性能开销，开销如何避免？"><span class="toc-text">fork函数会带来额外的性能开销，开销如何避免？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#全量的拷贝解决方式：写时复制（Copy-on-Write）"><span class="toc-text">全量的拷贝解决方式：写时复制（Copy-on-Write）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AOF（-Append-Only-File-仅追加文件-appendonly-aof）"><span class="toc-text">AOF（*Append Only File - 仅追加文件 *appendonly.aof）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#执行流程-1"><span class="toc-text">执行流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#手动触发-1"><span class="toc-text">手动触发</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#自动触发-1"><span class="toc-text">自动触发</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#重写"><span class="toc-text">重写</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#命令-amp-配置-1"><span class="toc-text">命令&amp;配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#混合持久化"><span class="toc-text">混合持久化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#区别？"><span class="toc-text">区别？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RDB-优点"><span class="toc-text">RDB | 优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RDB-缺点"><span class="toc-text">RDB | 缺点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AOF-优点"><span class="toc-text">AOF | 优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AOF-缺点"><span class="toc-text">AOF | 缺点</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#内存回收策略"><span class="toc-text">内存回收策略</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#内存过期"><span class="toc-text">内存过期</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#定时删除"><span class="toc-text">定时删除</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#惰性删除"><span class="toc-text">惰性删除</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#定期删除"><span class="toc-text">定期删除</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDB、AOF和复制功能对过期键处理"><span class="toc-text">RDB、AOF和复制功能对过期键处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RDB-1"><span class="toc-text">RDB</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#生成"><span class="toc-text">生成</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#载入"><span class="toc-text">载入</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AOF"><span class="toc-text">AOF</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#写入"><span class="toc-text">写入</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#重写-1"><span class="toc-text">重写</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#复制"><span class="toc-text">复制</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#内存淘汰"><span class="toc-text">内存淘汰</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#淘汰策略"><span class="toc-text">淘汰策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#淘汰算法"><span class="toc-text">淘汰算法</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#集群"><span class="toc-text">集群</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#主从"><span class="toc-text">主从</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#作用"><span class="toc-text">作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原理-1"><span class="toc-text">原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#执行SYNC命令"><span class="toc-text">执行SYNC命令</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#执行过程-1"><span class="toc-text">执行过程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#缺陷"><span class="toc-text">缺陷</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#执行PSYNC命令"><span class="toc-text">执行PSYNC命令</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#概念"><span class="toc-text">概念</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#配置"><span class="toc-text">配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#执行过程-2"><span class="toc-text">执行过程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#主从存在的问题"><span class="toc-text">主从存在的问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sentinel-哨兵"><span class="toc-text">Sentinel(哨兵)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#功能"><span class="toc-text">功能</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#工作原理"><span class="toc-text">工作原理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#客户端访问哨兵？"><span class="toc-text">客户端访问哨兵？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#初始化Sentinel"><span class="toc-text">初始化Sentinel</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#获取主服务器信息"><span class="toc-text">获取主服务器信息</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#检测主观下线状态"><span class="toc-text">检测主观下线状态</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#检测客观下线状态"><span class="toc-text">检测客观下线状态</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#选举Sentinel-Leader"><span class="toc-text">选举Sentinel Leader</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Raft算法"><span class="toc-text">Raft算法</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#选主"><span class="toc-text">选主</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#日志复制（Log-Replicate）"><span class="toc-text">日志复制（Log Replicate）</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#成员变更"><span class="toc-text">成员变更</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#新的主服务器是怎样被挑选出来的？"><span class="toc-text">新的主服务器是怎样被挑选出来的？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RedisCluster"><span class="toc-text">RedisCluster</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#基本原理"><span class="toc-text">基本原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#内部数据结构"><span class="toc-text">内部数据结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#重新分片"><span class="toc-text">重新分片</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#实现原理-2"><span class="toc-text">实现原理</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#集群的故障转移"><span class="toc-text">集群的故障转移</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#故障检测"><span class="toc-text">故障检测</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#故障转移"><span class="toc-text">故障转移</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#选举新节点"><span class="toc-text">选举新节点</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#主要作用"><span class="toc-text">主要作用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#分区方案"><span class="toc-text">分区方案</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分布式锁"><span class="toc-text">分布式锁</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#用途-3"><span class="toc-text">用途</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#目的"><span class="toc-text">目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特性"><span class="toc-text">特性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SET-NX（普通锁）"><span class="toc-text">SET NX（普通锁）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RedLock（redisson）"><span class="toc-text">RedLock（redisson）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RedLock特点"><span class="toc-text">RedLock特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决的问题"><span class="toc-text">解决的问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#加解锁"><span class="toc-text">加解锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#安全性影响"><span class="toc-text">安全性影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#可用条件"><span class="toc-text">可用条件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#高并发场景下的问题"><span class="toc-text">高并发场景下的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#性能问题"><span class="toc-text">&#x3D;&#x3D;性能问题&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#重试的问题"><span class="toc-text">&#x3D;&#x3D;重试的问题&#x3D;&#x3D;</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#解决的方案"><span class="toc-text">解决的方案</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#节点宕机"><span class="toc-text">&#x3D;&#x3D;节点宕机&#x3D;&#x3D;</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#解决方案"><span class="toc-text">解决方案</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#任务执行时间超过锁的TTL"><span class="toc-text">&#x3D;&#x3D;任务执行时间超过锁的TTL&#x3D;&#x3D;</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#解决方案-1"><span class="toc-text">解决方案</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#系统时钟漂移"><span class="toc-text">&#x3D;&#x3D;系统时钟漂移&#x3D;&#x3D;</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#为什么系统时钟会存在漂移呢？"><span class="toc-text">为什么系统时钟会存在漂移呢？</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Zookeeper"><span class="toc-text">Zookeeper</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#如何保证一致性？"><span class="toc-text">如何保证一致性？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#区别"><span class="toc-text">区别</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#限流"><span class="toc-text">限流</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ZSET"><span class="toc-text">ZSET</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RateLimit"><span class="toc-text">RateLimit</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#消息队列"><span class="toc-text">消息队列</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ZSET-1"><span class="toc-text">ZSET</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#优点-1"><span class="toc-text">优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#缺点-2"><span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pub-sub订阅"><span class="toc-text">pub&#x2F;sub订阅</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#优点-2"><span class="toc-text">优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#缺点-3"><span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#List（LPUSH-BRPOP-BLPOP）"><span class="toc-text">List（LPUSH+BRPOP&#x2F;BLPOP）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#通信"><span class="toc-text">通信</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Gossip协议"><span class="toc-text">Gossip协议</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#消息类型"><span class="toc-text">消息类型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#客户端通信（RESP）"><span class="toc-text">客户端通信（RESP）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#客户端-gt-服务端"><span class="toc-text">客户端 -&gt; 服务端</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#服务器-gt-客户端"><span class="toc-text">服务器 -&gt; 客户端</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#事件机制（Reactor）"><span class="toc-text">事件机制（Reactor）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#事务"><span class="toc-text">事务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#实现"><span class="toc-text">实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WATCH"><span class="toc-text">WATCH</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#原理-2"><span class="toc-text">原理</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#问题-1"><span class="toc-text">问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1）Redis为什么那么快？"><span class="toc-text">1）Redis为什么那么快？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#I-O多路复用"><span class="toc-text">I&#x2F;O多路复用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Blocking-I-O（I-O阻塞模型）"><span class="toc-text">* Blocking I&#x2F;O（I&#x2F;O阻塞模型）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#I-O-多路复用"><span class="toc-text">* I&#x2F;O 多路复用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#内存操作"><span class="toc-text">内存操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#命令操作时是单线程操作，提高效率"><span class="toc-text">命令操作时是单线程操作，提高效率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#大量数据结构上的优化（SDS、ZipList、Dict等）"><span class="toc-text">大量数据结构上的优化（SDS、ZipList、Dict等）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#自己的VM模型"><span class="toc-text">自己的VM模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2）缓存穿透、缓存雪崩、缓存击穿及处理方式？"><span class="toc-text">2）缓存穿透、缓存雪崩、缓存击穿及处理方式？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#缓存穿透"><span class="toc-text">缓存穿透</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#缓存雪崩"><span class="toc-text">缓存雪崩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#缓存击穿"><span class="toc-text">缓存击穿</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3）数据库缓存双写一致性？"><span class="toc-text">3）数据库缓存双写一致性？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#先更新数据库，再更新"><span class="toc-text">先更新数据库，再更新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#先删除缓存，再更新数据库"><span class="toc-text">先删除缓存，再更新数据库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#先更新数据库，再删除缓存"><span class="toc-text">先更新数据库，再删除缓存</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Cache-Aside-Pattern"><span class="toc-text">Cache Aside Pattern</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#问题-2"><span class="toc-text">问题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#一、并发脏数据问题"><span class="toc-text">一、并发脏数据问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#二、如果删缓存失败了怎么办，那不是会有不一致的情况出现么？"><span class="toc-text">二、如果删缓存失败了怎么办，那不是会有不一致的情况出现么？</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1）侵入代码的重试机制"><span class="toc-text">1）侵入代码的重试机制</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2）监听binlog的异步重试机制"><span class="toc-text">2）监听binlog的异步重试机制</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4）BigKey问题？"><span class="toc-text">4）BigKey问题？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#什么是bigkey？"><span class="toc-text">什么是bigkey？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#如何发现？"><span class="toc-text">如何发现？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#危害？"><span class="toc-text">危害？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5）消息队列实现？"><span class="toc-text">5）消息队列实现？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6）Key如何存储的？"><span class="toc-text">6）Key如何存储的？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#渐进式rehash-1"><span class="toc-text">渐进式rehash</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7）热Key问题？"><span class="toc-text">7）热Key问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8）redis删除很多key-内存不减少的原因？"><span class="toc-text">8）redis删除很多key, 内存不减少的原因？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9）如何解决redis的并发竞争key问题？"><span class="toc-text">9）如何解决redis的并发竞争key问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10）为什么-Redis-在最初的版本中选择单线程模型？"><span class="toc-text">10）为什么 Redis 在最初的版本中选择单线程模型？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11）为什么-Redis-服务增加了多个非阻塞的删除操作，例如：UNLINK、FLUSHALL-ASYNC-和-FLUSHDB-ASYNC？（Redis-4-0）"><span class="toc-text">11）为什么 Redis 服务增加了多个非阻塞的删除操作，例如：UNLINK、FLUSHALL ASYNC 和 FLUSHDB ASYNC？（Redis 4.0）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#删除操作"><span class="toc-text">删除操作</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12）Redis服务器中数据的存储"><span class="toc-text">12）Redis服务器中数据的存储</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13）Redis中的字符串对象编码？"><span class="toc-text">13）Redis中的字符串对象编码？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14）RedisObject详解"><span class="toc-text">14）RedisObject详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#内存回收"><span class="toc-text">内存回收</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#对象共享"><span class="toc-text">对象共享</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么Redis不共享包含字符串的对象？"><span class="toc-text">为什么Redis不共享包含字符串的对象？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#对象空转时长"><span class="toc-text">对象空转时长</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15）全局key搜索方式及原理？"><span class="toc-text">15）全局key搜索方式及原理？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SCAN"><span class="toc-text">SCAN</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#遍历顺序"><span class="toc-text">遍历顺序</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#操作"><span class="toc-text">操作</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#优点-3"><span class="toc-text">优点</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KEYS"><span class="toc-text">KEYS</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#缺点-4"><span class="toc-text">缺点</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16）慢查询日志（SLOW-LOG）"><span class="toc-text">16）慢查询日志（SLOW LOG）?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17）Redis监视器（Monitor）？"><span class="toc-text">17）Redis监视器（Monitor）？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#18）那么在Dict非稳定状态，即发生Rehash的情况下，Scan要如何保证原有的Key都能遍历出来，又尽少可能重复扫描呢？"><span class="toc-text">18）那么在Dict非稳定状态，即发生Rehash的情况下，Scan要如何保证原有的Key都能遍历出来，又尽少可能重复扫描呢？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#19）技术选型？"><span class="toc-text">19）技术选型？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#20）QPS过万，redis大量连接超时怎么解决？"><span class="toc-text">20）QPS过万，redis大量连接超时怎么解决？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#21）设置过期时间的key操作注意事项"><span class="toc-text">21）设置过期时间的key操作注意事项</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1、-DEL-SET-GETSET等命令会清除过期时间"><span class="toc-text">1、 DEL&#x2F;SET&#x2F;GETSET等命令会清除过期时间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2、INCR-LPUSH-HSET等命令则不会清除过期时间；"><span class="toc-text">2、INCR&#x2F;LPUSH&#x2F;HSET等命令则不会清除过期时间；</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3、PERSIST命令会清除过期时间；"><span class="toc-text">3、PERSIST命令会清除过期时间；</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4、使用RENAME命令，老key的过期时间将会转到新key上；"><span class="toc-text">4、使用RENAME命令，老key的过期时间将会转到新key上；</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5、使用EXPIRE-PEXPIRE设置的过期时间为负数，或者使用EXPIREAT-PEXPIREAT设置过期时间戳为过去的时间会导致key被删除；"><span class="toc-text">5、使用EXPIRE&#x2F;PEXPIRE设置的过期时间为负数，或者使用EXPIREAT&#x2F;PEXPIREAT设置过期时间戳为过去的时间会导致key被删除；</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6、EXPIRE命令可以更新过期时间"><span class="toc-text">6、EXPIRE命令可以更新过期时间;</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>
  </div>

  
<script src="/js/catalog.js"></script>




    
      <div class="comments-container">
        


  <script src='//unpkg.com/valine/dist/Valine.min.js'></script>

  <div id="vcomments"></div>

  <script>
    new Valine({
      el: '#vcomments',
      appId: 'bSYdbCIyQHwCwv9NC9Fes7mU-gzGzoHsz',
      appKey: 'zuj9HNh3w0O1O5t1nR1yeNHD',
      placeholder: '说出你的想法...',
      avatar: 'retro'
    })
  </script>

    <style>
      .comments-container .v .vempty {
        display: none!important;
      }
    </style>




      </div>
    
  </div>

  
        <div class="footer">
  <div class="social">
    <ul>
      
        <li>
          <a title="github" href="https://github.com/YYZ-coder" target="_blank" rel="noopener">
            <i class="iconfont icon-github"></i>
          </a>
        </li>
      
        <li>
          <a title="rss" href="/atom.xml">
            <i class="iconfont icon-rss"></i>
          </a>
        </li>
      
    </ul>
  </div>
  
    <div class="footer-more">
      <a href="">Copyright © YYZ-coder 2020</a>
    </div>
  
    <div class="footer-more">
      <a href="https://github.com/zchengsite/hexo-theme-oranges" target="_blank" rel="noopener">Theme by Oranges | Powered by Hexo</a>
    </div>
  
</div>

      </div>

      <div class="back-to-top hidden">
  <a href="javascript: void(0)">
    <i class="iconfont icon-chevronup"></i>
  </a>
</div>


<script src="/js/backtotop.js"></script>



    </div>
  </body>
</html>
